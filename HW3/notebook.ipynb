{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Convolutional Networks\n",
    "\n",
    "We have talked about convolutional neural networks. We will implement layers used by convolutional neural networks. The first part of the assignment asks you to implement three types of layers (dropout, convolution, and pooling) commonly used in CNNs. To reduce the level of difficulty, you can implement these layers with `numpy` and for-loops. The second part of the assignment asks you to train a convolutional neural network on the CIFAR10 dataset. This assignment gives an opportunity to gain a deeper understanding of CNNs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "# As usual, a bit of setup\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from np_layers import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "\n",
    "def rel_error(x, y):\n",
    "    err = np.mean(np.abs(x - y))\n",
    "    return err\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dropout Operation\n",
    "**Question 1 (4 points).** Please implement the dropout operation with `numpy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of the output and the input has a difference: 0.007506038600223692\n",
      "The average of the output from tf.nn.dropout and the input has a difference: 0.0074151633922579195\n",
      "The differences above should be near zero (< 0.05).\n",
      "\n",
      " In test mode, the difference between the output and the input: 0.0\n"
     ]
    }
   ],
   "source": [
    "# from np_layers_solutions import dropout_forward\n",
    "\n",
    "x = np.random.random_sample([10000, 100])\n",
    "\n",
    "out_train = dropout_forward(x, drop_rate=0.7, mode='train')\n",
    "out_test = dropout_forward(x, drop_rate=0.7, mode='test')\n",
    "out_tf = tf.nn.dropout(x, rate=0.7)\n",
    "\n",
    "print('The average of the output and the input has a difference:', rel_error(np.mean(out_train, axis=0), np.mean(x, axis=0)))\n",
    "print('The average of the output from tf.nn.dropout and the input has a difference:', rel_error(np.mean(out_tf, axis=0), np.mean(x, axis=0)))\n",
    "print('The differences above should be near zero (< 0.05).')\n",
    "\n",
    "print('\\n In test mode, the difference between the output and the input:', rel_error(out_test, x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Convolution Operation\n",
    "\n",
    "**Question 2 (4 points).** Please implement a convolutional operation. Your implementation with `numpy` will be compared against an existing convolutional operation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from np_layers_solutions import conv_forward\n",
    "\n",
    "# shape is NCHW\n",
    "x_shape = (2, 3, 4, 4)\n",
    "\n",
    "# shape is FCHW\n",
    "w_shape = (3, 3, 3, 3)\n",
    "\n",
    "x = np.linspace(-0.1, 0.5, num=np.prod(x_shape)).reshape(x_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape)\n",
    "b = np.linspace(-0.1, 0.2, num=3)\n",
    "\n",
    "# permute dimensions to NHWC\n",
    "x = np.transpose(x, [0, 2, 3, 1])\n",
    "# permute dimensions to HWCF\n",
    "w = np.transpose(w, [2, 3, 1, 0])\n",
    "\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "out = conv_forward(x, w, b, conv_param)\n",
    "\n",
    "tf_out = tf.nn.conv2d(\n",
    "    tf.constant(x, dtype=tf.float32),\n",
    "    tf.constant(w, dtype=tf.float32),\n",
    "    strides=[1, conv_param['stride'], conv_param['stride'], 1],\n",
    "    padding='SAME',\n",
    "    data_format='NHWC' # NHWC is the default setting of tensorflow\n",
    ")\n",
    "\n",
    "tf_conv = tf.nn.bias_add(\n",
    "    tf_out,\n",
    "    tf.constant(b, dtype=tf.float32), \n",
    "    data_format='NHWC')\n",
    "\n",
    "\n",
    "print('Difference between your implementation and tf calculation:', rel_error(out, tf_conv.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aside: Image processing via convolutions\n",
    "\n",
    "As fun way to both check your implementation and gain a better understanding of the type of operation that convolutional layers can perform, we will set up an input containing two images and manually set up filters that perform common image processing operations (grayscale conversion and edge detection). The convolution forward pass will apply these operations to each of the input images. We can then visualize the results as a sanity check.\n",
    "\n",
    "**Question 3 (2 points).** Please modify the following code, so that 1) the first filter takes out the red channel, and 2) the second filter detects vertical edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imread\n",
    "from PIL import Image\n",
    "from np_layers_solutions import conv_forward\n",
    "\n",
    "img_size = 200 \n",
    "puppy = Image.open('puppy.jpg')\n",
    "puppy = np.array(puppy.resize((img_size, img_size), Image.ANTIALIAS))\n",
    "\n",
    "kitten = Image.open('kitten.jpg')\n",
    "kitten = np.array(kitten.resize((img_size, img_size), Image.ANTIALIAS))\n",
    "\n",
    "x = np.stack([puppy[:, :, 0:3], kitten[:, :, 0:3]])\n",
    "\n",
    "\n",
    "# Set up a convolutional weights holding 2 filters, each 3x3\n",
    "w = np.zeros((2, 3, 3, 3))\n",
    "\n",
    "# The first filter converts the image to grayscale.\n",
    "# Set up the red, green, and blue channels of the filter.\n",
    "# filter in the format of FCHW, (filters, channels, image height, image width)\n",
    "w[0, 0, :, :] = [[0, 0, 0], [0, 0.3, 0], [0, 0, 0]]\n",
    "w[0, 1, :, :] = [[0, 0, 0], [0, 0.6, 0], [0, 0, 0]]\n",
    "w[0, 2, :, :] = [[0, 0, 0], [0, 0.1, 0], [0, 0, 0]]\n",
    "\n",
    "# Second filter detects horizontal edges in the blue channel.\n",
    "w[1, 2, :, :] = [[1, 2, 1], [0, 0, 0], [-1, -2, -1]]\n",
    "\n",
    "# after the transpose, the format is [HWCF]\n",
    "w = np.transpose(w, [2, 3, 1, 0])\n",
    "\n",
    "# Vector of biases. We don't need any bias for the grayscale\n",
    "# filter, but for the edge detection filter we want to add 128\n",
    "# to each output so that nothing is negative.\n",
    "b = np.array([0, 128])\n",
    "\n",
    "# Compute the result of convolving each input in x with each filter in w,\n",
    "# offsetting by b, and storing the results in out.\n",
    "# out = conv_forward_naive(x, w, b, {'stride': 1, 'pad': 1})\n",
    "out = conv_forward(x, w, b, {'stride': 1, 'pad': 1})\n",
    "\n",
    "def imshow_noax(img, normalize=True):\n",
    "    \"\"\" Tiny helper to show images as uint8 and remove axis labels \"\"\"\n",
    "    if normalize:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "# Show the original images and the results of the conv operation\n",
    "plt.subplot(2, 3, 1)\n",
    "imshow_noax(puppy, normalize=False)\n",
    "plt.title('Original image')\n",
    "plt.subplot(2, 3, 2)\n",
    "imshow_noax(out[0, :, :, 0])\n",
    "plt.title('Grayscale')\n",
    "plt.subplot(2, 3, 3)\n",
    "imshow_noax(out[0, :, :, 1])\n",
    "plt.title('Edges')\n",
    "plt.subplot(2, 3, 4)\n",
    "imshow_noax(kitten, normalize=False)\n",
    "plt.subplot(2, 3, 5)\n",
    "imshow_noax(out[1, :, :, 0])\n",
    "plt.subplot(2, 3, 6)\n",
    "imshow_noax(out[1, :, :, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max-Pooling: Naive forward\n",
    "\n",
    "**Question 4 (4 points).** Please implement the forward pass for the max-pooling operation in the function `max_pool_forward_naive` in the file `np_layers.py`. You can check your implementation by running the following code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from np_layers_solutions import max_pool_forward\n",
    "\n",
    "# shape is NCHW\n",
    "x_shape = (2, 3, 4, 4)\n",
    "x = np.linspace(-0.3, 0.4, num=np.prod(x_shape)).reshape(x_shape)\n",
    "x = np.transpose(x, [0, 2, 3, 1])\n",
    "\n",
    "pool_param = {'pool_width': 2, 'pool_height': 2, 'stride': 2}\n",
    "\n",
    "out = max_pool_forward(x, pool_param)\n",
    "\n",
    "correct_out = tf.nn.max_pool(x, [pool_param['pool_height'], pool_param['pool_width']], \n",
    "                             pool_param['stride'], padding='VALID')\n",
    "\n",
    "# Compare your output with ours. Difference should be on the order of e-8.\n",
    "print('Testing max_pool_forward function:')\n",
    "print('The difference between your implementation and tf operation is: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a ResNet with Keras and Train it\n",
    "\n",
    "In this task, you need to build a ResNet with `tensorflow.keras` and train it on the `CIFAR10` dataset. \n",
    "\n",
    "**Question 5 (5 points).** Implementatio: in your implementation of the neural network, you can only layers from the following list:\n",
    "`Conv2D`, `Activation`, `MaxPool2D`, `BatchNormalization`, `GlobalAvgPool2D`, `Flatten` and `Dense`. Particularly you cannot directly load a ResNet from `tf.keras`. You check the example code provided by [chapter 7](https://d2l.ai/chapter_convolutional-modern/resnet.html) of D2L book. NOTE: you cannot copy code from any resources. If you implementation is correct, you will get \n",
    "\n",
    "**Question 6 (6 points).** Model tuning: depending the final performance of your trained model, you will get\n",
    "* 2 points for the test accuracy being over 0.7\n",
    "* 2 points for the test accuracy being over 0.8\n",
    "* 2 points for the test accuracy being over 0.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the CNN\n",
    "A nice trick is to train your model with just a few training samples. You should be able to overfit small datasets, which will result in very high training accuracy and comparatively low validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(137)\n",
    "\n",
    "# Load the (preprocessed) CIFAR10 data.\n",
    "\n",
    "data = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = data[0][0].astype(np.float32)\n",
    "y_train = data[0][1]\n",
    "\n",
    "x_test = data[1][0].astype(np.float32)\n",
    "y_test = data[1][1]\n",
    "\n",
    "\n",
    "# shuffle the training data\n",
    "perm = np.arange(x_train.shape[0])\n",
    "np.random.shuffle(perm)\n",
    "x_train = x_train[perm]\n",
    "y_train = y_train[perm]\n",
    "\n",
    "\n",
    "# Use one-hot representation of the label\n",
    "y_train = tf.one_hot(np.squeeze(y_train), 10)\n",
    "y_test = tf.one_hot(np.squeeze(y_test), 10)\n",
    "\n",
    "\n",
    "from conv_net import ConvNet\n",
    "\n",
    "\n",
    "# NOTE: the settings below are only an example. You need to tune all settings below to best fit your model. \n",
    "\n",
    "# TODO: comment out these three lines once you are ready to tune your model on the entire dataset.\n",
    "num_train = 100\n",
    "x_train = x_train[:num_train]\n",
    "y_train = y_train[:num_train]\n",
    "\n",
    "model = ConvNet()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "trace = model.fit(x=x_train, y=y_train, batch_size=16, epochs=100, verbose=1, \n",
    "                  validation_split=0.1, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot training losses, validation losses,  training accuracies, and validation accuracies. If these numbers are from the training on a small dataset, you should see clear overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(trace.history['loss'], '-o')\n",
    "plt.plot(trace.history['val_loss'], '-o')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(trace.history['categorical_accuracy'], '-o')\n",
    "plt.plot(trace.history['val_categorical_accuracy'], '-o')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict labels of the test set and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test.astype(np.float32))\n",
    "\n",
    "acc = np.mean(np.argmax(y_test, axis=1) == np.argmax(y_pred, axis=1))\n",
    "\n",
    "print('The test accuracy is ', acc)\n",
    "\n",
    "model.save('cifar10_cls.kmod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
