{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sorted-channels",
   "metadata": {},
   "source": [
    "# Novel Inertia Based Human Pose Estimation Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "short-progressive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from utils import *\n",
    "\n",
    "#need to have these two lines to work on my ancient 1060 3gb\n",
    "#  https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "preceding-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data from MatLab SimScape Multibody Simulator\n",
    "\n",
    "#data comes from two files\n",
    "#1) n trajectories in xyz space, each length m\n",
    "traj = np.loadtxt(open(\"simulation/data/traj1M.txt\", \"rb\"), delimiter=\",\")\n",
    "trajPts = np.shape(traj)[0] #points per trajectory\n",
    "numTraj = np.shape(traj)[1]//3 #number of total trajectories\n",
    "#traj needs to be reshaped to a 3d numpy array\n",
    "#as is traj[n] shows [x,y,z,x,y,z...]\n",
    "\n",
    "\n",
    "#2) 7 joint angles at the end of the sequence\n",
    "jointPos = np.loadtxt(open(\"simulation/data/jointPos1M.txt\", \"rb\"), delimiter=\",\")\n",
    "\n",
    "# print(traj[-1])\n",
    "# print(jointPos[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "immune-recovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3, 1000000)\n",
      "(1000000, 3, 10)\n",
      "(1000000, 10, 3)\n"
     ]
    }
   ],
   "source": [
    "#reshape traj data into 3d numpy array\n",
    "# print(np.shape(traj)) #(10,30) -> should be (10,3,10)\n",
    "t = np.zeros([trajPts,3,numTraj])\n",
    "for j in range(np.shape(traj)[0]):\n",
    "    for i in range(np.shape(traj)[1]//3):\n",
    "        t[j,:,i] = traj[j,3*i:3*(i+1)]\n",
    "# print(t[:,:,0]) #same as in MatLab\n",
    "print(np.shape(t))\n",
    "#swap axis so batch size is first axis (for TF)\n",
    "t = np.swapaxes(t,0,2)\n",
    "print(np.shape(t)) #[numTraj, xyz, trajPts]\n",
    "#swap axis again so that conv1D moves on time and not xyz\n",
    "t = np.swapaxes(t,1,2)\n",
    "print(np.shape(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "public-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert data from numpy to tensors\n",
    "\n",
    "#shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "whole-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import Net\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "#convert data from numpy to tensors\n",
    "x_train = tf.convert_to_tensor(t,np.float32)\n",
    "y_train = tf.convert_to_tensor(jointPos,np.float32)\n",
    "\n",
    "#TODO -> shuffle data\n",
    "\n",
    "\n",
    "# print(tf.shape(x_train))\n",
    "# print(x_train[0,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "working-argument",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 10, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 10, 3)        12          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 8, 16)        160         batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 8, 16)        784         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 16)        64          conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 8, 16)        784         batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 16)        64          conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_4 (TensorF [(None, 8, 16)]      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 16)        0           batch_normalization_14[0][0]     \n",
      "                                                                 tf_op_layer_Identity_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 8, 16)        0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 8, 32)        1568        re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 32)        128         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 8, 32)        3104        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 32)        128         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_5 (TensorF [(None, 8, 32)]      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 32)        0           batch_normalization_16[0][0]     \n",
      "                                                                 tf_op_layer_Identity_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 8, 32)        0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 8, 64)        6208        re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 64)        256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 8, 64)        12352       batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 64)        256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_6 (TensorF [(None, 8, 64)]      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 64)        0           batch_normalization_18[0][0]     \n",
      "                                                                 tf_op_layer_Identity_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 8, 64)        0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 8, 128)       24704       re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 128)       512         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 8, 128)       49280       batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 128)       512         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_7 (TensorF [(None, 8, 128)]     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 128)       0           batch_normalization_20[0][0]     \n",
      "                                                                 tf_op_layer_Identity_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 8, 128)       0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 8, 256)       98560       re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 256)       1024        conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 8, 256)       196864      batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 256)       1024        conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_8 (TensorF [(None, 8, 256)]     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 256)       0           batch_normalization_22[0][0]     \n",
      "                                                                 tf_op_layer_Identity_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 8, 256)       0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           131136      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64)           256         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           4160        batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 64)           256         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           4160        batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 64)           256         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 7)            455         batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_1 (TensorFlowOp [(None, 7)]          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 7)]          0           tf_op_layer_Mul_1[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 539,027\n",
      "Trainable params: 536,653\n",
      "Non-trainable params: 2,374\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7032/7032 [==============================] - 66s 9ms/step - loss: 427.2530 - mean_squared_error: 427.2530 - val_loss: 340.7744 - val_mean_squared_error: 340.7744\n",
      "Epoch 2/300\n",
      "7032/7032 [==============================] - 67s 9ms/step - loss: 269.0633 - mean_squared_error: 269.0633 - val_loss: 249.2125 - val_mean_squared_error: 249.2125\n",
      "Epoch 3/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 221.2366 - mean_squared_error: 221.2366 - val_loss: 223.8643 - val_mean_squared_error: 223.8643\n",
      "Epoch 4/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 196.2024 - mean_squared_error: 196.2024 - val_loss: 185.1350 - val_mean_squared_error: 185.1350\n",
      "Epoch 5/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 181.6287 - mean_squared_error: 181.6287 - val_loss: 176.5024 - val_mean_squared_error: 176.5024\n",
      "Epoch 6/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 171.5591 - mean_squared_error: 171.5591 - val_loss: 171.9780 - val_mean_squared_error: 171.9780\n",
      "Epoch 7/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 163.5894 - mean_squared_error: 163.5894 - val_loss: 157.5752 - val_mean_squared_error: 157.5752\n",
      "Epoch 8/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 157.3304 - mean_squared_error: 157.3304 - val_loss: 155.0125 - val_mean_squared_error: 155.0125\n",
      "Epoch 9/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 152.2901 - mean_squared_error: 152.2901 - val_loss: 150.7448 - val_mean_squared_error: 150.7448\n",
      "Epoch 10/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 147.7123 - mean_squared_error: 147.7123 - val_loss: 155.3824 - val_mean_squared_error: 155.3824\n",
      "Epoch 11/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 144.0903 - mean_squared_error: 144.0903 - val_loss: 136.4996 - val_mean_squared_error: 136.4996\n",
      "Epoch 12/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 140.9289 - mean_squared_error: 140.9289 - val_loss: 141.1439 - val_mean_squared_error: 141.1439\n",
      "Epoch 13/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 137.9715 - mean_squared_error: 137.9715 - val_loss: 140.2435 - val_mean_squared_error: 140.2435\n",
      "Epoch 14/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 135.0421 - mean_squared_error: 135.0421 - val_loss: 135.5636 - val_mean_squared_error: 135.5636\n",
      "Epoch 15/300\n",
      "7032/7032 [==============================] - 64s 9ms/step - loss: 132.7642 - mean_squared_error: 132.7642 - val_loss: 130.4404 - val_mean_squared_error: 130.4404\n",
      "Epoch 16/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 130.5842 - mean_squared_error: 130.5842 - val_loss: 132.4610 - val_mean_squared_error: 132.4610\n",
      "Epoch 17/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 128.8810 - mean_squared_error: 128.8810 - val_loss: 129.7994 - val_mean_squared_error: 129.7994\n",
      "Epoch 18/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 127.2699 - mean_squared_error: 127.2699 - val_loss: 128.5330 - val_mean_squared_error: 128.5330\n",
      "Epoch 19/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 125.4537 - mean_squared_error: 125.4537 - val_loss: 123.6376 - val_mean_squared_error: 123.6376\n",
      "Epoch 20/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 123.9725 - mean_squared_error: 123.9725 - val_loss: 121.8652 - val_mean_squared_error: 121.8652\n",
      "Epoch 21/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 122.5957 - mean_squared_error: 122.5957 - val_loss: 120.7563 - val_mean_squared_error: 120.7563\n",
      "Epoch 22/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 121.1659 - mean_squared_error: 121.1659 - val_loss: 120.2080 - val_mean_squared_error: 120.2080\n",
      "Epoch 23/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 119.8262 - mean_squared_error: 119.8262 - val_loss: 120.9708 - val_mean_squared_error: 120.9708\n",
      "Epoch 24/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 118.5749 - mean_squared_error: 118.5749 - val_loss: 119.8880 - val_mean_squared_error: 119.8880\n",
      "Epoch 25/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 117.6902 - mean_squared_error: 117.6902 - val_loss: 118.3593 - val_mean_squared_error: 118.3593\n",
      "Epoch 26/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 116.4834 - mean_squared_error: 116.4834 - val_loss: 122.7610 - val_mean_squared_error: 122.7610\n",
      "Epoch 27/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 115.6349 - mean_squared_error: 115.6349 - val_loss: 119.1400 - val_mean_squared_error: 119.1400\n",
      "Epoch 28/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 114.7866 - mean_squared_error: 114.7866 - val_loss: 115.6109 - val_mean_squared_error: 115.6109\n",
      "Epoch 29/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 113.8325 - mean_squared_error: 113.8325 - val_loss: 115.7181 - val_mean_squared_error: 115.7181\n",
      "Epoch 30/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 112.8085 - mean_squared_error: 112.8085 - val_loss: 122.3094 - val_mean_squared_error: 122.3094\n",
      "Epoch 31/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 112.1863 - mean_squared_error: 112.1863 - val_loss: 112.3554 - val_mean_squared_error: 112.3554\n",
      "Epoch 32/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 111.3530 - mean_squared_error: 111.3530 - val_loss: 116.4893 - val_mean_squared_error: 116.4893\n",
      "Epoch 33/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 110.5561 - mean_squared_error: 110.5561 - val_loss: 109.3665 - val_mean_squared_error: 109.3665\n",
      "Epoch 34/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 109.8162 - mean_squared_error: 109.8162 - val_loss: 112.4708 - val_mean_squared_error: 112.4708\n",
      "Epoch 35/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 108.9772 - mean_squared_error: 108.9772 - val_loss: 119.0236 - val_mean_squared_error: 119.0236\n",
      "Epoch 36/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 108.6777 - mean_squared_error: 108.6777 - val_loss: 112.7913 - val_mean_squared_error: 112.7913\n",
      "Epoch 37/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 107.9035 - mean_squared_error: 107.9035 - val_loss: 112.1060 - val_mean_squared_error: 112.1060\n",
      "Epoch 38/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 107.4410 - mean_squared_error: 107.4410 - val_loss: 112.7722 - val_mean_squared_error: 112.7722\n",
      "Epoch 39/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 106.6612 - mean_squared_error: 106.6612 - val_loss: 122.7042 - val_mean_squared_error: 122.7042\n",
      "Epoch 40/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 106.1860 - mean_squared_error: 106.1860 - val_loss: 111.0632 - val_mean_squared_error: 111.0632\n",
      "Epoch 41/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 105.6131 - mean_squared_error: 105.6131 - val_loss: 107.3378 - val_mean_squared_error: 107.3378\n",
      "Epoch 42/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 104.9680 - mean_squared_error: 104.9680 - val_loss: 110.5361 - val_mean_squared_error: 110.5361\n",
      "Epoch 43/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 104.2932 - mean_squared_error: 104.2932 - val_loss: 110.4901 - val_mean_squared_error: 110.4901\n",
      "Epoch 44/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 103.9263 - mean_squared_error: 103.9263 - val_loss: 117.9857 - val_mean_squared_error: 117.9857\n",
      "Epoch 45/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 103.1979 - mean_squared_error: 103.1979 - val_loss: 112.1840 - val_mean_squared_error: 112.1840\n",
      "Epoch 46/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 102.9665 - mean_squared_error: 102.9665 - val_loss: 115.2258 - val_mean_squared_error: 115.2258\n",
      "Epoch 47/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 102.6938 - mean_squared_error: 102.6938 - val_loss: 108.0300 - val_mean_squared_error: 108.0300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 102.2512 - mean_squared_error: 102.2512 - val_loss: 106.8724 - val_mean_squared_error: 106.8724\n",
      "Epoch 49/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 101.8489 - mean_squared_error: 101.8489 - val_loss: 108.9161 - val_mean_squared_error: 108.9161\n",
      "Epoch 50/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 101.1761 - mean_squared_error: 101.1761 - val_loss: 107.8256 - val_mean_squared_error: 107.8256\n",
      "Epoch 51/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 100.8996 - mean_squared_error: 100.8996 - val_loss: 108.1558 - val_mean_squared_error: 108.1558\n",
      "Epoch 52/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 100.4568 - mean_squared_error: 100.4568 - val_loss: 109.0650 - val_mean_squared_error: 109.0650\n",
      "Epoch 53/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 99.8885 - mean_squared_error: 99.8885 - val_loss: 107.7808 - val_mean_squared_error: 107.7808\n",
      "Epoch 54/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 99.8145 - mean_squared_error: 99.8145 - val_loss: 107.7549 - val_mean_squared_error: 107.7549\n",
      "Epoch 55/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 99.2255 - mean_squared_error: 99.2255 - val_loss: 113.5392 - val_mean_squared_error: 113.5392\n",
      "Epoch 56/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 99.0408 - mean_squared_error: 99.0408 - val_loss: 107.0456 - val_mean_squared_error: 107.0456\n",
      "Epoch 57/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 98.6612 - mean_squared_error: 98.6612 - val_loss: 109.1041 - val_mean_squared_error: 109.1041\n",
      "Epoch 58/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 98.3224 - mean_squared_error: 98.3224 - val_loss: 108.8658 - val_mean_squared_error: 108.8658\n",
      "Epoch 59/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 97.9742 - mean_squared_error: 97.9742 - val_loss: 104.5178 - val_mean_squared_error: 104.5178\n",
      "Epoch 60/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 97.5965 - mean_squared_error: 97.5965 - val_loss: 106.8343 - val_mean_squared_error: 106.8343\n",
      "Epoch 61/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 97.1205 - mean_squared_error: 97.1205 - val_loss: 116.9937 - val_mean_squared_error: 116.9937\n",
      "Epoch 62/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 97.1824 - mean_squared_error: 97.1824 - val_loss: 112.5830 - val_mean_squared_error: 112.5830\n",
      "Epoch 63/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 96.7375 - mean_squared_error: 96.7375 - val_loss: 103.8564 - val_mean_squared_error: 103.8564\n",
      "Epoch 64/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 96.6740 - mean_squared_error: 96.6740 - val_loss: 106.3729 - val_mean_squared_error: 106.3729\n",
      "Epoch 65/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 96.4127 - mean_squared_error: 96.4127 - val_loss: 102.7066 - val_mean_squared_error: 102.7066\n",
      "Epoch 66/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 96.2037 - mean_squared_error: 96.2037 - val_loss: 104.0330 - val_mean_squared_error: 104.0330\n",
      "Epoch 67/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 95.7154 - mean_squared_error: 95.7154 - val_loss: 103.8056 - val_mean_squared_error: 103.8056\n",
      "Epoch 68/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 95.0626 - mean_squared_error: 95.0626 - val_loss: 100.6926 - val_mean_squared_error: 100.6926\n",
      "Epoch 69/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 95.0393 - mean_squared_error: 95.0393 - val_loss: 104.5137 - val_mean_squared_error: 104.5137\n",
      "Epoch 70/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 94.6210 - mean_squared_error: 94.6210 - val_loss: 106.6314 - val_mean_squared_error: 106.6314\n",
      "Epoch 71/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 94.4457 - mean_squared_error: 94.4457 - val_loss: 107.5628 - val_mean_squared_error: 107.5628\n",
      "Epoch 72/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 94.2019 - mean_squared_error: 94.2019 - val_loss: 101.9196 - val_mean_squared_error: 101.9196\n",
      "Epoch 73/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 93.9864 - mean_squared_error: 93.9864 - val_loss: 103.3013 - val_mean_squared_error: 103.3013\n",
      "Epoch 74/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 93.6788 - mean_squared_error: 93.6788 - val_loss: 107.1765 - val_mean_squared_error: 107.1765\n",
      "Epoch 75/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 93.3908 - mean_squared_error: 93.3908 - val_loss: 102.0080 - val_mean_squared_error: 102.0080\n",
      "Epoch 76/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 93.1213 - mean_squared_error: 93.1213 - val_loss: 102.5265 - val_mean_squared_error: 102.5265\n",
      "Epoch 77/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 93.2378 - mean_squared_error: 93.2378 - val_loss: 106.8580 - val_mean_squared_error: 106.8580\n",
      "Epoch 78/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 92.5276 - mean_squared_error: 92.5276 - val_loss: 101.7958 - val_mean_squared_error: 101.7958\n",
      "Epoch 79/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 92.7240 - mean_squared_error: 92.7240 - val_loss: 101.5099 - val_mean_squared_error: 101.5099\n",
      "Epoch 80/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 92.3411 - mean_squared_error: 92.3411 - val_loss: 106.3399 - val_mean_squared_error: 106.3399\n",
      "Epoch 81/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 92.1165 - mean_squared_error: 92.1165 - val_loss: 105.2095 - val_mean_squared_error: 105.2095\n",
      "Epoch 82/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 91.7621 - mean_squared_error: 91.7621 - val_loss: 104.8715 - val_mean_squared_error: 104.8715\n",
      "Epoch 83/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 91.8146 - mean_squared_error: 91.8146 - val_loss: 104.2309 - val_mean_squared_error: 104.2309\n",
      "Epoch 84/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 91.5917 - mean_squared_error: 91.5917 - val_loss: 104.7475 - val_mean_squared_error: 104.7475\n",
      "Epoch 85/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 91.4633 - mean_squared_error: 91.4633 - val_loss: 102.3661 - val_mean_squared_error: 102.3661\n",
      "Epoch 86/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 91.1456 - mean_squared_error: 91.1456 - val_loss: 103.7295 - val_mean_squared_error: 103.7295\n",
      "Epoch 87/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 90.9752 - mean_squared_error: 90.9752 - val_loss: 103.1573 - val_mean_squared_error: 103.1573\n",
      "Epoch 88/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 90.6279 - mean_squared_error: 90.6279 - val_loss: 100.3392 - val_mean_squared_error: 100.3392\n",
      "Epoch 89/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 90.6408 - mean_squared_error: 90.6408 - val_loss: 100.9584 - val_mean_squared_error: 100.9584\n",
      "Epoch 90/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 90.4345 - mean_squared_error: 90.4345 - val_loss: 101.7182 - val_mean_squared_error: 101.7182\n",
      "Epoch 91/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 90.1604 - mean_squared_error: 90.1604 - val_loss: 102.0436 - val_mean_squared_error: 102.0436\n",
      "Epoch 92/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 89.9304 - mean_squared_error: 89.9304 - val_loss: 100.8046 - val_mean_squared_error: 100.8046\n",
      "Epoch 93/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 89.6975 - mean_squared_error: 89.6975 - val_loss: 98.7091 - val_mean_squared_error: 98.7091\n",
      "Epoch 94/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 89.4749 - mean_squared_error: 89.4749 - val_loss: 106.8601 - val_mean_squared_error: 106.8601\n",
      "Epoch 95/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7032/7032 [==============================] - 65s 9ms/step - loss: 89.6274 - mean_squared_error: 89.6274 - val_loss: 101.6993 - val_mean_squared_error: 101.6993\n",
      "Epoch 96/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 89.4173 - mean_squared_error: 89.4173 - val_loss: 99.5365 - val_mean_squared_error: 99.5365\n",
      "Epoch 97/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 89.1281 - mean_squared_error: 89.1281 - val_loss: 105.9385 - val_mean_squared_error: 105.9385\n",
      "Epoch 98/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 88.8184 - mean_squared_error: 88.8184 - val_loss: 102.3267 - val_mean_squared_error: 102.3267\n",
      "Epoch 99/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 88.9163 - mean_squared_error: 88.9163 - val_loss: 102.2022 - val_mean_squared_error: 102.2022\n",
      "Epoch 100/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 88.6401 - mean_squared_error: 88.6401 - val_loss: 103.1668 - val_mean_squared_error: 103.1668\n",
      "Epoch 101/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 79.0232 - mean_squared_error: 79.0232 - val_loss: 90.8254 - val_mean_squared_error: 90.8254\n",
      "Epoch 102/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 77.1876 - mean_squared_error: 77.1876 - val_loss: 91.0119 - val_mean_squared_error: 91.0119\n",
      "Epoch 103/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 76.6015 - mean_squared_error: 76.6015 - val_loss: 90.6720 - val_mean_squared_error: 90.6720\n",
      "Epoch 104/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 76.2873 - mean_squared_error: 76.2873 - val_loss: 90.7401 - val_mean_squared_error: 90.7401\n",
      "Epoch 105/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 76.1175 - mean_squared_error: 76.1175 - val_loss: 90.4903 - val_mean_squared_error: 90.4903\n",
      "Epoch 106/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 75.9957 - mean_squared_error: 75.9957 - val_loss: 90.5907 - val_mean_squared_error: 90.5907\n",
      "Epoch 107/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 75.6520 - mean_squared_error: 75.6520 - val_loss: 90.8839 - val_mean_squared_error: 90.8839\n",
      "Epoch 108/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 75.5846 - mean_squared_error: 75.5846 - val_loss: 90.3296 - val_mean_squared_error: 90.3296\n",
      "Epoch 109/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 75.4806 - mean_squared_error: 75.4806 - val_loss: 91.1629 - val_mean_squared_error: 91.1629\n",
      "Epoch 110/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 75.4406 - mean_squared_error: 75.4406 - val_loss: 90.8955 - val_mean_squared_error: 90.8955\n",
      "Epoch 111/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 75.2727 - mean_squared_error: 75.2727 - val_loss: 90.9695 - val_mean_squared_error: 90.9695\n",
      "Epoch 112/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 75.1650 - mean_squared_error: 75.1650 - val_loss: 90.5063 - val_mean_squared_error: 90.5063\n",
      "Epoch 113/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 75.1088 - mean_squared_error: 75.1088 - val_loss: 90.3009 - val_mean_squared_error: 90.3009\n",
      "Epoch 114/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 74.9198 - mean_squared_error: 74.9198 - val_loss: 90.7867 - val_mean_squared_error: 90.7867\n",
      "Epoch 115/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 75.0876 - mean_squared_error: 75.0876 - val_loss: 90.6811 - val_mean_squared_error: 90.6811\n",
      "Epoch 116/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 74.9672 - mean_squared_error: 74.9672 - val_loss: 90.4500 - val_mean_squared_error: 90.4500\n",
      "Epoch 117/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 74.8302 - mean_squared_error: 74.8302 - val_loss: 90.9665 - val_mean_squared_error: 90.9665\n",
      "Epoch 118/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 74.8023 - mean_squared_error: 74.8023 - val_loss: 90.7432 - val_mean_squared_error: 90.7432\n",
      "Epoch 119/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 74.7937 - mean_squared_error: 74.7937 - val_loss: 90.7087 - val_mean_squared_error: 90.7087\n",
      "Epoch 120/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 74.6005 - mean_squared_error: 74.6005 - val_loss: 90.7559 - val_mean_squared_error: 90.7559\n",
      "Epoch 121/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 74.6308 - mean_squared_error: 74.6308 - val_loss: 90.9012 - val_mean_squared_error: 90.9012\n",
      "Epoch 122/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 74.5965 - mean_squared_error: 74.5965 - val_loss: 90.6633 - val_mean_squared_error: 90.6633\n",
      "Epoch 123/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 74.5752 - mean_squared_error: 74.5752 - val_loss: 90.6650 - val_mean_squared_error: 90.6650\n",
      "Epoch 124/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 74.3787 - mean_squared_error: 74.3787 - val_loss: 90.9871 - val_mean_squared_error: 90.9871\n",
      "Epoch 125/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 74.2717 - mean_squared_error: 74.2717 - val_loss: 90.4691 - val_mean_squared_error: 90.4691\n",
      "Epoch 126/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 74.2504 - mean_squared_error: 74.2504 - val_loss: 90.7383 - val_mean_squared_error: 90.7383\n",
      "Epoch 127/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 74.1962 - mean_squared_error: 74.1962 - val_loss: 90.5782 - val_mean_squared_error: 90.5782\n",
      "Epoch 128/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 74.1329 - mean_squared_error: 74.1329 - val_loss: 90.5662 - val_mean_squared_error: 90.5662\n",
      "Epoch 129/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 74.2735 - mean_squared_error: 74.2735 - val_loss: 91.7905 - val_mean_squared_error: 91.7905\n",
      "Epoch 130/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 74.0340 - mean_squared_error: 74.0340 - val_loss: 91.3584 - val_mean_squared_error: 91.3584\n",
      "Epoch 131/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 74.0246 - mean_squared_error: 74.0246 - val_loss: 90.4962 - val_mean_squared_error: 90.4962\n",
      "Epoch 132/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 74.1093 - mean_squared_error: 74.1093 - val_loss: 90.8025 - val_mean_squared_error: 90.8025\n",
      "Epoch 133/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.8710 - mean_squared_error: 73.8710 - val_loss: 90.7950 - val_mean_squared_error: 90.7950\n",
      "Epoch 134/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.8773 - mean_squared_error: 73.8773 - val_loss: 90.5428 - val_mean_squared_error: 90.5428\n",
      "Epoch 135/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.8771 - mean_squared_error: 73.8771 - val_loss: 91.0562 - val_mean_squared_error: 91.0562\n",
      "Epoch 136/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.8171 - mean_squared_error: 73.8171 - val_loss: 90.4834 - val_mean_squared_error: 90.4834\n",
      "Epoch 137/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.8523 - mean_squared_error: 73.8523 - val_loss: 90.4822 - val_mean_squared_error: 90.4822\n",
      "Epoch 138/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 73.7202 - mean_squared_error: 73.7202 - val_loss: 90.6127 - val_mean_squared_error: 90.6127\n",
      "Epoch 139/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.7670 - mean_squared_error: 73.7670 - val_loss: 90.9126 - val_mean_squared_error: 90.9126\n",
      "Epoch 140/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.6322 - mean_squared_error: 73.6322 - val_loss: 90.9633 - val_mean_squared_error: 90.9633\n",
      "Epoch 141/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.5715 - mean_squared_error: 73.5715 - val_loss: 90.7625 - val_mean_squared_error: 90.7625\n",
      "Epoch 142/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 73.6629 - mean_squared_error: 73.6629 - val_loss: 90.9872 - val_mean_squared_error: 90.9872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.5280 - mean_squared_error: 73.5280 - val_loss: 90.8374 - val_mean_squared_error: 90.8374\n",
      "Epoch 144/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.4903 - mean_squared_error: 73.4903 - val_loss: 92.5413 - val_mean_squared_error: 92.5413\n",
      "Epoch 145/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.5313 - mean_squared_error: 73.5313 - val_loss: 90.8918 - val_mean_squared_error: 90.8918\n",
      "Epoch 146/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.5850 - mean_squared_error: 73.5850 - val_loss: 91.0819 - val_mean_squared_error: 91.0819\n",
      "Epoch 147/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.3928 - mean_squared_error: 73.3928 - val_loss: 90.9601 - val_mean_squared_error: 90.9601\n",
      "Epoch 148/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 73.5520 - mean_squared_error: 73.5520 - val_loss: 90.6544 - val_mean_squared_error: 90.6544\n",
      "Epoch 149/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.4848 - mean_squared_error: 73.4848 - val_loss: 90.8131 - val_mean_squared_error: 90.8131\n",
      "Epoch 150/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.3805 - mean_squared_error: 73.3805 - val_loss: 90.8096 - val_mean_squared_error: 90.8096\n",
      "Epoch 151/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.3562 - mean_squared_error: 73.3562 - val_loss: 90.9637 - val_mean_squared_error: 90.9637\n",
      "Epoch 152/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.3795 - mean_squared_error: 73.3795 - val_loss: 90.7170 - val_mean_squared_error: 90.7170\n",
      "Epoch 153/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.2094 - mean_squared_error: 73.2094 - val_loss: 91.5487 - val_mean_squared_error: 91.5487\n",
      "Epoch 154/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.2990 - mean_squared_error: 73.2990 - val_loss: 90.6716 - val_mean_squared_error: 90.6716\n",
      "Epoch 155/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.1601 - mean_squared_error: 73.1601 - val_loss: 90.7244 - val_mean_squared_error: 90.7244\n",
      "Epoch 156/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.2726 - mean_squared_error: 73.2726 - val_loss: 90.7614 - val_mean_squared_error: 90.7614\n",
      "Epoch 157/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.2617 - mean_squared_error: 73.2617 - val_loss: 90.8637 - val_mean_squared_error: 90.8637\n",
      "Epoch 158/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.2237 - mean_squared_error: 73.2237 - val_loss: 91.2721 - val_mean_squared_error: 91.2721\n",
      "Epoch 159/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.1224 - mean_squared_error: 73.1224 - val_loss: 91.0449 - val_mean_squared_error: 91.0449\n",
      "Epoch 160/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.1703 - mean_squared_error: 73.1703 - val_loss: 91.0769 - val_mean_squared_error: 91.0769\n",
      "Epoch 161/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.1651 - mean_squared_error: 73.1651 - val_loss: 91.3347 - val_mean_squared_error: 91.3347\n",
      "Epoch 162/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.0747 - mean_squared_error: 73.0747 - val_loss: 91.1561 - val_mean_squared_error: 91.1561\n",
      "Epoch 163/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.0052 - mean_squared_error: 73.0052 - val_loss: 91.9188 - val_mean_squared_error: 91.9188\n",
      "Epoch 164/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.9375 - mean_squared_error: 72.9375 - val_loss: 91.0168 - val_mean_squared_error: 91.0168\n",
      "Epoch 165/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.0378 - mean_squared_error: 73.0378 - val_loss: 91.2049 - val_mean_squared_error: 91.2049\n",
      "Epoch 166/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 73.0638 - mean_squared_error: 73.0638 - val_loss: 90.9429 - val_mean_squared_error: 90.9429\n",
      "Epoch 167/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.9857 - mean_squared_error: 72.9857 - val_loss: 91.0057 - val_mean_squared_error: 91.0057\n",
      "Epoch 168/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.8948 - mean_squared_error: 72.8948 - val_loss: 90.9449 - val_mean_squared_error: 90.9449\n",
      "Epoch 169/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.8229 - mean_squared_error: 72.8229 - val_loss: 91.1576 - val_mean_squared_error: 91.1576\n",
      "Epoch 170/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.8618 - mean_squared_error: 72.8618 - val_loss: 91.2975 - val_mean_squared_error: 91.2975\n",
      "Epoch 171/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.8366 - mean_squared_error: 72.8366 - val_loss: 90.7969 - val_mean_squared_error: 90.7969\n",
      "Epoch 172/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.8473 - mean_squared_error: 72.8473 - val_loss: 91.4354 - val_mean_squared_error: 91.4354\n",
      "Epoch 173/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.7196 - mean_squared_error: 72.7196 - val_loss: 91.3809 - val_mean_squared_error: 91.3809\n",
      "Epoch 174/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.7380 - mean_squared_error: 72.7380 - val_loss: 90.9542 - val_mean_squared_error: 90.9542\n",
      "Epoch 175/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.6963 - mean_squared_error: 72.6963 - val_loss: 90.8192 - val_mean_squared_error: 90.8192\n",
      "Epoch 176/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.6838 - mean_squared_error: 72.6838 - val_loss: 91.1127 - val_mean_squared_error: 91.1127\n",
      "Epoch 177/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.5839 - mean_squared_error: 72.5839 - val_loss: 90.9900 - val_mean_squared_error: 90.9900\n",
      "Epoch 178/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.6258 - mean_squared_error: 72.6258 - val_loss: 90.8112 - val_mean_squared_error: 90.8112\n",
      "Epoch 179/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.7321 - mean_squared_error: 72.7321 - val_loss: 91.2683 - val_mean_squared_error: 91.2683\n",
      "Epoch 180/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.5426 - mean_squared_error: 72.5426 - val_loss: 91.0454 - val_mean_squared_error: 91.0454\n",
      "Epoch 181/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.5920 - mean_squared_error: 72.5920 - val_loss: 91.0112 - val_mean_squared_error: 91.0112\n",
      "Epoch 182/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.4968 - mean_squared_error: 72.4968 - val_loss: 91.1355 - val_mean_squared_error: 91.1355\n",
      "Epoch 183/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.5228 - mean_squared_error: 72.5228 - val_loss: 91.0543 - val_mean_squared_error: 91.0543\n",
      "Epoch 184/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.5384 - mean_squared_error: 72.5384 - val_loss: 90.7874 - val_mean_squared_error: 90.7874\n",
      "Epoch 185/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.6447 - mean_squared_error: 72.6447 - val_loss: 90.8539 - val_mean_squared_error: 90.8539\n",
      "Epoch 186/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.4501 - mean_squared_error: 72.4501 - val_loss: 91.2304 - val_mean_squared_error: 91.2304\n",
      "Epoch 187/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.4296 - mean_squared_error: 72.4296 - val_loss: 91.4662 - val_mean_squared_error: 91.4662\n",
      "Epoch 188/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.4740 - mean_squared_error: 72.4740 - val_loss: 91.6449 - val_mean_squared_error: 91.6449\n",
      "Epoch 189/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.3326 - mean_squared_error: 72.3326 - val_loss: 91.2321 - val_mean_squared_error: 91.2321\n",
      "Epoch 190/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.3867 - mean_squared_error: 72.3867 - val_loss: 91.3161 - val_mean_squared_error: 91.3161\n",
      "Epoch 191/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.4406 - mean_squared_error: 72.4406 - val_loss: 91.3922 - val_mean_squared_error: 91.3922\n",
      "Epoch 192/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.2860 - mean_squared_error: 72.2860 - val_loss: 91.3447 - val_mean_squared_error: 91.3447\n",
      "Epoch 193/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 72.3950 - mean_squared_error: 72.3950 - val_loss: 91.3374 - val_mean_squared_error: 91.3374\n",
      "Epoch 194/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.2685 - mean_squared_error: 72.2685 - val_loss: 91.1644 - val_mean_squared_error: 91.1644\n",
      "Epoch 195/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.4118 - mean_squared_error: 72.4118 - val_loss: 90.9044 - val_mean_squared_error: 90.9044\n",
      "Epoch 196/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.2689 - mean_squared_error: 72.2689 - val_loss: 91.3044 - val_mean_squared_error: 91.3044\n",
      "Epoch 197/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.3255 - mean_squared_error: 72.3255 - val_loss: 91.4163 - val_mean_squared_error: 91.4163\n",
      "Epoch 198/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.1481 - mean_squared_error: 72.1481 - val_loss: 91.7979 - val_mean_squared_error: 91.7979\n",
      "Epoch 199/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.2208 - mean_squared_error: 72.2208 - val_loss: 91.1000 - val_mean_squared_error: 91.1000\n",
      "Epoch 200/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 72.1688 - mean_squared_error: 72.1688 - val_loss: 90.8372 - val_mean_squared_error: 90.8372\n",
      "Epoch 201/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 71.1893 - mean_squared_error: 71.1893 - val_loss: 90.5730 - val_mean_squared_error: 90.5730\n",
      "Epoch 202/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 71.1737 - mean_squared_error: 71.1737 - val_loss: 90.5849 - val_mean_squared_error: 90.5849\n",
      "Epoch 203/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 71.0213 - mean_squared_error: 71.0213 - val_loss: 90.5649 - val_mean_squared_error: 90.5649\n",
      "Epoch 204/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 71.0457 - mean_squared_error: 71.0457 - val_loss: 90.4285 - val_mean_squared_error: 90.4285\n",
      "Epoch 205/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.9402 - mean_squared_error: 70.9402 - val_loss: 90.5688 - val_mean_squared_error: 90.5688\n",
      "Epoch 206/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.8858 - mean_squared_error: 70.8858 - val_loss: 90.5717 - val_mean_squared_error: 90.5717\n",
      "Epoch 207/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 71.0581 - mean_squared_error: 71.0581 - val_loss: 90.5102 - val_mean_squared_error: 90.5102\n",
      "Epoch 208/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 71.1194 - mean_squared_error: 71.1194 - val_loss: 90.5082 - val_mean_squared_error: 90.5082\n",
      "Epoch 209/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 71.0527 - mean_squared_error: 71.0527 - val_loss: 90.6262 - val_mean_squared_error: 90.6262\n",
      "Epoch 210/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.8671 - mean_squared_error: 70.8671 - val_loss: 90.5530 - val_mean_squared_error: 90.5530\n",
      "Epoch 211/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.8895 - mean_squared_error: 70.8895 - val_loss: 90.5845 - val_mean_squared_error: 90.5845\n",
      "Epoch 212/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.9287 - mean_squared_error: 70.9287 - val_loss: 90.4992 - val_mean_squared_error: 90.4992\n",
      "Epoch 213/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.8606 - mean_squared_error: 70.8606 - val_loss: 90.5600 - val_mean_squared_error: 90.5600\n",
      "Epoch 214/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.8842 - mean_squared_error: 70.8842 - val_loss: 90.5223 - val_mean_squared_error: 90.5223\n",
      "Epoch 215/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.9686 - mean_squared_error: 70.9686 - val_loss: 90.5277 - val_mean_squared_error: 90.5277\n",
      "Epoch 216/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.7329 - mean_squared_error: 70.7329 - val_loss: 90.5245 - val_mean_squared_error: 90.5245\n",
      "Epoch 217/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.8740 - mean_squared_error: 70.8740 - val_loss: 90.5559 - val_mean_squared_error: 90.5559\n",
      "Epoch 218/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.9423 - mean_squared_error: 70.9423 - val_loss: 90.5400 - val_mean_squared_error: 90.5400\n",
      "Epoch 219/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.9419 - mean_squared_error: 70.9419 - val_loss: 90.5168 - val_mean_squared_error: 90.5168\n",
      "Epoch 220/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.9321 - mean_squared_error: 70.9321 - val_loss: 90.4421 - val_mean_squared_error: 90.4421\n",
      "Epoch 221/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.8840 - mean_squared_error: 70.8840 - val_loss: 90.5698 - val_mean_squared_error: 90.5698\n",
      "Epoch 222/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.8888 - mean_squared_error: 70.8888 - val_loss: 90.5889 - val_mean_squared_error: 90.5889\n",
      "Epoch 223/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.9250 - mean_squared_error: 70.9250 - val_loss: 90.5993 - val_mean_squared_error: 90.5993\n",
      "Epoch 224/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.8363 - mean_squared_error: 70.8363 - val_loss: 90.4655 - val_mean_squared_error: 90.4655\n",
      "Epoch 225/300\n",
      "7032/7032 [==============================] - 67s 10ms/step - loss: 70.8542 - mean_squared_error: 70.8542 - val_loss: 90.5248 - val_mean_squared_error: 90.5248\n",
      "Epoch 226/300\n",
      "7032/7032 [==============================] - 69s 10ms/step - loss: 70.9171 - mean_squared_error: 70.9171 - val_loss: 90.5404 - val_mean_squared_error: 90.5404\n",
      "Epoch 227/300\n",
      "7032/7032 [==============================] - 70s 10ms/step - loss: 70.8465 - mean_squared_error: 70.8465 - val_loss: 90.5717 - val_mean_squared_error: 90.5717\n",
      "Epoch 228/300\n",
      "7032/7032 [==============================] - 68s 10ms/step - loss: 70.7474 - mean_squared_error: 70.7474 - val_loss: 90.6183 - val_mean_squared_error: 90.6183\n",
      "Epoch 229/300\n",
      "7032/7032 [==============================] - 72s 10ms/step - loss: 70.7909 - mean_squared_error: 70.7909 - val_loss: 90.5746 - val_mean_squared_error: 90.5746\n",
      "Epoch 230/300\n",
      "7032/7032 [==============================] - 68s 10ms/step - loss: 70.7492 - mean_squared_error: 70.7492 - val_loss: 90.7066 - val_mean_squared_error: 90.7066\n",
      "Epoch 231/300\n",
      "7032/7032 [==============================] - 70s 10ms/step - loss: 70.7035 - mean_squared_error: 70.7035 - val_loss: 90.6275 - val_mean_squared_error: 90.6275\n",
      "Epoch 232/300\n",
      "7032/7032 [==============================] - 69s 10ms/step - loss: 70.9242 - mean_squared_error: 70.9242 - val_loss: 91.0533 - val_mean_squared_error: 91.0533\n",
      "Epoch 233/300\n",
      "7032/7032 [==============================] - 70s 10ms/step - loss: 70.7609 - mean_squared_error: 70.7609 - val_loss: 90.5552 - val_mean_squared_error: 90.5552\n",
      "Epoch 234/300\n",
      "7032/7032 [==============================] - 70s 10ms/step - loss: 70.7589 - mean_squared_error: 70.7589 - val_loss: 90.5700 - val_mean_squared_error: 90.5700\n",
      "Epoch 235/300\n",
      "7032/7032 [==============================] - 70s 10ms/step - loss: 70.7738 - mean_squared_error: 70.7738 - val_loss: 90.4788 - val_mean_squared_error: 90.4788\n",
      "Epoch 236/300\n",
      "7032/7032 [==============================] - 69s 10ms/step - loss: 70.6891 - mean_squared_error: 70.6891 - val_loss: 90.5152 - val_mean_squared_error: 90.5152\n",
      "Epoch 237/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7032/7032 [==============================] - 69s 10ms/step - loss: 70.8812 - mean_squared_error: 70.8812 - val_loss: 90.5283 - val_mean_squared_error: 90.5283\n",
      "Epoch 238/300\n",
      "7032/7032 [==============================] - 71s 10ms/step - loss: 70.8050 - mean_squared_error: 70.8050 - val_loss: 90.5393 - val_mean_squared_error: 90.5393\n",
      "Epoch 239/300\n",
      "7032/7032 [==============================] - 71s 10ms/step - loss: 70.6754 - mean_squared_error: 70.6754 - val_loss: 90.5667 - val_mean_squared_error: 90.5667\n",
      "Epoch 240/300\n",
      "7032/7032 [==============================] - 73s 10ms/step - loss: 70.7784 - mean_squared_error: 70.7784 - val_loss: 90.5966 - val_mean_squared_error: 90.5966\n",
      "Epoch 241/300\n",
      "7032/7032 [==============================] - 72s 10ms/step - loss: 70.8332 - mean_squared_error: 70.8332 - val_loss: 90.5067 - val_mean_squared_error: 90.5067\n",
      "Epoch 242/300\n",
      "7032/7032 [==============================] - 70s 10ms/step - loss: 70.9137 - mean_squared_error: 70.9137 - val_loss: 90.5656 - val_mean_squared_error: 90.5656\n",
      "Epoch 243/300\n",
      "7032/7032 [==============================] - 70s 10ms/step - loss: 70.8884 - mean_squared_error: 70.8884 - val_loss: 90.5977 - val_mean_squared_error: 90.5977\n",
      "Epoch 244/300\n",
      "7032/7032 [==============================] - 71s 10ms/step - loss: 70.8373 - mean_squared_error: 70.8373 - val_loss: 90.5404 - val_mean_squared_error: 90.5404\n",
      "Epoch 245/300\n",
      "7032/7032 [==============================] - 70s 10ms/step - loss: 70.9304 - mean_squared_error: 70.9304 - val_loss: 90.6348 - val_mean_squared_error: 90.6348\n",
      "Epoch 246/300\n",
      "7032/7032 [==============================] - 69s 10ms/step - loss: 70.8889 - mean_squared_error: 70.8889 - val_loss: 90.5745 - val_mean_squared_error: 90.5745\n",
      "Epoch 247/300\n",
      "7032/7032 [==============================] - 71s 10ms/step - loss: 70.8380 - mean_squared_error: 70.8380 - val_loss: 90.5676 - val_mean_squared_error: 90.5676\n",
      "Epoch 248/300\n",
      "7032/7032 [==============================] - 69s 10ms/step - loss: 70.7906 - mean_squared_error: 70.7906 - val_loss: 90.6011 - val_mean_squared_error: 90.6011\n",
      "Epoch 249/300\n",
      "7032/7032 [==============================] - 69s 10ms/step - loss: 70.8219 - mean_squared_error: 70.8219 - val_loss: 90.5258 - val_mean_squared_error: 90.5258\n",
      "Epoch 250/300\n",
      "7032/7032 [==============================] - 72s 10ms/step - loss: 70.8242 - mean_squared_error: 70.8242 - val_loss: 90.5465 - val_mean_squared_error: 90.5465\n",
      "Epoch 251/300\n",
      "7032/7032 [==============================] - 70s 10ms/step - loss: 70.8152 - mean_squared_error: 70.8152 - val_loss: 90.5925 - val_mean_squared_error: 90.5925\n",
      "Epoch 252/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 70.8128 - mean_squared_error: 70.8128 - val_loss: 90.5246 - val_mean_squared_error: 90.5246\n",
      "Epoch 253/300\n",
      "7032/7032 [==============================] - 69s 10ms/step - loss: 70.6791 - mean_squared_error: 70.6791 - val_loss: 90.5681 - val_mean_squared_error: 90.5681\n",
      "Epoch 254/300\n",
      "7032/7032 [==============================] - 68s 10ms/step - loss: 70.7155 - mean_squared_error: 70.7155 - val_loss: 90.5419 - val_mean_squared_error: 90.5419\n",
      "Epoch 255/300\n",
      "7032/7032 [==============================] - 68s 10ms/step - loss: 70.7561 - mean_squared_error: 70.7561 - val_loss: 90.4711 - val_mean_squared_error: 90.4711\n",
      "Epoch 256/300\n",
      "7032/7032 [==============================] - 69s 10ms/step - loss: 70.6765 - mean_squared_error: 70.6765 - val_loss: 90.5101 - val_mean_squared_error: 90.5101\n",
      "Epoch 257/300\n",
      "7032/7032 [==============================] - 72s 10ms/step - loss: 70.8650 - mean_squared_error: 70.8650 - val_loss: 90.6108 - val_mean_squared_error: 90.6108\n",
      "Epoch 258/300\n",
      "7032/7032 [==============================] - 72s 10ms/step - loss: 70.7673 - mean_squared_error: 70.7673 - val_loss: 90.5182 - val_mean_squared_error: 90.5182\n",
      "Epoch 259/300\n",
      "7032/7032 [==============================] - 70s 10ms/step - loss: 70.7535 - mean_squared_error: 70.7535 - val_loss: 90.5130 - val_mean_squared_error: 90.5130\n",
      "Epoch 260/300\n",
      "7032/7032 [==============================] - 72s 10ms/step - loss: 70.6570 - mean_squared_error: 70.6570 - val_loss: 90.5683 - val_mean_squared_error: 90.5683\n",
      "Epoch 261/300\n",
      "7032/7032 [==============================] - 71s 10ms/step - loss: 70.7870 - mean_squared_error: 70.7870 - val_loss: 90.6699 - val_mean_squared_error: 90.6699\n",
      "Epoch 262/300\n",
      "7032/7032 [==============================] - 71s 10ms/step - loss: 70.6101 - mean_squared_error: 70.6101 - val_loss: 90.6480 - val_mean_squared_error: 90.6480\n",
      "Epoch 263/300\n",
      "7032/7032 [==============================] - 71s 10ms/step - loss: 70.7840 - mean_squared_error: 70.7840 - val_loss: 90.5857 - val_mean_squared_error: 90.5857\n",
      "Epoch 264/300\n",
      "7032/7032 [==============================] - 71s 10ms/step - loss: 70.6413 - mean_squared_error: 70.6413 - val_loss: 90.4233 - val_mean_squared_error: 90.4233\n",
      "Epoch 265/300\n",
      "7032/7032 [==============================] - 70s 10ms/step - loss: 70.6617 - mean_squared_error: 70.6617 - val_loss: 90.5319 - val_mean_squared_error: 90.5319\n",
      "Epoch 266/300\n",
      "7032/7032 [==============================] - 70s 10ms/step - loss: 70.7530 - mean_squared_error: 70.7530 - val_loss: 90.5895 - val_mean_squared_error: 90.5895\n",
      "Epoch 267/300\n",
      "7032/7032 [==============================] - 71s 10ms/step - loss: 70.6157 - mean_squared_error: 70.6157 - val_loss: 90.5533 - val_mean_squared_error: 90.5533\n",
      "Epoch 268/300\n",
      "7032/7032 [==============================] - 70s 10ms/step - loss: 70.7805 - mean_squared_error: 70.7805 - val_loss: 90.5383 - val_mean_squared_error: 90.5383\n",
      "Epoch 269/300\n",
      "7032/7032 [==============================] - 71s 10ms/step - loss: 70.6622 - mean_squared_error: 70.6622 - val_loss: 90.6247 - val_mean_squared_error: 90.6247\n",
      "Epoch 270/300\n",
      "7032/7032 [==============================] - 69s 10ms/step - loss: 70.7411 - mean_squared_error: 70.7411 - val_loss: 90.5853 - val_mean_squared_error: 90.5853\n",
      "Epoch 271/300\n",
      "7032/7032 [==============================] - 70s 10ms/step - loss: 70.6309 - mean_squared_error: 70.6309 - val_loss: 90.6044 - val_mean_squared_error: 90.6044\n",
      "Epoch 272/300\n",
      "7032/7032 [==============================] - 71s 10ms/step - loss: 70.6806 - mean_squared_error: 70.6806 - val_loss: 90.5738 - val_mean_squared_error: 90.5738\n",
      "Epoch 273/300\n",
      "7032/7032 [==============================] - 70s 10ms/step - loss: 70.7602 - mean_squared_error: 70.7602 - val_loss: 90.5463 - val_mean_squared_error: 90.5463\n",
      "Epoch 274/300\n",
      "7032/7032 [==============================] - 70s 10ms/step - loss: 70.8434 - mean_squared_error: 70.8434 - val_loss: 90.4618 - val_mean_squared_error: 90.4618\n",
      "Epoch 275/300\n",
      "7032/7032 [==============================] - 72s 10ms/step - loss: 70.6521 - mean_squared_error: 70.6521 - val_loss: 90.5424 - val_mean_squared_error: 90.5424\n",
      "Epoch 276/300\n",
      "7032/7032 [==============================] - 72s 10ms/step - loss: 70.5217 - mean_squared_error: 70.5217 - val_loss: 90.5184 - val_mean_squared_error: 90.5184\n",
      "Epoch 277/300\n",
      "7032/7032 [==============================] - 71s 10ms/step - loss: 70.7424 - mean_squared_error: 70.7424 - val_loss: 90.6658 - val_mean_squared_error: 90.6658\n",
      "Epoch 278/300\n",
      "7032/7032 [==============================] - 71s 10ms/step - loss: 70.6857 - mean_squared_error: 70.6857 - val_loss: 90.5469 - val_mean_squared_error: 90.5469\n",
      "Epoch 279/300\n",
      "7032/7032 [==============================] - 72s 10ms/step - loss: 70.6780 - mean_squared_error: 70.6780 - val_loss: 90.5450 - val_mean_squared_error: 90.5450\n",
      "Epoch 280/300\n",
      "7032/7032 [==============================] - 69s 10ms/step - loss: 70.7903 - mean_squared_error: 70.7903 - val_loss: 90.4723 - val_mean_squared_error: 90.4723\n",
      "Epoch 281/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 70.7227 - mean_squared_error: 70.7227 - val_loss: 90.7647 - val_mean_squared_error: 90.7647\n",
      "Epoch 282/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 70.5534 - mean_squared_error: 70.5534 - val_loss: 90.6493 - val_mean_squared_error: 90.6493\n",
      "Epoch 283/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 70.7861 - mean_squared_error: 70.7861 - val_loss: 90.5034 - val_mean_squared_error: 90.5034\n",
      "Epoch 284/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.7365 - mean_squared_error: 70.7365 - val_loss: 90.5137 - val_mean_squared_error: 90.5137\n",
      "Epoch 285/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.5423 - mean_squared_error: 70.5423 - val_loss: 90.5526 - val_mean_squared_error: 90.5526\n",
      "Epoch 286/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.6481 - mean_squared_error: 70.6481 - val_loss: 90.5322 - val_mean_squared_error: 90.5322\n",
      "Epoch 287/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.5562 - mean_squared_error: 70.5562 - val_loss: 90.6021 - val_mean_squared_error: 90.6021\n",
      "Epoch 288/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.5524 - mean_squared_error: 70.5524 - val_loss: 90.6385 - val_mean_squared_error: 90.6385\n",
      "Epoch 289/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.6119 - mean_squared_error: 70.6119 - val_loss: 90.6317 - val_mean_squared_error: 90.6317\n",
      "Epoch 290/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.8175 - mean_squared_error: 70.8175 - val_loss: 90.6492 - val_mean_squared_error: 90.6492\n",
      "Epoch 291/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.6180 - mean_squared_error: 70.6180 - val_loss: 90.6007 - val_mean_squared_error: 90.6007\n",
      "Epoch 292/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.7414 - mean_squared_error: 70.7414 - val_loss: 90.6342 - val_mean_squared_error: 90.6342\n",
      "Epoch 293/300\n",
      "7032/7032 [==============================] - 65s 9ms/step - loss: 70.6820 - mean_squared_error: 70.6820 - val_loss: 90.5640 - val_mean_squared_error: 90.5640\n",
      "Epoch 294/300\n",
      "7032/7032 [==============================] - 66s 9ms/step - loss: 70.5943 - mean_squared_error: 70.5943 - val_loss: 90.6721 - val_mean_squared_error: 90.6721\n",
      "Epoch 295/300\n",
      "7032/7032 [==============================] - 67s 9ms/step - loss: 70.5164 - mean_squared_error: 70.5164 - val_loss: 90.6102 - val_mean_squared_error: 90.6102\n",
      "Epoch 296/300\n",
      "7032/7032 [==============================] - 67s 10ms/step - loss: 70.6164 - mean_squared_error: 70.6164 - val_loss: 90.5813 - val_mean_squared_error: 90.5813\n",
      "Epoch 297/300\n",
      "7032/7032 [==============================] - 68s 10ms/step - loss: 70.6910 - mean_squared_error: 70.6910 - val_loss: 90.5134 - val_mean_squared_error: 90.5134\n",
      "Epoch 298/300\n",
      "7032/7032 [==============================] - 67s 10ms/step - loss: 70.6585 - mean_squared_error: 70.6585 - val_loss: 90.4672 - val_mean_squared_error: 90.4672\n",
      "Epoch 299/300\n",
      "7032/7032 [==============================] - 67s 10ms/step - loss: 70.5398 - mean_squared_error: 70.5398 - val_loss: 90.5889 - val_mean_squared_error: 90.5889\n",
      "Epoch 300/300\n",
      "7032/7032 [==============================] - 67s 10ms/step - loss: 70.5127 - mean_squared_error: 70.5127 - val_loss: 90.5950 - val_mean_squared_error: 90.5950\n"
     ]
    }
   ],
   "source": [
    "model = Net() #starting out with basic linear feedforward network (CNN wrote for CIFR-10 does not work with 2D data)\n",
    "\n",
    "runLen = 300    \n",
    "\n",
    "# def scheduler(epoch, lr):\n",
    "#     part1 = runLen//50\n",
    "#     part2 = runLen//2\n",
    "#     part3 = 3*runLen//4\n",
    "    \n",
    "#     if epoch < part1:\n",
    "#         lr = 0.05\n",
    "#         return lr\n",
    "#     if epoch >= part1 and epoch < part2:\n",
    "#         lr = 0.01\n",
    "#         return lr\n",
    "#     if epoch >= part2 and epoch < part3:\n",
    "#         lr = 0.001\n",
    "#         return lr\n",
    "#     if epoch >= part3:\n",
    "#         lr = 0.0001\n",
    "#         return lr\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    part1 = runLen//3\n",
    "    part2 = 2*runLen//3\n",
    "    \n",
    "    if epoch < part1:\n",
    "        lr = 0.01\n",
    "        return lr\n",
    "    if epoch >= part1 and epoch < part2:\n",
    "        lr = 0.001\n",
    "        return lr\n",
    "    if epoch >= part2:\n",
    "        lr = 0.0001\n",
    "        return lr\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.MeanSquaredError()],)\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)\n",
    "\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "#Train Model bs was 256\n",
    "trace = model.fit(x=x_train, y=y_train, batch_size=128, epochs=runLen, verbose=1, \n",
    "                  validation_split=0.1, callbacks = [callback], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "promotional-howard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.0, 500.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(trace.history['loss'], '-')\n",
    "plt.plot(trace.history['val_loss'], '-')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim(10,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "quiet-reducing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error =  [ 4.6392007  4.9545536  2.4391654 10.214085   7.704418   9.492755\n",
      "  8.46071  ]\n",
      "error as frac of joint range =  [0.092 0.082 0.036 0.092 0.064 0.026 0.065]\n",
      "total error =  0.46000563483076434\n"
     ]
    }
   ],
   "source": [
    "#test model- IMPORTANT TO USE NEVER BEFORE SEEN DATA\n",
    "\n",
    "#from train data (not ideal to use for testing)\n",
    "# prediction = model.predict(x_train[-1000:-1])\n",
    "# actual = y_train[-1000:-1]\n",
    "\n",
    "#x_data\n",
    "trajTest = np.loadtxt(open(\"simulation/data/traj1k.txt\", \"rb\"), delimiter=\",\")\n",
    "trajPtsTest = np.shape(trajTest)[0] #points per test trajectory\n",
    "numTrajTest = np.shape(trajTest)[1]//3 #number of test trajectories\n",
    "tTest = np.zeros([trajPtsTest,3,numTrajTest])\n",
    "for j in range(np.shape(trajTest)[0]):\n",
    "    for i in range(np.shape(trajTest)[1]//3):\n",
    "        tTest[j,:,i] = trajTest[j,3*i:3*(i+1)]\n",
    "#swap axis so batch size is first axis (for TF)\n",
    "tTest = np.swapaxes(tTest,0,2)\n",
    "#swap axis again so that conv1D moves on time and not xyz\n",
    "tTest = np.swapaxes(tTest,1,2)\n",
    "x_test = tf.convert_to_tensor(tTest,np.float32)\n",
    "\n",
    "#y_data\n",
    "jointPosTest = np.loadtxt(open(\"simulation/data/jointPos1k.txt\", \"rb\"), delimiter=\",\")\n",
    "y_test = tf.convert_to_tensor(jointPosTest,np.float32)\n",
    "\n",
    "prediction = model.predict(x_test)\n",
    "error = (y_test - prediction)\n",
    "# print(np.floor(error))\n",
    "\n",
    "#average error for estimates for each joint\n",
    "avg = np.average(abs(error),axis=0)\n",
    "print(\"average error = \", avg)\n",
    "\n",
    "#range for each joint:\n",
    "ranges = [50, 60, 67.5, 110, 120, 360, 130]\n",
    "rel_error = avg/ranges\n",
    "print(\"error as frac of joint range = \", np.floor(rel_error*1000)/1000) #1 is full range of joint\n",
    "print(\"total error = \",sum(rel_error))\n",
    "#current best is: \n",
    "#                 0.460 @ [0.092 0.082 0.036 0.092 0.064 0.026 0.065]\n",
    "#                 val_error: 90.46\n",
    "\n",
    "# print(prediction[-10])\n",
    "# print(y_test[-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hidden-policy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Derm\\anaconda3\\envs\\dnn\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Derm\\anaconda3\\envs\\dnn\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: trajectory_cls.kmod\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"trajectory_cls.kmod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proof my model is doing better than completely random guessing\n",
    "\n",
    "np.random.seed(None)\n",
    "\n",
    "# print(actual)\n",
    "# print(tf.shape(actual)) #[99 7]\n",
    "B = tf.random.uniform([1000,7])\n",
    "\n",
    "# B = tf.ones([99,7])\n",
    "B = B *tf.constant([25., 30., 33.75, 55. , 60., 180., 65.]) + tf.constant([0., 0., 26.25, -35., 30., 0., -65.])\n",
    "\n",
    "# print(tf.shape(B))\n",
    "# print(tf.shape(actual))\n",
    "\n",
    "fake_error = (actual - B)\n",
    "# print(fake_error)\n",
    "\n",
    "fake_avg = tf.math.reduce_mean(tf.math.abs(fake_error), axis=0)\n",
    "print(fake_avg)\n",
    "\n",
    "rel_fake_error = fake_avg/ranges\n",
    "\n",
    "print(\"error as frac of joint range: \",rel_fake_error)\n",
    "print(\"total error: \", sum(rel_fake_error))\n",
    "\n",
    "#NOTE: these are not all the same becuase the starting ranges for joint positions do NOT fall in the middle of all\n",
    "#      possible positions for each joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-punishment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn",
   "language": "python",
   "name": "dnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
