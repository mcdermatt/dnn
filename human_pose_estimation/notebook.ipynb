{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sorted-channels",
   "metadata": {},
   "source": [
    "# Novel Inertia Based Human Pose Estimation Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "short-progressive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from utils import *\n",
    "\n",
    "#need to have these two lines to work on my ancient 1060 3gb\n",
    "#  https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and augment data by rotating about y axis\n",
    "\n",
    "from utils import *\n",
    "\n",
    "# f1 = \"simulation/data/traj_9DOF_500k.txt\"\n",
    "# f2 = \"simulation/data/jointPos_9DOF_500k.txt\"\n",
    "# numTraj = 500000\n",
    "# t, jointPos = add_body_rotation(f1, f2, numTraj, mult = 1)\n",
    "\n",
    "f3 = \"simulation/data/traj_9DOF_250k.txt\"\n",
    "f4 = \"simulation/data/jointPos_9DOF_250k.txt\"\n",
    "numTraj = 250000\n",
    "t2, jointPos2 = add_body_rotation(f3, f4, numTraj, mult = 1)\n",
    "\n",
    "\n",
    "# print(jointPos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine traj and jointpos from the two datasets\n",
    "\n",
    "# print(np.shape(t),np.shape(t2))\n",
    "# print(np.shape(jointPos),np.shape(jointPos2))\n",
    "\n",
    "tCombined = np.concatenate((t,t2), axis = 0)\n",
    "jointPosCombined = np.concatenate((jointPos,jointPos2), axis = 0)\n",
    "\n",
    "print(np.shape(tCombined), np.shape(jointPosCombined))\n",
    "\n",
    "t = tCombined\n",
    "jointPos = jointPosCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find and fix errors in data \n",
    "err = np.argwhere(np.abs(jointPos) == 0)[:,0]\n",
    "over_extended = np.argwhere(np.abs(jointPos) > 360)\n",
    "\n",
    "print(err)\n",
    "print(over_extended)\n",
    "\n",
    "# Remove cells with errors instead of doubling existing cells\n",
    "jointPos = np.delete(jointPos,err,axis = 0)\n",
    "t = np.delete(t,err, axis = 0)\n",
    "\n",
    "#replace empty trials with data from existing trials -> not a good idea...?\n",
    "# for i in err[:,0]:\n",
    "# #     print(jointPos[i])\n",
    "#     randIndex = int(np.floor(np.random.rand()*np.shape(jointPos)[0]))\n",
    "#     jointPos[i] = jointPos[randIndex]\n",
    "#     t[i] = t[randIndex]\n",
    "\n",
    "print(np.shape(jointPos))\n",
    "print(np.shape(t))\n",
    "\n",
    "# np.save(\"simulation/data/traj_combined\", t)\n",
    "# np.save(\"simulation/data/jointPos_combined\", jointPos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pending-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pre-rotated dataset\n",
    "\n",
    "t = np.load(\"simulation/data/traj_combined.npy\")\n",
    "jointPos = np.load(\"simulation/data/jointPos_combined.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "whole-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import Net4 #for 10DOF model\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "#convert data from numpy to tensors\n",
    "x_train = tf.convert_to_tensor(t,np.float32)\n",
    "y_train = tf.convert_to_tensor(jointPos,np.float32)\n",
    "\n",
    "# print(tf.shape(x_train))\n",
    "# print(x_train[0,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "working-argument",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 10, 6)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 10, 6)        24          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 8, 16)        304         batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 8, 16)        784         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 16)        64          conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 8, 16)        784         batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 16)        64          conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_20 (Tensor [(None, 8, 16)]      0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 8, 16)        0           batch_normalization_54[0][0]     \n",
      "                                                                 tf_op_layer_Identity_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 8, 16)        0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 8, 32)        1568        re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 32)        128         conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 8, 32)        3104        batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 32)        128         conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_21 (Tensor [(None, 8, 32)]      0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 8, 32)        0           batch_normalization_56[0][0]     \n",
      "                                                                 tf_op_layer_Identity_21[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 8, 32)        0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 8, 64)        6208        re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 64)        256         conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 8, 64)        12352       batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 64)        256         conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_22 (Tensor [(None, 8, 64)]      0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 8, 64)        0           batch_normalization_58[0][0]     \n",
      "                                                                 tf_op_layer_Identity_22[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, 8, 64)        0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 8, 128)       24704       re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 128)       512         conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 8, 128)       49280       batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 128)       512         conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_23 (Tensor [(None, 8, 128)]     0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 8, 128)       0           batch_normalization_60[0][0]     \n",
      "                                                                 tf_op_layer_Identity_23[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_23 (ReLU)                 (None, 8, 128)       0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 8, 256)       98560       re_lu_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 256)       1024        conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 8, 256)       196864      batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 256)       1024        conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_24 (Tensor [(None, 8, 256)]     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 8, 256)       0           batch_normalization_62[0][0]     \n",
      "                                                                 tf_op_layer_Identity_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_24 (ReLU)                 (None, 8, 256)       0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 8, 512)       393728      re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 8, 512)       2048        conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 8, 512)       786944      batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 8, 512)       2048        conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_25 (Tensor [(None, 8, 512)]     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 8, 512)       0           batch_normalization_64[0][0]     \n",
      "                                                                 tf_op_layer_Identity_25[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_25 (ReLU)                 (None, 8, 512)       0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 8, 1024)      1573888     re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 8, 1024)      4096        conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 8, 1024)      3146752     batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 8, 1024)      4096        conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_26 (Tensor [(None, 8, 1024)]    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 8, 1024)      0           batch_normalization_66[0][0]     \n",
      "                                                                 tf_op_layer_Identity_26[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_26 (ReLU)                 (None, 8, 1024)      0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 8192)         0           re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           524352      flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 64)           256         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 64)           4160        batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 64)           256         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 64)           4160        batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 64)           256         dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 10)           650         batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_3 (TensorFlowOp [(None, 10)]         0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_3 (TensorFlow [(None, 10)]         0           tf_op_layer_Mul_3[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 6,846,194\n",
      "Trainable params: 6,837,670\n",
      "Non-trainable params: 8,524\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4843/4843 [==============================] - 156s 32ms/step - loss: 1383.6189 - val_loss: 1400.7711\n",
      "Epoch 2/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 1066.4075 - val_loss: 1089.1138\n",
      "Epoch 3/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 887.4127 - val_loss: 853.4233\n",
      "Epoch 4/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 767.1614 - val_loss: 771.3403\n",
      "Epoch 5/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 687.9963 - val_loss: 705.0956\n",
      "Epoch 6/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 633.7965 - val_loss: 687.2437\n",
      "Epoch 7/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 590.0159 - val_loss: 600.9707\n",
      "Epoch 8/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 554.9099 - val_loss: 599.1541\n",
      "Epoch 9/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 526.9313 - val_loss: 580.6180\n",
      "Epoch 10/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 502.7914 - val_loss: 610.2239\n",
      "Epoch 11/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 484.0242 - val_loss: 545.0199\n",
      "Epoch 12/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 464.2482 - val_loss: 498.6668\n",
      "Epoch 13/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 449.4705 - val_loss: 537.3607\n",
      "Epoch 14/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 435.6913 - val_loss: 508.1628\n",
      "Epoch 15/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 422.2351 - val_loss: 487.1968\n",
      "Epoch 16/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 409.4614 - val_loss: 478.8127\n",
      "Epoch 17/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 398.2996 - val_loss: 488.2777\n",
      "Epoch 18/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 387.8668 - val_loss: 509.6641\n",
      "Epoch 19/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 375.8455 - val_loss: 507.4705\n",
      "Epoch 20/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 368.5148 - val_loss: 483.8606\n",
      "Epoch 21/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 359.1503 - val_loss: 459.7153\n",
      "Epoch 22/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 350.9431 - val_loss: 457.5870\n",
      "Epoch 23/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 344.4890 - val_loss: 464.9408\n",
      "Epoch 24/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 336.6585 - val_loss: 470.0703\n",
      "Epoch 25/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 330.5316 - val_loss: 448.3344\n",
      "Epoch 26/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 323.8209 - val_loss: 577.5410\n",
      "Epoch 27/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 317.3373 - val_loss: 486.0832\n",
      "Epoch 28/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 311.2684 - val_loss: 489.1768\n",
      "Epoch 29/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 305.6342 - val_loss: 447.7230\n",
      "Epoch 30/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 302.0445 - val_loss: 467.7666\n",
      "Epoch 31/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 296.6721 - val_loss: 449.5580\n",
      "Epoch 32/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 290.4448 - val_loss: 454.7139\n",
      "Epoch 33/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 286.6733 - val_loss: 440.8809\n",
      "Epoch 34/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 205.8929 - val_loss: 364.3398\n",
      "Epoch 35/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 187.1932 - val_loss: 367.6666\n",
      "Epoch 36/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 178.6485 - val_loss: 356.2467\n",
      "Epoch 37/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 175.2934 - val_loss: 358.0851\n",
      "Epoch 38/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 170.8515 - val_loss: 360.9083\n",
      "Epoch 39/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 165.9632 - val_loss: 361.8916\n",
      "Epoch 40/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 161.8862 - val_loss: 357.7028\n",
      "Epoch 41/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 159.3425 - val_loss: 370.2342\n",
      "Epoch 42/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 156.6668 - val_loss: 357.9792\n",
      "Epoch 43/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 154.8451 - val_loss: 371.3051\n",
      "Epoch 44/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 153.0119 - val_loss: 374.8447\n",
      "Epoch 45/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 151.3995 - val_loss: 370.4471\n",
      "Epoch 46/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 148.7740 - val_loss: 378.7773\n",
      "Epoch 47/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 148.9870 - val_loss: 362.1854\n",
      "Epoch 48/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 147.0922 - val_loss: 360.8661\n",
      "Epoch 49/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 145.3610 - val_loss: 357.9785\n",
      "Epoch 50/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 144.2909 - val_loss: 370.9504\n",
      "Epoch 51/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 143.3367 - val_loss: 365.7022\n",
      "Epoch 52/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 143.4227 - val_loss: 365.9225\n",
      "Epoch 53/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 141.5501 - val_loss: 367.1175\n",
      "Epoch 54/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 140.0064 - val_loss: 376.5320\n",
      "Epoch 55/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 138.6375 - val_loss: 368.0344\n",
      "Epoch 56/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 138.9504 - val_loss: 366.8654\n",
      "Epoch 57/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 137.9069 - val_loss: 372.8089\n",
      "Epoch 58/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 136.7317 - val_loss: 375.3958\n",
      "Epoch 59/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 136.3855 - val_loss: 373.3657\n",
      "Epoch 60/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 135.5933 - val_loss: 377.5307\n",
      "Epoch 61/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 133.6019 - val_loss: 379.1457\n",
      "Epoch 62/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 134.6478 - val_loss: 369.1328\n",
      "Epoch 63/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 132.2190 - val_loss: 380.9432\n",
      "Epoch 64/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 133.0652 - val_loss: 359.9824\n",
      "Epoch 65/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 131.3525 - val_loss: 370.1449\n",
      "Epoch 66/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 130.7663 - val_loss: 367.5274\n",
      "Epoch 67/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 126.2515 - val_loss: 365.2075\n",
      "Epoch 68/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 125.5107 - val_loss: 373.1800\n",
      "Epoch 69/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 124.4186 - val_loss: 380.4904\n",
      "Epoch 70/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 123.8889 - val_loss: 371.1118\n",
      "Epoch 71/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 122.8094 - val_loss: 370.7813\n",
      "Epoch 72/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 123.6708 - val_loss: 372.2823\n",
      "Epoch 73/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 122.5698 - val_loss: 381.3833\n",
      "Epoch 74/100\n",
      "4843/4843 [==============================] - 157s 32ms/step - loss: 121.4820 - val_loss: 369.6554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "4843/4843 [==============================] - 155s 32ms/step - loss: 121.7850 - val_loss: 370.0743\n",
      "Epoch 76/100\n",
      "4843/4843 [==============================] - 155s 32ms/step - loss: 121.5321 - val_loss: 368.2549\n",
      "Epoch 77/100\n",
      "4843/4843 [==============================] - 155s 32ms/step - loss: 120.8018 - val_loss: 380.9489\n",
      "Epoch 78/100\n",
      "4843/4843 [==============================] - 155s 32ms/step - loss: 120.4648 - val_loss: 363.0666\n",
      "Epoch 79/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 119.6428 - val_loss: 365.8386\n",
      "Epoch 80/100\n",
      "4843/4843 [==============================] - 155s 32ms/step - loss: 120.0425 - val_loss: 374.8709\n",
      "Epoch 81/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 119.6253 - val_loss: 372.6107\n",
      "Epoch 82/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 118.8632 - val_loss: 370.4093\n",
      "Epoch 83/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 119.4138 - val_loss: 386.3583\n",
      "Epoch 84/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 118.7816 - val_loss: 366.0984\n",
      "Epoch 85/100\n",
      "4843/4843 [==============================] - 155s 32ms/step - loss: 119.1145 - val_loss: 372.7395\n",
      "Epoch 86/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 118.8653 - val_loss: 378.2406\n",
      "Epoch 87/100\n",
      "4843/4843 [==============================] - 155s 32ms/step - loss: 117.3085 - val_loss: 375.1328\n",
      "Epoch 88/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 117.9831 - val_loss: 373.5222\n",
      "Epoch 89/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 117.2798 - val_loss: 362.0135\n",
      "Epoch 90/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 116.9179 - val_loss: 373.3396\n",
      "Epoch 91/100\n",
      "4843/4843 [==============================] - 155s 32ms/step - loss: 117.6560 - val_loss: 366.6419\n",
      "Epoch 92/100\n",
      "4843/4843 [==============================] - 155s 32ms/step - loss: 116.2405 - val_loss: 362.8839\n",
      "Epoch 93/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 117.0086 - val_loss: 366.9083\n",
      "Epoch 94/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 116.9215 - val_loss: 369.9894\n",
      "Epoch 95/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 115.5990 - val_loss: 373.2950\n",
      "Epoch 96/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 116.1009 - val_loss: 374.9791\n",
      "Epoch 97/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 115.4368 - val_loss: 363.0099\n",
      "Epoch 98/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 115.4559 - val_loss: 372.7210\n",
      "Epoch 99/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 114.8480 - val_loss: 361.1087\n",
      "Epoch 100/100\n",
      "4843/4843 [==============================] - 156s 32ms/step - loss: 114.6105 - val_loss: 371.3004\n"
     ]
    }
   ],
   "source": [
    "model = Net4()\n",
    "\n",
    "runLen = 100    \n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "#     part1 = 2*runLen//3\n",
    "#     part2 = 5*runLen//6 #net1\n",
    "\n",
    "    part1 = runLen//3\n",
    "    part2 = 2*runLen//3 #net2\n",
    "\n",
    "    if epoch < part1:\n",
    "        lr = 0.01\n",
    "        return lr\n",
    "    if epoch >= part1 and epoch < part2:\n",
    "        lr = 0.001\n",
    "        return lr\n",
    "    if epoch >= part2:\n",
    "        lr = 0.0005\n",
    "        return lr\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "#     loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "#     metrics=[tf.keras.metrics.MeanSquaredError()],\n",
    ")\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)\n",
    "\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "trace = model.fit(x=x_train, y=y_train, batch_size=128, epochs=runLen, verbose=1, \n",
    "                  validation_split=0.01, callbacks = [callback], shuffle=True)\n",
    "\n",
    "#current best on combined dataset:\n",
    "#   val_loss = 505\n",
    "#   sum error on 10k test set: 0.97\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "promotional-howard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(trace.history['loss'], '-')\n",
    "plt.plot(trace.history['val_loss'], '-')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "# plt.ylim(10,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "necessary-column",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved augmented data as tbr, jbr\n"
     ]
    }
   ],
   "source": [
    "#load larger test dataset (for calculating accuracy of network)\n",
    "\n",
    "ft1 = \"simulation/data/traj_9DOF_10k.txt\"\n",
    "ft2 = \"simulation/data/jointPos_9DOF_10k.txt\"\n",
    "numTraj = 10000 #number of trajectories given in base file\n",
    "\n",
    "tTest, jointPosTest = add_body_rotation(ft1, ft2, numTraj, mult =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "demonstrated-elimination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved augmented data as tbr, jbr, at\n"
     ]
    }
   ],
   "source": [
    "#load single test case (for use with viz)\n",
    "#DEBUG -> why does this perform better when data is generated with fast restart disabled??\n",
    "\n",
    "ft1 = \"simulation/data/traj_9DOF_1.txt\"\n",
    "ft2 = \"simulation/data/jointPos_9DOF_1.txt\"\n",
    "ft3 = \"simulation/data/jointPath.txt\"\n",
    "numTraj = 1 #number of trajectories given in base file\n",
    "\n",
    "tTest, jointPosTest = add_body_rotation(ft1, ft2, numTraj, mult =1, actual_traj=ft3)\n",
    "\n",
    "# print(tTest)\n",
    "# print(jointPosTest) #issue when only one element in jointPos input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "quiet-reducing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error =  [ 2.8742712  9.76874    3.863006   2.655428   9.805542  13.70463\n",
      "  8.035751   5.449898  16.70791    6.6410294]\n",
      "error as frac of joint range =  [0.057 0.162 0.057 0.024 0.081 0.038 0.061 0.03  0.151 0.018]\n",
      "total error =  0.6838770731493958\n",
      "prediction:  [ -0.1185288   -0.87593955  -0.11680603  17.353573    33.89946\n",
      "  40.14663    -28.451752   -29.064898   -16.47697    -17.252594  ]\n",
      "actual:  tf.Tensor(\n",
      "[ -2.9928     8.8928     3.7462    20.009     43.705     26.442\n",
      " -20.416    -23.615      0.23094  -23.893623], shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#test model- IMPORTANT TO USE NEVER BEFORE SEEN DATA\n",
    "\n",
    "x_test = tf.convert_to_tensor(tTest,np.float32)\n",
    "y_test = tf.convert_to_tensor(jointPosTest,np.float32)\n",
    "\n",
    "prediction = model.predict(x_test)\n",
    "error = abs(y_test - prediction)\n",
    "\n",
    "#average error for estimates for each joint\n",
    "avg = np.average(error,axis=0)\n",
    "print(\"average error = \", avg)\n",
    "\n",
    "#range for each joint:\n",
    "ranges = [50, 60, 67.5, 110, 120, 360, 130, 180, 110, 360]\n",
    "rel_error = avg/ranges\n",
    "print(\"error as frac of joint range = \", np.floor(rel_error*1000)/1000) #1 is full range of joint\n",
    "print(\"total error = \",sum(rel_error))\n",
    "\n",
    "print(\"prediction: \",prediction[0])\n",
    "print(\"actual: \", y_test[0])\n",
    "\n",
    "np.save(\"simulation/data/prediction.npy\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-investment",
   "metadata": {},
   "source": [
    "Best total error: \n",
    "\n",
    "1.52 @ 10k  dataset, mult 1, BS 128, MSE\n",
    "\n",
    "1.29 @ 100k dataset, mult 2, BS 128, MSE\n",
    "\n",
    "1.15 @ 100k dataset, mult 1, BS 128, MSE\n",
    "\n",
    "1.10 @ 100k dataset, mult 1, BS 64,  MSE, Val loss = 851, 10 epoch\n",
    "\n",
    "0.97 @ 100k dataset, mult 1, BS 128,  MSE, Val loss = 623, 30 epoch\n",
    "\n",
    "0.86 @ 100k dataset, mult 1, BS 128,  MSE, Val loss = 556, 100 epoch\n",
    "\n",
    "0.90 @ 250k dataset (replace errors with repeats), mult 1, BS 128, val loss = 476, 100 epoch\n",
    "\n",
    "0.82 @ combined 650k dataset, mult 1, BS 128, MSE, val loss = 371, 100 epoch\n",
    "\n",
    "Notes:\n",
    "artifially creating more data by rotating about y axis at different angles is a bad idea. This teaches the network to memorize patterns of movement rather than learn the underlying dynamic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hidden-policy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Derm\\anaconda3\\envs\\dnn\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Derm\\anaconda3\\envs\\dnn\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: 10DOF.kmod\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"10DOF.kmod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best scoring model\n",
    "\n",
    "model = tf.keras.models.load_model(\"10DOF.kmod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proof my model is doing better than completely random guessing\n",
    "\n",
    "np.random.seed(None)\n",
    "\n",
    "# print(actual)\n",
    "# print(tf.shape(actual)) #[99 7]\n",
    "B = tf.random.uniform([1000,7])\n",
    "\n",
    "# B = tf.ones([99,7])\n",
    "B = B *tf.constant([25., 30., 33.75, 55. , 60., 180., 65.]) + tf.constant([0., 0., 26.25, -35., 30., 0., -65.])\n",
    "\n",
    "# print(tf.shape(B))\n",
    "# print(tf.shape(actual))\n",
    "\n",
    "fake_error = (y_test - B)\n",
    "# print(fake_error)\n",
    "\n",
    "fake_avg = tf.math.reduce_mean(tf.math.abs(fake_error), axis=0)\n",
    "print(fake_avg)\n",
    "\n",
    "rel_fake_error = fake_avg/ranges\n",
    "\n",
    "print(\"error as frac of joint range: \",rel_fake_error)\n",
    "print(\"total error: \", sum(rel_fake_error))\n",
    "\n",
    "#NOTE: these are not all the same becuase the starting ranges for joint positions do NOT fall in the middle of all\n",
    "#      possible positions for each joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "r = R.from_euler('zyx', [\n",
    "[90, 0, 0],\n",
    "[0, 45, 0],\n",
    "[45, 60, 30]], degrees=True)\n",
    "\n",
    "print(r)\n",
    "r.as_quat()\n",
    "\n",
    "v = [1, 2, 3]\n",
    "\n",
    "r.apply(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = R.from_euler('z', 90, degrees=True)\n",
    "r2 = R.from_euler('x', 90, degrees=True)\n",
    "r3 = r1*r2\n",
    "\n",
    "v = [1, 2, 3]\n",
    "\n",
    "rot1 = r1.apply(v)\n",
    "rot2 = r3.apply(v)\n",
    "print(rot2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c= r3.apply([1, 2, 3])\n",
    "print(a,b,c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data from MatLab SimScape Multibody Simulator\n",
    "\n",
    "#data comes from two files\n",
    "#1) n trajectories in xyz space, each length m\n",
    "# traj = np.loadtxt(open(\"C:/Users/Derm/Desktop/traj_with_angs_1M.txt\", \"rb\"), delimiter=\",\")\n",
    "traj = np.loadtxt(open(\"simulation/data/traj_9DOF_100k.txt\", \"rb\"), delimiter=\",\")\n",
    "\n",
    "trajPts = np.shape(traj)[0] #points per trajectory\n",
    "# numTraj = np.shape(traj)[1]//3 #number of total trajectories\n",
    "numTraj = np.shape(traj)[1]//6 #number of total trajectories\n",
    "\n",
    "\n",
    "#traj needs to be reshaped to a 3d numpy array\n",
    "#as is traj[n] shows [x,y,z,x,y,z...]\n",
    "\n",
    "\n",
    "#2) 7 joint angles at the end of the sequence\n",
    "# jointPos = np.loadtxt(open(\"C:/Users/Derm/Desktop/jointPos_with_angs_1M.txt\", \"rb\"), delimiter=\",\")\n",
    "jointPos = np.loadtxt(open(\"simulation/data/jointPos_9DOF_100k.txt\", \"rb\"), delimiter=\",\")\n",
    "\n",
    "# print(traj[-1])\n",
    "# print(jointPos[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape traj data into 3d numpy array\n",
    "# t = np.zeros([trajPts,3,numTraj]) #net 1\n",
    "# for j in range(np.shape(traj)[0]):\n",
    "#     for i in range(np.shape(traj)[1]//3):\n",
    "#         t[j,:,i] = traj[j,3*i:3*(i+1)]\n",
    "        \n",
    "t = np.zeros([trajPts,6,numTraj]) #net 3\n",
    "for j in range(np.shape(traj)[0]):\n",
    "    for i in range(np.shape(traj)[1]//6):\n",
    "        t[j,:,i] = traj[j,6*i:6*(i+1)]\n",
    "\n",
    "        \n",
    "# print(t[:,:,0]) #same as in MatLab\n",
    "print(np.shape(t))\n",
    "#swap axis so batch size is first axis (for TF)\n",
    "t = np.swapaxes(t,0,2)\n",
    "print(np.shape(t)) #[numTraj, xyz, trajPts]\n",
    "#swap axis again so that conv1D moves on time and not xyz\n",
    "t = np.swapaxes(t,1,2)\n",
    "print(np.shape(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-signature",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn",
   "language": "python",
   "name": "dnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
