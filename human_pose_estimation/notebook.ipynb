{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sorted-channels",
   "metadata": {},
   "source": [
    "# Novel Inertia Based Human Pose Estimation Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "short-progressive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from utils import *\n",
    "\n",
    "#need to have these two lines to work on my ancient 1060 3gb\n",
    "#  https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "preceding-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data from MatLab SimScape Multibody Simulator\n",
    "\n",
    "#data comes from two files\n",
    "#1) n trajectories in xyz space, each length m\n",
    "# traj = np.loadtxt(open(\"simulation/data/traj1M.txt\", \"rb\"), delimiter=\",\")\n",
    "# traj = np.loadtxt(open(\"simulation/data/traj_random100k.txt\", \"rb\"), delimiter=\",\")\n",
    "traj = np.loadtxt(open(\"simulation/data/traj_with_angs_10k.txt\", \"rb\"), delimiter=\",\")\n",
    "\n",
    "\n",
    "trajPts = np.shape(traj)[0] #points per trajectory\n",
    "# numTraj = np.shape(traj)[1]//3 #number of total trajectories\n",
    "numTraj = np.shape(traj)[1]//6 #number of total trajectories\n",
    "\n",
    "\n",
    "#traj needs to be reshaped to a 3d numpy array\n",
    "#as is traj[n] shows [x,y,z,x,y,z...]\n",
    "\n",
    "\n",
    "#2) 7 joint angles at the end of the sequence\n",
    "jointPos = np.loadtxt(open(\"simulation/data/jointPos_with_angs_10k.txt\", \"rb\"), delimiter=\",\")\n",
    "# jointPos = np.loadtxt(open(\"simulation/data/jointPos_random100k.txt\", \"rb\"), delimiter=\",\")\n",
    "\n",
    "# print(traj[-1])\n",
    "# print(jointPos[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "immune-recovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 6, 10000)\n",
      "(10000, 6, 10)\n",
      "(10000, 10, 6)\n"
     ]
    }
   ],
   "source": [
    "#reshape traj data into 3d numpy array\n",
    "# t = np.zeros([trajPts,3,numTraj]) #net 1\n",
    "# for j in range(np.shape(traj)[0]):\n",
    "#     for i in range(np.shape(traj)[1]//3):\n",
    "#         t[j,:,i] = traj[j,3*i:3*(i+1)]\n",
    "        \n",
    "t = np.zeros([trajPts,6,numTraj]) #net 3\n",
    "for j in range(np.shape(traj)[0]):\n",
    "    for i in range(np.shape(traj)[1]//6):\n",
    "        t[j,:,i] = traj[j,6*i:6*(i+1)]\n",
    "\n",
    "        \n",
    "# print(t[:,:,0]) #same as in MatLab\n",
    "print(np.shape(t))\n",
    "#swap axis so batch size is first axis (for TF)\n",
    "t = np.swapaxes(t,0,2)\n",
    "print(np.shape(t)) #[numTraj, xyz, trajPts]\n",
    "#swap axis again so that conv1D moves on time and not xyz\n",
    "t = np.swapaxes(t,1,2)\n",
    "print(np.shape(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "whole-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from network import Net1 #optim for 1M linear dataset (not ideal because used inconsistant timesteps in solver)\n",
    "# from network import Net2 #optim for 100k time varying\n",
    "from network import Net3 #optim for data with position and rotation\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "#convert data from numpy to tensors\n",
    "x_train = tf.convert_to_tensor(t,np.float32)\n",
    "y_train = tf.convert_to_tensor(jointPos,np.float32)\n",
    "\n",
    "# print(tf.shape(x_train))\n",
    "# print(x_train[0,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "working-argument",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 10, 6)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 10, 6)        24          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 8, 16)        304         batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 8, 16)        784         conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 16)        64          conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 8, 16)        784         batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 16)        64          conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_15 (Tensor [(None, 8, 16)]      0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 16)        0           batch_normalization_44[0][0]     \n",
      "                                                                 tf_op_layer_Identity_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 8, 16)        0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 8, 32)        1568        re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 32)        128         conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 8, 32)        3104        batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 32)        128         conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_16 (Tensor [(None, 8, 32)]      0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 32)        0           batch_normalization_46[0][0]     \n",
      "                                                                 tf_op_layer_Identity_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 8, 32)        0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 8, 64)        6208        re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 8, 64)        256         conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 8, 64)        12352       batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 8, 64)        256         conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_17 (Tensor [(None, 8, 64)]      0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 8, 64)        0           batch_normalization_48[0][0]     \n",
      "                                                                 tf_op_layer_Identity_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 8, 64)        0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 8, 128)       24704       re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 8, 128)       512         conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 8, 128)       49280       batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 128)       512         conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_18 (Tensor [(None, 8, 128)]     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 8, 128)       0           batch_normalization_50[0][0]     \n",
      "                                                                 tf_op_layer_Identity_18[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 8, 128)       0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 8, 256)       98560       re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 256)       1024        conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 8, 256)       196864      batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 256)       1024        conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_19 (Tensor [(None, 8, 256)]     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 8, 256)       0           batch_normalization_52[0][0]     \n",
      "                                                                 tf_op_layer_Identity_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 8, 256)       0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 2048)         0           re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           131136      flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 64)           256         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 64)           4160        batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 64)           256         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 64)           4160        batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 64)           256         dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 7)            455         batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_3 (TensorFlowOp [(None, 7)]          0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_3 (TensorFlow [(None, 7)]          0           tf_op_layer_Mul_3[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 539,183\n",
      "Trainable params: 536,803\n",
      "Non-trainable params: 2,380\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 2s 9ms/step - loss: 665.9810 - mean_squared_error: 665.9810 - val_loss: 499.4478 - val_mean_squared_error: 499.4478\n",
      "Epoch 2/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 442.4386 - mean_squared_error: 442.4386 - val_loss: 405.3983 - val_mean_squared_error: 405.3983\n",
      "Epoch 3/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 415.3629 - mean_squared_error: 415.3629 - val_loss: 420.6691 - val_mean_squared_error: 420.6691\n",
      "Epoch 4/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 402.3947 - mean_squared_error: 402.3947 - val_loss: 407.2169 - val_mean_squared_error: 407.2169\n",
      "Epoch 5/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 379.4077 - mean_squared_error: 379.4077 - val_loss: 353.9772 - val_mean_squared_error: 353.9772\n",
      "Epoch 6/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 377.0948 - mean_squared_error: 377.0948 - val_loss: 358.6138 - val_mean_squared_error: 358.6138\n",
      "Epoch 7/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 371.7987 - mean_squared_error: 371.7987 - val_loss: 388.6750 - val_mean_squared_error: 388.6750\n",
      "Epoch 8/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 368.5423 - mean_squared_error: 368.5423 - val_loss: 343.9361 - val_mean_squared_error: 343.9361\n",
      "Epoch 9/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 354.8278 - mean_squared_error: 354.8278 - val_loss: 326.1217 - val_mean_squared_error: 326.1217\n",
      "Epoch 10/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 353.1401 - mean_squared_error: 353.1401 - val_loss: 325.5418 - val_mean_squared_error: 325.5418\n",
      "Epoch 11/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 349.5998 - mean_squared_error: 349.5998 - val_loss: 345.3846 - val_mean_squared_error: 345.3846\n",
      "Epoch 12/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 343.9549 - mean_squared_error: 343.9549 - val_loss: 326.4540 - val_mean_squared_error: 326.4540\n",
      "Epoch 13/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 345.4592 - mean_squared_error: 345.4592 - val_loss: 317.4442 - val_mean_squared_error: 317.4442\n",
      "Epoch 14/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 343.7474 - mean_squared_error: 343.7474 - val_loss: 321.4995 - val_mean_squared_error: 321.4995\n",
      "Epoch 15/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 340.9655 - mean_squared_error: 340.9655 - val_loss: 315.5156 - val_mean_squared_error: 315.5156\n",
      "Epoch 16/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 337.5679 - mean_squared_error: 337.5679 - val_loss: 334.7308 - val_mean_squared_error: 334.7308\n",
      "Epoch 17/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 338.3264 - mean_squared_error: 338.3264 - val_loss: 315.2087 - val_mean_squared_error: 315.2087\n",
      "Epoch 18/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 336.5539 - mean_squared_error: 336.5539 - val_loss: 313.3878 - val_mean_squared_error: 313.3878\n",
      "Epoch 19/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 337.5111 - mean_squared_error: 337.5111 - val_loss: 311.8443 - val_mean_squared_error: 311.8443\n",
      "Epoch 20/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 333.4734 - mean_squared_error: 333.4734 - val_loss: 311.6245 - val_mean_squared_error: 311.6245\n",
      "Epoch 21/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 327.6575 - mean_squared_error: 327.6575 - val_loss: 320.2872 - val_mean_squared_error: 320.2872\n",
      "Epoch 22/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 329.8744 - mean_squared_error: 329.8744 - val_loss: 315.5596 - val_mean_squared_error: 315.5596\n",
      "Epoch 23/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 331.8347 - mean_squared_error: 331.8347 - val_loss: 320.1677 - val_mean_squared_error: 320.1677\n",
      "Epoch 24/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 330.2773 - mean_squared_error: 330.2773 - val_loss: 331.5856 - val_mean_squared_error: 331.5856\n",
      "Epoch 25/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 328.0219 - mean_squared_error: 328.0219 - val_loss: 301.0277 - val_mean_squared_error: 301.0277\n",
      "Epoch 26/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 325.9987 - mean_squared_error: 325.9987 - val_loss: 298.5092 - val_mean_squared_error: 298.5092\n",
      "Epoch 27/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 326.8752 - mean_squared_error: 326.8752 - val_loss: 296.5833 - val_mean_squared_error: 296.5833\n",
      "Epoch 28/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 323.4265 - mean_squared_error: 323.4265 - val_loss: 296.8450 - val_mean_squared_error: 296.8450\n",
      "Epoch 29/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 323.9369 - mean_squared_error: 323.9369 - val_loss: 308.8842 - val_mean_squared_error: 308.8842\n",
      "Epoch 30/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 319.0487 - mean_squared_error: 319.0487 - val_loss: 298.1490 - val_mean_squared_error: 298.1490\n",
      "Epoch 31/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 321.0072 - mean_squared_error: 321.0072 - val_loss: 291.8876 - val_mean_squared_error: 291.8876\n",
      "Epoch 32/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 319.1475 - mean_squared_error: 319.1475 - val_loss: 292.7497 - val_mean_squared_error: 292.7497\n",
      "Epoch 33/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 318.0219 - mean_squared_error: 318.0219 - val_loss: 297.4969 - val_mean_squared_error: 297.4969\n",
      "Epoch 34/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 317.2971 - mean_squared_error: 317.2971 - val_loss: 284.1586 - val_mean_squared_error: 284.1586\n",
      "Epoch 35/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 314.7698 - mean_squared_error: 314.7698 - val_loss: 302.3669 - val_mean_squared_error: 302.3669\n",
      "Epoch 36/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 315.3403 - mean_squared_error: 315.3403 - val_loss: 286.5434 - val_mean_squared_error: 286.5434\n",
      "Epoch 37/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 315.0775 - mean_squared_error: 315.0775 - val_loss: 285.8137 - val_mean_squared_error: 285.8137\n",
      "Epoch 38/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 312.1857 - mean_squared_error: 312.1857 - val_loss: 284.0981 - val_mean_squared_error: 284.0981\n",
      "Epoch 39/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 309.0280 - mean_squared_error: 309.0280 - val_loss: 285.8595 - val_mean_squared_error: 285.8595\n",
      "Epoch 40/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 311.6761 - mean_squared_error: 311.6761 - val_loss: 280.8541 - val_mean_squared_error: 280.8541\n",
      "Epoch 41/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 309.1866 - mean_squared_error: 309.1866 - val_loss: 278.6617 - val_mean_squared_error: 278.6617\n",
      "Epoch 42/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 309.2484 - mean_squared_error: 309.2484 - val_loss: 291.4593 - val_mean_squared_error: 291.4593\n",
      "Epoch 43/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 307.9412 - mean_squared_error: 307.9412 - val_loss: 290.1718 - val_mean_squared_error: 290.1718\n",
      "Epoch 44/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 310.2219 - mean_squared_error: 310.2219 - val_loss: 279.2387 - val_mean_squared_error: 279.2387\n",
      "Epoch 45/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 309.7196 - mean_squared_error: 309.7196 - val_loss: 282.6757 - val_mean_squared_error: 282.6757\n",
      "Epoch 46/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 304.2646 - mean_squared_error: 304.2646 - val_loss: 296.3255 - val_mean_squared_error: 296.3255\n",
      "Epoch 47/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 306.4912 - mean_squared_error: 306.4912 - val_loss: 338.5318 - val_mean_squared_error: 338.5318\n",
      "Epoch 48/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 300.7601 - mean_squared_error: 300.7601 - val_loss: 283.3516 - val_mean_squared_error: 283.3516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 299.2141 - mean_squared_error: 299.2141 - val_loss: 299.3604 - val_mean_squared_error: 299.3604\n",
      "Epoch 50/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 299.9188 - mean_squared_error: 299.9188 - val_loss: 283.5486 - val_mean_squared_error: 283.5486\n",
      "Epoch 51/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 298.9355 - mean_squared_error: 298.9355 - val_loss: 297.7919 - val_mean_squared_error: 297.7919\n",
      "Epoch 52/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 300.7979 - mean_squared_error: 300.7979 - val_loss: 337.5101 - val_mean_squared_error: 337.5101\n",
      "Epoch 53/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 298.3954 - mean_squared_error: 298.3954 - val_loss: 273.3911 - val_mean_squared_error: 273.3911\n",
      "Epoch 54/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 292.5292 - mean_squared_error: 292.5292 - val_loss: 276.8167 - val_mean_squared_error: 276.8167\n",
      "Epoch 55/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 292.3309 - mean_squared_error: 292.3309 - val_loss: 267.8631 - val_mean_squared_error: 267.8631\n",
      "Epoch 56/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 292.0440 - mean_squared_error: 292.0440 - val_loss: 262.1461 - val_mean_squared_error: 262.1461\n",
      "Epoch 57/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 290.1494 - mean_squared_error: 290.1494 - val_loss: 275.9078 - val_mean_squared_error: 275.9078\n",
      "Epoch 58/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 285.8513 - mean_squared_error: 285.8513 - val_loss: 267.1221 - val_mean_squared_error: 267.1221\n",
      "Epoch 59/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 287.2313 - mean_squared_error: 287.2313 - val_loss: 294.5664 - val_mean_squared_error: 294.5664\n",
      "Epoch 60/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 284.9290 - mean_squared_error: 284.9290 - val_loss: 277.8280 - val_mean_squared_error: 277.8280\n",
      "Epoch 61/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 286.4188 - mean_squared_error: 286.4188 - val_loss: 265.9456 - val_mean_squared_error: 265.9456\n",
      "Epoch 62/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 278.8408 - mean_squared_error: 278.8408 - val_loss: 263.7941 - val_mean_squared_error: 263.7941\n",
      "Epoch 63/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 280.8362 - mean_squared_error: 280.8362 - val_loss: 270.6490 - val_mean_squared_error: 270.6490\n",
      "Epoch 64/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 279.3054 - mean_squared_error: 279.3054 - val_loss: 276.3576 - val_mean_squared_error: 276.3576\n",
      "Epoch 65/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 275.9023 - mean_squared_error: 275.9023 - val_loss: 272.5247 - val_mean_squared_error: 272.5247\n",
      "Epoch 66/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 276.2580 - mean_squared_error: 276.2580 - val_loss: 250.6438 - val_mean_squared_error: 250.6438\n",
      "Epoch 67/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 255.7660 - mean_squared_error: 255.7660 - val_loss: 232.9795 - val_mean_squared_error: 232.9795\n",
      "Epoch 68/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 247.5831 - mean_squared_error: 247.5831 - val_loss: 231.9118 - val_mean_squared_error: 231.9118\n",
      "Epoch 69/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 246.0141 - mean_squared_error: 246.0141 - val_loss: 231.8582 - val_mean_squared_error: 231.8582\n",
      "Epoch 70/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 244.0115 - mean_squared_error: 244.0115 - val_loss: 227.4617 - val_mean_squared_error: 227.4617\n",
      "Epoch 71/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 243.5245 - mean_squared_error: 243.5245 - val_loss: 227.8982 - val_mean_squared_error: 227.8982\n",
      "Epoch 72/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 242.3329 - mean_squared_error: 242.3329 - val_loss: 227.1414 - val_mean_squared_error: 227.1414\n",
      "Epoch 73/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 243.2278 - mean_squared_error: 243.2278 - val_loss: 226.8935 - val_mean_squared_error: 226.8935\n",
      "Epoch 74/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 237.6084 - mean_squared_error: 237.6084 - val_loss: 229.0011 - val_mean_squared_error: 229.0011\n",
      "Epoch 75/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 240.6075 - mean_squared_error: 240.6075 - val_loss: 229.1235 - val_mean_squared_error: 229.1235\n",
      "Epoch 76/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 237.4463 - mean_squared_error: 237.4463 - val_loss: 229.5701 - val_mean_squared_error: 229.5701\n",
      "Epoch 77/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 240.0894 - mean_squared_error: 240.0894 - val_loss: 228.7539 - val_mean_squared_error: 228.7539\n",
      "Epoch 78/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 236.2106 - mean_squared_error: 236.2106 - val_loss: 225.2443 - val_mean_squared_error: 225.2443\n",
      "Epoch 79/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 237.5255 - mean_squared_error: 237.5255 - val_loss: 222.7327 - val_mean_squared_error: 222.7327\n",
      "Epoch 80/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 232.7884 - mean_squared_error: 232.7884 - val_loss: 228.9604 - val_mean_squared_error: 228.9604\n",
      "Epoch 81/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 234.4770 - mean_squared_error: 234.4770 - val_loss: 224.7555 - val_mean_squared_error: 224.7555\n",
      "Epoch 82/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 235.0579 - mean_squared_error: 235.0579 - val_loss: 225.5073 - val_mean_squared_error: 225.5073\n",
      "Epoch 83/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 237.2015 - mean_squared_error: 237.2015 - val_loss: 225.2496 - val_mean_squared_error: 225.2496\n",
      "Epoch 84/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 230.1623 - mean_squared_error: 230.1623 - val_loss: 222.5431 - val_mean_squared_error: 222.5431\n",
      "Epoch 85/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 229.7310 - mean_squared_error: 229.7310 - val_loss: 222.3163 - val_mean_squared_error: 222.3163\n",
      "Epoch 86/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 232.5112 - mean_squared_error: 232.5112 - val_loss: 221.7722 - val_mean_squared_error: 221.7722\n",
      "Epoch 87/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 230.8266 - mean_squared_error: 230.8266 - val_loss: 222.6943 - val_mean_squared_error: 222.6943\n",
      "Epoch 88/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 230.0187 - mean_squared_error: 230.0187 - val_loss: 221.8131 - val_mean_squared_error: 221.8131\n",
      "Epoch 89/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 230.5078 - mean_squared_error: 230.5078 - val_loss: 221.6590 - val_mean_squared_error: 221.6590\n",
      "Epoch 90/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 227.9765 - mean_squared_error: 227.9765 - val_loss: 221.9409 - val_mean_squared_error: 221.9409\n",
      "Epoch 91/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 228.2453 - mean_squared_error: 228.2453 - val_loss: 221.6786 - val_mean_squared_error: 221.6786\n",
      "Epoch 92/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 231.5399 - mean_squared_error: 231.5399 - val_loss: 222.0626 - val_mean_squared_error: 222.0626\n",
      "Epoch 93/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 228.2758 - mean_squared_error: 228.2758 - val_loss: 221.7195 - val_mean_squared_error: 221.7195\n",
      "Epoch 94/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 227.7611 - mean_squared_error: 227.7611 - val_loss: 221.8991 - val_mean_squared_error: 221.8991\n",
      "Epoch 95/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 226.6840 - mean_squared_error: 226.6840 - val_loss: 221.8468 - val_mean_squared_error: 221.8468\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 2s 8ms/step - loss: 226.9651 - mean_squared_error: 226.9651 - val_loss: 221.9445 - val_mean_squared_error: 221.9445\n",
      "Epoch 97/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 228.0954 - mean_squared_error: 228.0954 - val_loss: 222.0982 - val_mean_squared_error: 222.0982\n",
      "Epoch 98/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 227.0300 - mean_squared_error: 227.0300 - val_loss: 221.7837 - val_mean_squared_error: 221.7837\n",
      "Epoch 99/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 226.9053 - mean_squared_error: 226.9053 - val_loss: 221.7094 - val_mean_squared_error: 221.7094\n",
      "Epoch 100/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 227.4608 - mean_squared_error: 227.4608 - val_loss: 222.3421 - val_mean_squared_error: 222.3421\n"
     ]
    }
   ],
   "source": [
    "# model = Net1()\n",
    "model = Net3()\n",
    "\n",
    "runLen = 100    \n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    part1 = 2*runLen//3\n",
    "    part2 = 5*runLen//6 #net1\n",
    "\n",
    "#     part1 = runLen//3\n",
    "#     part2 = 2*runLen//3 #net2\n",
    "\n",
    "    if epoch < part1:\n",
    "        lr = 0.01\n",
    "        return lr\n",
    "    if epoch >= part1 and epoch < part2:\n",
    "        lr = 0.001\n",
    "        return lr\n",
    "    if epoch >= part2:\n",
    "        lr = 0.0001\n",
    "        return lr\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.MeanSquaredError()],)\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)\n",
    "\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "#for 1M linear dataset\n",
    "# trace = model.fit(x=x_train, y=y_train, batch_size=128, epochs=runLen, verbose=1, \n",
    "#                   validation_split=0.1, callbacks = [callback], shuffle=True) \n",
    "#New Changes- added 512 conv layer to network #Increases performance drastically (reaches val error of 89.0 in <30 epoch) \n",
    "#             adding another layer of 1024 (reaches val error of ~81.5 in <30 epoch)\n",
    "\n",
    "trace = model.fit(x=x_train, y=y_train, batch_size=32, epochs=runLen, verbose=1, \n",
    "                  validation_split=0.1, callbacks = [callback], shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "promotional-howard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.0, 1000.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(trace.history['loss'], '-')\n",
    "plt.plot(trace.history['val_loss'], '-')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim(10,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model- IMPORTANT TO USE NEVER BEFORE SEEN DATA\n",
    "\n",
    "#from train data (not ideal to use for testing)\n",
    "# prediction = model.predict(x_train[-1000:-1])\n",
    "# actual = y_train[-1000:-1]\n",
    "\n",
    "#x_data\n",
    "trajTest = np.loadtxt(open(\"simulation/data/traj_2sec.txt\", \"rb\"), delimiter=\",\")\n",
    "trajPtsTest = np.shape(trajTest)[0] #points per test trajectory\n",
    "numTrajTest = np.shape(trajTest)[1]//3 #number of test trajectories\n",
    "tTest = np.zeros([trajPtsTest,3,numTrajTest])\n",
    "for j in range(np.shape(trajTest)[0]):\n",
    "    for i in range(np.shape(trajTest)[1]//3):\n",
    "        tTest[j,:,i] = trajTest[j,3*i:3*(i+1)]\n",
    "#swap axis so batch size is first axis (for TF)\n",
    "tTest = np.swapaxes(tTest,0,2)\n",
    "#swap axis again so that conv1D moves on time and not xyz\n",
    "tTest = np.swapaxes(tTest,1,2)\n",
    "x_test = tf.convert_to_tensor(tTest,np.float32)\n",
    "\n",
    "#y_data\n",
    "jointPosTest = np.loadtxt(open(\"simulation/data/jointPos_2sec.txt\", \"rb\"), delimiter=\",\")\n",
    "y_test = tf.convert_to_tensor(jointPosTest,np.float32)\n",
    "\n",
    "prediction = model.predict(x_test)\n",
    "error = (y_test - prediction)\n",
    "# print(np.floor(error))\n",
    "\n",
    "#average error for estimates for each joint\n",
    "avg = np.average(abs(error),axis=0)\n",
    "print(\"average error = \", avg)\n",
    "\n",
    "#range for each joint:\n",
    "ranges = [50, 60, 67.5, 110, 120, 360, 130]\n",
    "rel_error = avg/ranges\n",
    "print(\"error as frac of joint range = \", np.floor(rel_error*1000)/1000) #1 is full range of joint\n",
    "print(\"total error = \",sum(rel_error))\n",
    "\n",
    "#current best for network 1 is: \n",
    "#                 0.438 @ [0.09  0.082 0.034 0.086 0.061 0.024 0.058]\n",
    "#                 val_error: 81.84\n",
    "\n",
    "print(prediction[-10])\n",
    "print(y_test[-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"trajectory_cls.kmod\")\n",
    "\n",
    "# model.save(\"trajectory_random_forces_cls.kmod\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best scoring model for 1M dataset\n",
    "\n",
    "model = tf.keras.models.load_model(\"trajectory_cls.kmod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proof my model is doing better than completely random guessing\n",
    "\n",
    "np.random.seed(None)\n",
    "\n",
    "# print(actual)\n",
    "# print(tf.shape(actual)) #[99 7]\n",
    "B = tf.random.uniform([1000,7])\n",
    "\n",
    "# B = tf.ones([99,7])\n",
    "B = B *tf.constant([25., 30., 33.75, 55. , 60., 180., 65.]) + tf.constant([0., 0., 26.25, -35., 30., 0., -65.])\n",
    "\n",
    "# print(tf.shape(B))\n",
    "# print(tf.shape(actual))\n",
    "\n",
    "fake_error = (y_test - B)\n",
    "# print(fake_error)\n",
    "\n",
    "fake_avg = tf.math.reduce_mean(tf.math.abs(fake_error), axis=0)\n",
    "print(fake_avg)\n",
    "\n",
    "rel_fake_error = fake_avg/ranges\n",
    "\n",
    "print(\"error as frac of joint range: \",rel_fake_error)\n",
    "print(\"total error: \", sum(rel_fake_error))\n",
    "\n",
    "#NOTE: these are not all the same becuase the starting ranges for joint positions do NOT fall in the middle of all\n",
    "#      possible positions for each joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-punishment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn",
   "language": "python",
   "name": "dnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
