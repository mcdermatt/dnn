{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "random-brick",
   "metadata": {},
   "source": [
    "# Novel Inertia Based Human Pose Estimation Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imported-conjunction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from utils import *\n",
    "\n",
    "#need to have these two lines to work on my ancient 1060 3gb\n",
    "#  https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "genetic-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data from MatLab SimScape Multibody Simulator\n",
    "\n",
    "#data comes from two files\n",
    "#1) n trajectories in xyz space, each length m\n",
    "traj = np.loadtxt(open(\"simulation/data/traj100k.txt\", \"rb\"), delimiter=\",\")\n",
    "trajPts = np.shape(traj)[0] #points per trajectory\n",
    "numTraj = np.shape(traj)[1]//3 #number of total trajectories\n",
    "#traj needs to be reshaped to a 3d numpy array\n",
    "#as is traj[n] shows [x,y,z,x,y,z...]\n",
    "\n",
    "\n",
    "#2) 7 joint angles at the end of the sequence\n",
    "jointPos = np.loadtxt(open(\"simulation/data/jointPos100k.txt\", \"rb\"), delimiter=\",\")\n",
    "\n",
    "# print(traj[-1])\n",
    "# print(jointPos[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pleased-johnston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3, 100000)\n",
      "(100000, 3, 10)\n",
      "(100000, 10, 3)\n"
     ]
    }
   ],
   "source": [
    "#reshape traj data into 3d numpy array\n",
    "# print(np.shape(traj)) #(10,30) -> should be (10,3,10)\n",
    "t = np.zeros([trajPts,3,numTraj])\n",
    "for j in range(np.shape(traj)[0]):\n",
    "    for i in range(np.shape(traj)[1]//3):\n",
    "        t[j,:,i] = traj[j,3*i:3*(i+1)]\n",
    "# print(t[:,:,0]) #same as in MatLab\n",
    "print(np.shape(t))\n",
    "#swap axis so batch size is first axis (for TF)\n",
    "t = np.swapaxes(t,0,2)\n",
    "print(np.shape(t)) #[numTraj, xyz, trajPts]\n",
    "#swap axis again so that conv1D moves on time and not xyz\n",
    "t = np.swapaxes(t,1,2)\n",
    "print(np.shape(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceramic-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert data from numpy to tensors\n",
    "\n",
    "#shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "upset-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import Net\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "#convert data from numpy to tensors\n",
    "x_train = tf.convert_to_tensor(t,np.float32)\n",
    "y_train = tf.convert_to_tensor(jointPos,np.float32)\n",
    "\n",
    "#TODO -> shuffle data\n",
    "\n",
    "\n",
    "# print(tf.shape(x_train))\n",
    "# print(x_train[0,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "altered-administration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 10, 3)        12          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 8, 16)        160         batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 8, 16)        784         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8, 16)        64          conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 8, 16)        784         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 8, 16)        64          conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity (TensorFlo [(None, 8, 16)]      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 8, 16)        0           batch_normalization_2[0][0]      \n",
      "                                                                 tf_op_layer_Identity[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 8, 16)        0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 8, 32)        1568        re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 32)        128         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 8, 32)        3104        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 8, 32)        128         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_1 (TensorF [(None, 8, 32)]      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 8, 32)        0           batch_normalization_4[0][0]      \n",
      "                                                                 tf_op_layer_Identity_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 8, 32)        0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 8, 64)        6208        re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 8, 64)        256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 8, 64)        12352       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 64)        256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_2 (TensorF [(None, 8, 64)]      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 8, 64)        0           batch_normalization_6[0][0]      \n",
      "                                                                 tf_op_layer_Identity_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 8, 64)        0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 8, 128)       24704       re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 128)       512         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 8, 128)       49280       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 128)       512         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_3 (TensorF [(None, 8, 128)]     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 128)       0           batch_normalization_8[0][0]      \n",
      "                                                                 tf_op_layer_Identity_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 8, 128)       0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           65600       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64)           256         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64)           256         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           4160        batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64)           256         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 7)            455         batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None, 7)]          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 7)]          0           tf_op_layer_Mul[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 176,019\n",
      "Trainable params: 174,669\n",
      "Non-trainable params: 1,350\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 3s 9ms/step - loss: 699.0064 - mean_squared_error: 699.0064 - val_loss: 675.3813 - val_mean_squared_error: 675.3813\n",
      "Epoch 2/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 537.5065 - mean_squared_error: 537.5065 - val_loss: 496.7490 - val_mean_squared_error: 496.7490\n",
      "Epoch 3/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 501.6385 - mean_squared_error: 501.6385 - val_loss: 591.4052 - val_mean_squared_error: 591.4052\n",
      "Epoch 4/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 464.3881 - mean_squared_error: 464.3881 - val_loss: 490.9832 - val_mean_squared_error: 490.9832\n",
      "Epoch 5/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 449.9445 - mean_squared_error: 449.9445 - val_loss: 604.8453 - val_mean_squared_error: 604.8453\n",
      "Epoch 6/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 425.9848 - mean_squared_error: 425.9848 - val_loss: 427.4637 - val_mean_squared_error: 427.4637\n",
      "Epoch 7/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 502.9511 - mean_squared_error: 502.9511 - val_loss: 506.1465 - val_mean_squared_error: 506.1465\n",
      "Epoch 8/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 447.6345 - mean_squared_error: 447.6345 - val_loss: 463.8899 - val_mean_squared_error: 463.8899\n",
      "Epoch 9/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 399.3656 - mean_squared_error: 399.3656 - val_loss: 417.4738 - val_mean_squared_error: 417.4738\n",
      "Epoch 10/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 370.1931 - mean_squared_error: 370.1931 - val_loss: 406.3777 - val_mean_squared_error: 406.3777\n",
      "Epoch 11/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 350.8335 - mean_squared_error: 350.8335 - val_loss: 372.5209 - val_mean_squared_error: 372.5209\n",
      "Epoch 12/300\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 337.2937 - mean_squared_error: 337.2937 - val_loss: 364.5063 - val_mean_squared_error: 364.5063\n",
      "Epoch 13/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 323.3938 - mean_squared_error: 323.3938 - val_loss: 356.0136 - val_mean_squared_error: 356.0136\n",
      "Epoch 14/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 312.3658 - mean_squared_error: 312.3658 - val_loss: 347.1228 - val_mean_squared_error: 347.1228\n",
      "Epoch 15/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 303.0666 - mean_squared_error: 303.0666 - val_loss: 358.4788 - val_mean_squared_error: 358.4788\n",
      "Epoch 16/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 294.2763 - mean_squared_error: 294.2763 - val_loss: 343.2042 - val_mean_squared_error: 343.2042\n",
      "Epoch 17/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 288.7580 - mean_squared_error: 288.7580 - val_loss: 316.0027 - val_mean_squared_error: 316.0027\n",
      "Epoch 18/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 280.9323 - mean_squared_error: 280.9323 - val_loss: 314.9612 - val_mean_squared_error: 314.9612\n",
      "Epoch 19/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 273.5871 - mean_squared_error: 273.5871 - val_loss: 309.4040 - val_mean_squared_error: 309.4040\n",
      "Epoch 20/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 268.6456 - mean_squared_error: 268.6456 - val_loss: 293.6851 - val_mean_squared_error: 293.6851\n",
      "Epoch 21/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 262.3123 - mean_squared_error: 262.3123 - val_loss: 292.3130 - val_mean_squared_error: 292.3130\n",
      "Epoch 22/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 257.8088 - mean_squared_error: 257.8088 - val_loss: 290.7302 - val_mean_squared_error: 290.7302\n",
      "Epoch 23/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 253.6413 - mean_squared_error: 253.6413 - val_loss: 282.3686 - val_mean_squared_error: 282.3686\n",
      "Epoch 24/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 249.5590 - mean_squared_error: 249.5590 - val_loss: 273.3298 - val_mean_squared_error: 273.3298\n",
      "Epoch 25/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 244.9884 - mean_squared_error: 244.9884 - val_loss: 303.0345 - val_mean_squared_error: 303.0345\n",
      "Epoch 26/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 239.4262 - mean_squared_error: 239.4262 - val_loss: 259.9197 - val_mean_squared_error: 259.9197\n",
      "Epoch 27/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 236.4348 - mean_squared_error: 236.4348 - val_loss: 274.9834 - val_mean_squared_error: 274.9834\n",
      "Epoch 28/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 233.3637 - mean_squared_error: 233.3637 - val_loss: 260.9924 - val_mean_squared_error: 260.9924\n",
      "Epoch 29/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 227.3602 - mean_squared_error: 227.3602 - val_loss: 258.5745 - val_mean_squared_error: 258.5745\n",
      "Epoch 30/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 225.1042 - mean_squared_error: 225.1042 - val_loss: 284.2780 - val_mean_squared_error: 284.2780\n",
      "Epoch 31/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 221.4742 - mean_squared_error: 221.4742 - val_loss: 256.6599 - val_mean_squared_error: 256.6599\n",
      "Epoch 32/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 218.2724 - mean_squared_error: 218.2724 - val_loss: 256.3929 - val_mean_squared_error: 256.3929\n",
      "Epoch 33/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 213.8689 - mean_squared_error: 213.8689 - val_loss: 249.2648 - val_mean_squared_error: 249.2648\n",
      "Epoch 34/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 212.9669 - mean_squared_error: 212.9669 - val_loss: 258.8079 - val_mean_squared_error: 258.8079\n",
      "Epoch 35/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 210.8960 - mean_squared_error: 210.8960 - val_loss: 249.6953 - val_mean_squared_error: 249.6953\n",
      "Epoch 36/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 205.0279 - mean_squared_error: 205.0279 - val_loss: 238.4080 - val_mean_squared_error: 238.4080\n",
      "Epoch 37/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 203.6566 - mean_squared_error: 203.6566 - val_loss: 248.2744 - val_mean_squared_error: 248.2744\n",
      "Epoch 38/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 201.1975 - mean_squared_error: 201.1975 - val_loss: 237.8434 - val_mean_squared_error: 237.8434\n",
      "Epoch 39/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 199.4464 - mean_squared_error: 199.4464 - val_loss: 253.2326 - val_mean_squared_error: 253.2326\n",
      "Epoch 40/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 195.8124 - mean_squared_error: 195.8124 - val_loss: 262.1244 - val_mean_squared_error: 262.1244\n",
      "Epoch 41/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 196.1084 - mean_squared_error: 196.1084 - val_loss: 238.3111 - val_mean_squared_error: 238.3111\n",
      "Epoch 42/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 192.6280 - mean_squared_error: 192.6280 - val_loss: 252.0703 - val_mean_squared_error: 252.0703\n",
      "Epoch 43/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 190.7710 - mean_squared_error: 190.7710 - val_loss: 241.8427 - val_mean_squared_error: 241.8427\n",
      "Epoch 44/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 187.7666 - mean_squared_error: 187.7666 - val_loss: 233.6060 - val_mean_squared_error: 233.6060\n",
      "Epoch 45/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 187.5336 - mean_squared_error: 187.5336 - val_loss: 231.2883 - val_mean_squared_error: 231.2883\n",
      "Epoch 46/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 183.8192 - mean_squared_error: 183.8192 - val_loss: 234.4324 - val_mean_squared_error: 234.4324\n",
      "Epoch 47/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 182.7914 - mean_squared_error: 182.7914 - val_loss: 230.4696 - val_mean_squared_error: 230.4696\n",
      "Epoch 48/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 180.9113 - mean_squared_error: 180.9113 - val_loss: 230.5518 - val_mean_squared_error: 230.5518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 179.5131 - mean_squared_error: 179.5131 - val_loss: 238.8640 - val_mean_squared_error: 238.8640\n",
      "Epoch 50/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 177.5769 - mean_squared_error: 177.5769 - val_loss: 230.4238 - val_mean_squared_error: 230.4238\n",
      "Epoch 51/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 176.6440 - mean_squared_error: 176.6440 - val_loss: 228.3163 - val_mean_squared_error: 228.3163\n",
      "Epoch 52/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 176.2540 - mean_squared_error: 176.2540 - val_loss: 223.2504 - val_mean_squared_error: 223.2504\n",
      "Epoch 53/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 173.7872 - mean_squared_error: 173.7872 - val_loss: 222.2379 - val_mean_squared_error: 222.2379\n",
      "Epoch 54/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 172.0649 - mean_squared_error: 172.0649 - val_loss: 231.0499 - val_mean_squared_error: 231.0499\n",
      "Epoch 55/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 170.8758 - mean_squared_error: 170.8758 - val_loss: 228.8283 - val_mean_squared_error: 228.8283\n",
      "Epoch 56/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 168.6723 - mean_squared_error: 168.6723 - val_loss: 229.0699 - val_mean_squared_error: 229.0699\n",
      "Epoch 57/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 166.7420 - mean_squared_error: 166.7420 - val_loss: 226.5528 - val_mean_squared_error: 226.5528\n",
      "Epoch 58/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 166.1896 - mean_squared_error: 166.1896 - val_loss: 236.3601 - val_mean_squared_error: 236.3601\n",
      "Epoch 59/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 165.0212 - mean_squared_error: 165.0212 - val_loss: 229.2083 - val_mean_squared_error: 229.2083\n",
      "Epoch 60/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 164.4400 - mean_squared_error: 164.4400 - val_loss: 224.6306 - val_mean_squared_error: 224.6306\n",
      "Epoch 61/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 164.1677 - mean_squared_error: 164.1677 - val_loss: 232.0996 - val_mean_squared_error: 232.0996\n",
      "Epoch 62/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 161.6342 - mean_squared_error: 161.6342 - val_loss: 222.6140 - val_mean_squared_error: 222.6140\n",
      "Epoch 63/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 160.6510 - mean_squared_error: 160.6510 - val_loss: 239.5246 - val_mean_squared_error: 239.5246\n",
      "Epoch 64/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 159.5771 - mean_squared_error: 159.5771 - val_loss: 221.4772 - val_mean_squared_error: 221.4772\n",
      "Epoch 65/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 158.7366 - mean_squared_error: 158.7366 - val_loss: 219.6143 - val_mean_squared_error: 219.6143\n",
      "Epoch 66/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 157.2595 - mean_squared_error: 157.2595 - val_loss: 220.3106 - val_mean_squared_error: 220.3106\n",
      "Epoch 67/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 155.6823 - mean_squared_error: 155.6823 - val_loss: 224.1572 - val_mean_squared_error: 224.1572\n",
      "Epoch 68/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 155.6990 - mean_squared_error: 155.6990 - val_loss: 225.2036 - val_mean_squared_error: 225.2036\n",
      "Epoch 69/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 154.3845 - mean_squared_error: 154.3845 - val_loss: 221.4396 - val_mean_squared_error: 221.4396\n",
      "Epoch 70/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 152.9495 - mean_squared_error: 152.9495 - val_loss: 242.8972 - val_mean_squared_error: 242.8972\n",
      "Epoch 71/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 153.2776 - mean_squared_error: 153.2776 - val_loss: 231.5657 - val_mean_squared_error: 231.5657\n",
      "Epoch 72/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 151.5606 - mean_squared_error: 151.5606 - val_loss: 218.7269 - val_mean_squared_error: 218.7269\n",
      "Epoch 73/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 151.4694 - mean_squared_error: 151.4694 - val_loss: 225.0455 - val_mean_squared_error: 225.0455\n",
      "Epoch 74/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 150.3576 - mean_squared_error: 150.3576 - val_loss: 217.0132 - val_mean_squared_error: 217.0132\n",
      "Epoch 75/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 147.8004 - mean_squared_error: 147.8004 - val_loss: 229.8156 - val_mean_squared_error: 229.8156\n",
      "Epoch 76/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 148.2128 - mean_squared_error: 148.2128 - val_loss: 226.4264 - val_mean_squared_error: 226.4264\n",
      "Epoch 77/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 147.7018 - mean_squared_error: 147.7018 - val_loss: 217.9920 - val_mean_squared_error: 217.9920\n",
      "Epoch 78/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 146.4738 - mean_squared_error: 146.4738 - val_loss: 221.9958 - val_mean_squared_error: 221.9958\n",
      "Epoch 79/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 145.4997 - mean_squared_error: 145.4997 - val_loss: 225.5678 - val_mean_squared_error: 225.5678\n",
      "Epoch 80/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 145.1441 - mean_squared_error: 145.1441 - val_loss: 229.4605 - val_mean_squared_error: 229.4605\n",
      "Epoch 81/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 145.0484 - mean_squared_error: 145.0484 - val_loss: 215.3870 - val_mean_squared_error: 215.3870\n",
      "Epoch 82/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 143.3344 - mean_squared_error: 143.3344 - val_loss: 220.8898 - val_mean_squared_error: 220.8898\n",
      "Epoch 83/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 142.6570 - mean_squared_error: 142.6570 - val_loss: 221.5711 - val_mean_squared_error: 221.5711\n",
      "Epoch 84/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 142.3516 - mean_squared_error: 142.3516 - val_loss: 222.1428 - val_mean_squared_error: 222.1428\n",
      "Epoch 85/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 141.5849 - mean_squared_error: 141.5849 - val_loss: 216.0214 - val_mean_squared_error: 216.0214\n",
      "Epoch 86/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 140.0243 - mean_squared_error: 140.0243 - val_loss: 213.6674 - val_mean_squared_error: 213.6674\n",
      "Epoch 87/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 140.5266 - mean_squared_error: 140.5266 - val_loss: 217.9135 - val_mean_squared_error: 217.9135\n",
      "Epoch 88/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 139.2501 - mean_squared_error: 139.2501 - val_loss: 218.4294 - val_mean_squared_error: 218.4294\n",
      "Epoch 89/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 139.0158 - mean_squared_error: 139.0158 - val_loss: 217.5866 - val_mean_squared_error: 217.5866\n",
      "Epoch 90/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 137.4956 - mean_squared_error: 137.4956 - val_loss: 217.3951 - val_mean_squared_error: 217.3951\n",
      "Epoch 91/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 138.7047 - mean_squared_error: 138.7047 - val_loss: 222.1651 - val_mean_squared_error: 222.1651\n",
      "Epoch 92/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 136.8546 - mean_squared_error: 136.8546 - val_loss: 218.5249 - val_mean_squared_error: 218.5249\n",
      "Epoch 93/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 136.4356 - mean_squared_error: 136.4356 - val_loss: 212.2095 - val_mean_squared_error: 212.2095\n",
      "Epoch 94/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 135.2756 - mean_squared_error: 135.2756 - val_loss: 219.6910 - val_mean_squared_error: 219.6910\n",
      "Epoch 95/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 135.3106 - mean_squared_error: 135.3106 - val_loss: 226.1321 - val_mean_squared_error: 226.1321\n",
      "Epoch 96/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 3s 8ms/step - loss: 134.0785 - mean_squared_error: 134.0785 - val_loss: 213.7306 - val_mean_squared_error: 213.7306\n",
      "Epoch 97/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 134.5246 - mean_squared_error: 134.5246 - val_loss: 216.9158 - val_mean_squared_error: 216.9158\n",
      "Epoch 98/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 134.7344 - mean_squared_error: 134.7344 - val_loss: 223.7167 - val_mean_squared_error: 223.7167\n",
      "Epoch 99/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 131.8088 - mean_squared_error: 131.8088 - val_loss: 216.6779 - val_mean_squared_error: 216.6779\n",
      "Epoch 100/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 133.5522 - mean_squared_error: 133.5522 - val_loss: 216.3427 - val_mean_squared_error: 216.3427\n",
      "Epoch 101/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 112.2862 - mean_squared_error: 112.2862 - val_loss: 196.2647 - val_mean_squared_error: 196.2647\n",
      "Epoch 102/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 107.4057 - mean_squared_error: 107.4057 - val_loss: 197.0661 - val_mean_squared_error: 197.0661\n",
      "Epoch 103/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 105.5008 - mean_squared_error: 105.5008 - val_loss: 197.5384 - val_mean_squared_error: 197.5384\n",
      "Epoch 104/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 104.5357 - mean_squared_error: 104.5357 - val_loss: 196.7221 - val_mean_squared_error: 196.7221\n",
      "Epoch 105/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 103.7075 - mean_squared_error: 103.7075 - val_loss: 198.3908 - val_mean_squared_error: 198.3908\n",
      "Epoch 106/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 102.7708 - mean_squared_error: 102.7708 - val_loss: 197.6181 - val_mean_squared_error: 197.6181\n",
      "Epoch 107/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 102.4075 - mean_squared_error: 102.4075 - val_loss: 197.5336 - val_mean_squared_error: 197.5336\n",
      "Epoch 108/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 101.8895 - mean_squared_error: 101.8895 - val_loss: 197.1182 - val_mean_squared_error: 197.1182\n",
      "Epoch 109/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 102.5140 - mean_squared_error: 102.5140 - val_loss: 198.5377 - val_mean_squared_error: 198.5377\n",
      "Epoch 110/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 100.9611 - mean_squared_error: 100.9611 - val_loss: 198.5285 - val_mean_squared_error: 198.5285\n",
      "Epoch 111/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 100.5436 - mean_squared_error: 100.5436 - val_loss: 196.7220 - val_mean_squared_error: 196.7220\n",
      "Epoch 112/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 100.8180 - mean_squared_error: 100.8180 - val_loss: 198.5246 - val_mean_squared_error: 198.5246\n",
      "Epoch 113/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 100.4233 - mean_squared_error: 100.4233 - val_loss: 198.9682 - val_mean_squared_error: 198.9682\n",
      "Epoch 114/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 99.7987 - mean_squared_error: 99.7987 - val_loss: 199.0366 - val_mean_squared_error: 199.0366\n",
      "Epoch 115/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 99.7730 - mean_squared_error: 99.7730 - val_loss: 199.1849 - val_mean_squared_error: 199.1849\n",
      "Epoch 116/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 100.0770 - mean_squared_error: 100.0770 - val_loss: 199.3894 - val_mean_squared_error: 199.3894\n",
      "Epoch 117/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 99.2370 - mean_squared_error: 99.2370 - val_loss: 199.7357 - val_mean_squared_error: 199.7357\n",
      "Epoch 118/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 98.9145 - mean_squared_error: 98.9145 - val_loss: 200.0063 - val_mean_squared_error: 200.0063\n",
      "Epoch 119/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 98.8262 - mean_squared_error: 98.8262 - val_loss: 198.5830 - val_mean_squared_error: 198.5830\n",
      "Epoch 120/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 98.8838 - mean_squared_error: 98.8838 - val_loss: 199.4659 - val_mean_squared_error: 199.4659\n",
      "Epoch 121/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 98.9469 - mean_squared_error: 98.9469 - val_loss: 199.0988 - val_mean_squared_error: 199.0988\n",
      "Epoch 122/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 98.2326 - mean_squared_error: 98.2326 - val_loss: 199.5204 - val_mean_squared_error: 199.5204\n",
      "Epoch 123/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 98.1294 - mean_squared_error: 98.1294 - val_loss: 200.7875 - val_mean_squared_error: 200.7875\n",
      "Epoch 124/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 98.0915 - mean_squared_error: 98.0915 - val_loss: 200.5963 - val_mean_squared_error: 200.5963\n",
      "Epoch 125/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 97.6479 - mean_squared_error: 97.6479 - val_loss: 200.8120 - val_mean_squared_error: 200.8120\n",
      "Epoch 126/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 97.6302 - mean_squared_error: 97.6302 - val_loss: 199.9166 - val_mean_squared_error: 199.9166\n",
      "Epoch 127/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 97.5237 - mean_squared_error: 97.5237 - val_loss: 200.2181 - val_mean_squared_error: 200.2181\n",
      "Epoch 128/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 97.0036 - mean_squared_error: 97.0036 - val_loss: 201.7934 - val_mean_squared_error: 201.7934\n",
      "Epoch 129/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 97.5389 - mean_squared_error: 97.5389 - val_loss: 200.8623 - val_mean_squared_error: 200.8623\n",
      "Epoch 130/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 97.1556 - mean_squared_error: 97.1556 - val_loss: 200.5151 - val_mean_squared_error: 200.5151\n",
      "Epoch 131/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 96.9336 - mean_squared_error: 96.9336 - val_loss: 200.5053 - val_mean_squared_error: 200.5053\n",
      "Epoch 132/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 96.1229 - mean_squared_error: 96.1229 - val_loss: 200.3162 - val_mean_squared_error: 200.3162\n",
      "Epoch 133/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 96.0475 - mean_squared_error: 96.0475 - val_loss: 199.9390 - val_mean_squared_error: 199.9390\n",
      "Epoch 134/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 96.1398 - mean_squared_error: 96.1398 - val_loss: 201.6233 - val_mean_squared_error: 201.6233\n",
      "Epoch 135/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 96.4348 - mean_squared_error: 96.4348 - val_loss: 201.2478 - val_mean_squared_error: 201.2478\n",
      "Epoch 136/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 95.7098 - mean_squared_error: 95.7098 - val_loss: 201.3466 - val_mean_squared_error: 201.3466\n",
      "Epoch 137/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 96.0566 - mean_squared_error: 96.0566 - val_loss: 201.0218 - val_mean_squared_error: 201.0218\n",
      "Epoch 138/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 95.4601 - mean_squared_error: 95.4601 - val_loss: 201.1440 - val_mean_squared_error: 201.1440\n",
      "Epoch 139/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 95.0982 - mean_squared_error: 95.0982 - val_loss: 202.3189 - val_mean_squared_error: 202.3189\n",
      "Epoch 140/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 95.6368 - mean_squared_error: 95.6368 - val_loss: 201.0581 - val_mean_squared_error: 201.0581\n",
      "Epoch 141/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 95.2868 - mean_squared_error: 95.2868 - val_loss: 202.8084 - val_mean_squared_error: 202.8084\n",
      "Epoch 142/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 95.1117 - mean_squared_error: 95.1117 - val_loss: 202.4055 - val_mean_squared_error: 202.4055\n",
      "Epoch 143/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 94.7087 - mean_squared_error: 94.7087 - val_loss: 201.9637 - val_mean_squared_error: 201.9637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 94.7801 - mean_squared_error: 94.7801 - val_loss: 201.4345 - val_mean_squared_error: 201.4345\n",
      "Epoch 145/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 94.5551 - mean_squared_error: 94.5551 - val_loss: 202.2141 - val_mean_squared_error: 202.2141\n",
      "Epoch 146/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 94.5219 - mean_squared_error: 94.5219 - val_loss: 201.2598 - val_mean_squared_error: 201.2598\n",
      "Epoch 147/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 94.6449 - mean_squared_error: 94.6449 - val_loss: 201.3008 - val_mean_squared_error: 201.3008\n",
      "Epoch 148/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 94.3959 - mean_squared_error: 94.3959 - val_loss: 201.6476 - val_mean_squared_error: 201.6476\n",
      "Epoch 149/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 94.6078 - mean_squared_error: 94.6078 - val_loss: 202.0258 - val_mean_squared_error: 202.0258\n",
      "Epoch 150/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 94.3758 - mean_squared_error: 94.3758 - val_loss: 203.2323 - val_mean_squared_error: 203.2323\n",
      "Epoch 151/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 94.5077 - mean_squared_error: 94.5077 - val_loss: 202.5196 - val_mean_squared_error: 202.5196\n",
      "Epoch 152/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 93.6584 - mean_squared_error: 93.6584 - val_loss: 203.1001 - val_mean_squared_error: 203.1001\n",
      "Epoch 153/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 93.8899 - mean_squared_error: 93.8899 - val_loss: 202.3316 - val_mean_squared_error: 202.3316\n",
      "Epoch 154/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 92.9507 - mean_squared_error: 92.9507 - val_loss: 202.5497 - val_mean_squared_error: 202.5497\n",
      "Epoch 155/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 93.3971 - mean_squared_error: 93.3971 - val_loss: 202.7769 - val_mean_squared_error: 202.7769\n",
      "Epoch 156/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 93.9288 - mean_squared_error: 93.9288 - val_loss: 202.5187 - val_mean_squared_error: 202.5187\n",
      "Epoch 157/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 93.1779 - mean_squared_error: 93.1779 - val_loss: 203.9128 - val_mean_squared_error: 203.9128\n",
      "Epoch 158/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 93.1111 - mean_squared_error: 93.1111 - val_loss: 202.3584 - val_mean_squared_error: 202.3584\n",
      "Epoch 159/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 92.9686 - mean_squared_error: 92.9686 - val_loss: 203.6311 - val_mean_squared_error: 203.6311\n",
      "Epoch 160/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 93.0515 - mean_squared_error: 93.0515 - val_loss: 203.2281 - val_mean_squared_error: 203.2281\n",
      "Epoch 161/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 93.1886 - mean_squared_error: 93.1886 - val_loss: 204.0682 - val_mean_squared_error: 204.0682\n",
      "Epoch 162/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 92.6072 - mean_squared_error: 92.6072 - val_loss: 202.4586 - val_mean_squared_error: 202.4586\n",
      "Epoch 163/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 92.4026 - mean_squared_error: 92.4026 - val_loss: 205.8060 - val_mean_squared_error: 205.8060\n",
      "Epoch 164/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 92.5600 - mean_squared_error: 92.5600 - val_loss: 204.6221 - val_mean_squared_error: 204.6221\n",
      "Epoch 165/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 92.4079 - mean_squared_error: 92.4079 - val_loss: 205.1452 - val_mean_squared_error: 205.1452\n",
      "Epoch 166/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 91.8447 - mean_squared_error: 91.8447 - val_loss: 203.1881 - val_mean_squared_error: 203.1881\n",
      "Epoch 167/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 92.6167 - mean_squared_error: 92.6167 - val_loss: 203.4124 - val_mean_squared_error: 203.4124\n",
      "Epoch 168/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 92.0278 - mean_squared_error: 92.0278 - val_loss: 203.8513 - val_mean_squared_error: 203.8513\n",
      "Epoch 169/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 91.7521 - mean_squared_error: 91.7521 - val_loss: 204.2945 - val_mean_squared_error: 204.2945\n",
      "Epoch 170/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 92.5129 - mean_squared_error: 92.5129 - val_loss: 203.2740 - val_mean_squared_error: 203.2740\n",
      "Epoch 171/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 91.9685 - mean_squared_error: 91.9685 - val_loss: 203.6135 - val_mean_squared_error: 203.6135\n",
      "Epoch 172/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 91.5373 - mean_squared_error: 91.5373 - val_loss: 203.4016 - val_mean_squared_error: 203.4016\n",
      "Epoch 173/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 91.7536 - mean_squared_error: 91.7536 - val_loss: 205.7674 - val_mean_squared_error: 205.7674\n",
      "Epoch 174/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 91.9741 - mean_squared_error: 91.9741 - val_loss: 202.8305 - val_mean_squared_error: 202.8305\n",
      "Epoch 175/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 92.0399 - mean_squared_error: 92.0399 - val_loss: 204.9213 - val_mean_squared_error: 204.9213\n",
      "Epoch 176/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 91.9574 - mean_squared_error: 91.9574 - val_loss: 204.2357 - val_mean_squared_error: 204.2357\n",
      "Epoch 177/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 91.5756 - mean_squared_error: 91.5756 - val_loss: 204.4212 - val_mean_squared_error: 204.4212\n",
      "Epoch 178/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 90.8167 - mean_squared_error: 90.8167 - val_loss: 204.2485 - val_mean_squared_error: 204.2485\n",
      "Epoch 179/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 90.9451 - mean_squared_error: 90.9451 - val_loss: 204.8555 - val_mean_squared_error: 204.8555\n",
      "Epoch 180/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 91.6361 - mean_squared_error: 91.6361 - val_loss: 203.6006 - val_mean_squared_error: 203.6006\n",
      "Epoch 181/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 91.2163 - mean_squared_error: 91.2163 - val_loss: 204.3574 - val_mean_squared_error: 204.3574\n",
      "Epoch 182/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 90.7618 - mean_squared_error: 90.7618 - val_loss: 203.9317 - val_mean_squared_error: 203.9317\n",
      "Epoch 183/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 90.7544 - mean_squared_error: 90.7544 - val_loss: 204.5694 - val_mean_squared_error: 204.5694\n",
      "Epoch 184/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 90.3934 - mean_squared_error: 90.3934 - val_loss: 205.4728 - val_mean_squared_error: 205.4728\n",
      "Epoch 185/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 90.6307 - mean_squared_error: 90.6307 - val_loss: 204.5723 - val_mean_squared_error: 204.5723\n",
      "Epoch 186/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 90.4693 - mean_squared_error: 90.4693 - val_loss: 204.1431 - val_mean_squared_error: 204.1431\n",
      "Epoch 187/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 90.9114 - mean_squared_error: 90.9114 - val_loss: 205.2135 - val_mean_squared_error: 205.2135\n",
      "Epoch 188/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 90.9059 - mean_squared_error: 90.9059 - val_loss: 206.9491 - val_mean_squared_error: 206.9491\n",
      "Epoch 189/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 90.1377 - mean_squared_error: 90.1377 - val_loss: 205.4121 - val_mean_squared_error: 205.4121\n",
      "Epoch 190/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 89.5419 - mean_squared_error: 89.5419 - val_loss: 205.1933 - val_mean_squared_error: 205.1933\n",
      "Epoch 191/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 90.3930 - mean_squared_error: 90.3930 - val_loss: 206.1016 - val_mean_squared_error: 206.1016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 90.5410 - mean_squared_error: 90.5410 - val_loss: 204.9751 - val_mean_squared_error: 204.9751\n",
      "Epoch 193/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 90.0093 - mean_squared_error: 90.0093 - val_loss: 206.0442 - val_mean_squared_error: 206.0442\n",
      "Epoch 194/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 89.3390 - mean_squared_error: 89.3390 - val_loss: 206.0932 - val_mean_squared_error: 206.0932\n",
      "Epoch 195/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 89.9259 - mean_squared_error: 89.9259 - val_loss: 206.3636 - val_mean_squared_error: 206.3636\n",
      "Epoch 196/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 89.7158 - mean_squared_error: 89.7158 - val_loss: 205.5660 - val_mean_squared_error: 205.5660\n",
      "Epoch 197/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 89.4356 - mean_squared_error: 89.4356 - val_loss: 206.0514 - val_mean_squared_error: 206.0514\n",
      "Epoch 198/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 90.4274 - mean_squared_error: 90.4274 - val_loss: 205.3461 - val_mean_squared_error: 205.3461\n",
      "Epoch 199/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 89.6059 - mean_squared_error: 89.6059 - val_loss: 206.2947 - val_mean_squared_error: 206.2947\n",
      "Epoch 200/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 89.6536 - mean_squared_error: 89.6536 - val_loss: 207.0993 - val_mean_squared_error: 207.0993\n",
      "Epoch 201/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 87.3778 - mean_squared_error: 87.3778 - val_loss: 204.3751 - val_mean_squared_error: 204.3751\n",
      "Epoch 202/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.7575 - mean_squared_error: 86.7575 - val_loss: 204.3995 - val_mean_squared_error: 204.3995\n",
      "Epoch 203/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.4629 - mean_squared_error: 86.4629 - val_loss: 204.3666 - val_mean_squared_error: 204.3666\n",
      "Epoch 204/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.5203 - mean_squared_error: 86.5203 - val_loss: 204.2742 - val_mean_squared_error: 204.2742\n",
      "Epoch 205/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.8204 - mean_squared_error: 86.8204 - val_loss: 204.4714 - val_mean_squared_error: 204.4714\n",
      "Epoch 206/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.7076 - mean_squared_error: 86.7076 - val_loss: 204.3044 - val_mean_squared_error: 204.3044\n",
      "Epoch 207/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.8933 - mean_squared_error: 86.8933 - val_loss: 204.2550 - val_mean_squared_error: 204.2550\n",
      "Epoch 208/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.3710 - mean_squared_error: 86.3710 - val_loss: 204.4206 - val_mean_squared_error: 204.4206\n",
      "Epoch 209/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.4507 - mean_squared_error: 86.4507 - val_loss: 204.3353 - val_mean_squared_error: 204.3353\n",
      "Epoch 210/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.9135 - mean_squared_error: 85.9135 - val_loss: 204.4465 - val_mean_squared_error: 204.4465\n",
      "Epoch 211/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.5339 - mean_squared_error: 86.5339 - val_loss: 204.2813 - val_mean_squared_error: 204.2813\n",
      "Epoch 212/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.3056 - mean_squared_error: 86.3056 - val_loss: 204.5259 - val_mean_squared_error: 204.5259\n",
      "Epoch 213/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.4113 - mean_squared_error: 86.4113 - val_loss: 204.3226 - val_mean_squared_error: 204.3226\n",
      "Epoch 214/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.3403 - mean_squared_error: 86.3403 - val_loss: 204.5304 - val_mean_squared_error: 204.5304\n",
      "Epoch 215/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.3134 - mean_squared_error: 86.3134 - val_loss: 204.3666 - val_mean_squared_error: 204.3666\n",
      "Epoch 216/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.3444 - mean_squared_error: 86.3444 - val_loss: 204.4660 - val_mean_squared_error: 204.4660\n",
      "Epoch 217/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.5856 - mean_squared_error: 86.5856 - val_loss: 204.3107 - val_mean_squared_error: 204.3107\n",
      "Epoch 218/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.2618 - mean_squared_error: 86.2618 - val_loss: 204.1803 - val_mean_squared_error: 204.1803\n",
      "Epoch 219/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.2272 - mean_squared_error: 86.2272 - val_loss: 204.3482 - val_mean_squared_error: 204.3482\n",
      "Epoch 220/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.6073 - mean_squared_error: 86.6073 - val_loss: 204.2128 - val_mean_squared_error: 204.2128\n",
      "Epoch 221/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.8952 - mean_squared_error: 85.8952 - val_loss: 204.2918 - val_mean_squared_error: 204.2918\n",
      "Epoch 222/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.2411 - mean_squared_error: 86.2411 - val_loss: 204.5047 - val_mean_squared_error: 204.5047\n",
      "Epoch 223/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.0539 - mean_squared_error: 86.0539 - val_loss: 204.5628 - val_mean_squared_error: 204.5628\n",
      "Epoch 224/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.0107 - mean_squared_error: 86.0107 - val_loss: 204.4841 - val_mean_squared_error: 204.4841\n",
      "Epoch 225/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.7098 - mean_squared_error: 85.7098 - val_loss: 204.3528 - val_mean_squared_error: 204.3528\n",
      "Epoch 226/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.4791 - mean_squared_error: 85.4791 - val_loss: 204.6345 - val_mean_squared_error: 204.6345\n",
      "Epoch 227/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.6497 - mean_squared_error: 85.6497 - val_loss: 204.3753 - val_mean_squared_error: 204.3753\n",
      "Epoch 228/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 86.4277 - mean_squared_error: 86.4277 - val_loss: 204.4557 - val_mean_squared_error: 204.4557\n",
      "Epoch 229/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 86.3020 - mean_squared_error: 86.3020 - val_loss: 204.6124 - val_mean_squared_error: 204.6124\n",
      "Epoch 230/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.6647 - mean_squared_error: 85.6647 - val_loss: 204.6263 - val_mean_squared_error: 204.6263\n",
      "Epoch 231/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.8314 - mean_squared_error: 85.8314 - val_loss: 204.8446 - val_mean_squared_error: 204.8446\n",
      "Epoch 232/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 86.1738 - mean_squared_error: 86.1738 - val_loss: 204.7514 - val_mean_squared_error: 204.7514\n",
      "Epoch 233/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.9377 - mean_squared_error: 85.9377 - val_loss: 204.6801 - val_mean_squared_error: 204.6801\n",
      "Epoch 234/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.1778 - mean_squared_error: 86.1778 - val_loss: 204.4427 - val_mean_squared_error: 204.4427\n",
      "Epoch 235/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.1702 - mean_squared_error: 86.1702 - val_loss: 204.6721 - val_mean_squared_error: 204.6721\n",
      "Epoch 236/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.7492 - mean_squared_error: 85.7492 - val_loss: 204.7615 - val_mean_squared_error: 204.7615\n",
      "Epoch 237/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 86.1246 - mean_squared_error: 86.1246 - val_loss: 204.9088 - val_mean_squared_error: 204.9088\n",
      "Epoch 238/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.6470 - mean_squared_error: 85.6470 - val_loss: 204.5626 - val_mean_squared_error: 204.5626\n",
      "Epoch 239/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.6202 - mean_squared_error: 85.6202 - val_loss: 204.8790 - val_mean_squared_error: 204.8790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.6709 - mean_squared_error: 85.6709 - val_loss: 204.8596 - val_mean_squared_error: 204.8596\n",
      "Epoch 241/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.6079 - mean_squared_error: 85.6079 - val_loss: 204.7959 - val_mean_squared_error: 204.7959\n",
      "Epoch 242/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.8772 - mean_squared_error: 85.8772 - val_loss: 205.2480 - val_mean_squared_error: 205.2480\n",
      "Epoch 243/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.9173 - mean_squared_error: 85.9173 - val_loss: 204.9974 - val_mean_squared_error: 204.9974\n",
      "Epoch 244/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.1476 - mean_squared_error: 86.1476 - val_loss: 204.8669 - val_mean_squared_error: 204.8669\n",
      "Epoch 245/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.1261 - mean_squared_error: 86.1261 - val_loss: 204.9241 - val_mean_squared_error: 204.9241\n",
      "Epoch 246/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.8140 - mean_squared_error: 85.8140 - val_loss: 204.8826 - val_mean_squared_error: 204.8826\n",
      "Epoch 247/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.3409 - mean_squared_error: 85.3409 - val_loss: 204.9756 - val_mean_squared_error: 204.9756\n",
      "Epoch 248/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.9380 - mean_squared_error: 85.9380 - val_loss: 205.1122 - val_mean_squared_error: 205.1122\n",
      "Epoch 249/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 86.0205 - mean_squared_error: 86.0205 - val_loss: 204.7547 - val_mean_squared_error: 204.7547\n",
      "Epoch 250/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.9123 - mean_squared_error: 85.9123 - val_loss: 204.9559 - val_mean_squared_error: 204.9559\n",
      "Epoch 251/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.3528 - mean_squared_error: 86.3528 - val_loss: 204.6978 - val_mean_squared_error: 204.6978\n",
      "Epoch 252/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.8736 - mean_squared_error: 85.8736 - val_loss: 204.9898 - val_mean_squared_error: 204.9898\n",
      "Epoch 253/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.5481 - mean_squared_error: 85.5481 - val_loss: 205.1541 - val_mean_squared_error: 205.1541\n",
      "Epoch 254/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.9166 - mean_squared_error: 85.9166 - val_loss: 204.8533 - val_mean_squared_error: 204.8533\n",
      "Epoch 255/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.9569 - mean_squared_error: 85.9569 - val_loss: 204.8562 - val_mean_squared_error: 204.8562\n",
      "Epoch 256/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.6461 - mean_squared_error: 85.6461 - val_loss: 204.9727 - val_mean_squared_error: 204.9727\n",
      "Epoch 257/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.9396 - mean_squared_error: 85.9396 - val_loss: 204.8316 - val_mean_squared_error: 204.8316\n",
      "Epoch 258/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.4886 - mean_squared_error: 85.4886 - val_loss: 204.8900 - val_mean_squared_error: 204.8900\n",
      "Epoch 259/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.8597 - mean_squared_error: 85.8597 - val_loss: 205.0424 - val_mean_squared_error: 205.0424\n",
      "Epoch 260/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 86.5524 - mean_squared_error: 86.5524 - val_loss: 204.9596 - val_mean_squared_error: 204.9596\n",
      "Epoch 261/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.6934 - mean_squared_error: 85.6934 - val_loss: 205.1771 - val_mean_squared_error: 205.1771\n",
      "Epoch 262/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.6177 - mean_squared_error: 85.6177 - val_loss: 205.0797 - val_mean_squared_error: 205.0797\n",
      "Epoch 263/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.6762 - mean_squared_error: 85.6762 - val_loss: 205.1156 - val_mean_squared_error: 205.1156\n",
      "Epoch 264/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.6477 - mean_squared_error: 85.6477 - val_loss: 205.2202 - val_mean_squared_error: 205.2202\n",
      "Epoch 265/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.2267 - mean_squared_error: 85.2267 - val_loss: 204.8040 - val_mean_squared_error: 204.8040\n",
      "Epoch 266/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.9390 - mean_squared_error: 85.9390 - val_loss: 205.1585 - val_mean_squared_error: 205.1585\n",
      "Epoch 267/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.6876 - mean_squared_error: 85.6876 - val_loss: 204.8897 - val_mean_squared_error: 204.8897\n",
      "Epoch 268/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.4694 - mean_squared_error: 85.4694 - val_loss: 205.1505 - val_mean_squared_error: 205.1505\n",
      "Epoch 269/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.6274 - mean_squared_error: 85.6274 - val_loss: 205.2201 - val_mean_squared_error: 205.2201\n",
      "Epoch 270/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.0780 - mean_squared_error: 85.0780 - val_loss: 205.2392 - val_mean_squared_error: 205.2392\n",
      "Epoch 271/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.0066 - mean_squared_error: 85.0066 - val_loss: 205.1053 - val_mean_squared_error: 205.1053\n",
      "Epoch 272/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.8453 - mean_squared_error: 85.8453 - val_loss: 205.0203 - val_mean_squared_error: 205.0203\n",
      "Epoch 273/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.4194 - mean_squared_error: 85.4194 - val_loss: 205.3090 - val_mean_squared_error: 205.3090\n",
      "Epoch 274/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.6292 - mean_squared_error: 85.6292 - val_loss: 204.7896 - val_mean_squared_error: 204.7896\n",
      "Epoch 275/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 86.1885 - mean_squared_error: 86.1885 - val_loss: 205.0296 - val_mean_squared_error: 205.0296\n",
      "Epoch 276/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.8231 - mean_squared_error: 85.8231 - val_loss: 205.0090 - val_mean_squared_error: 205.0090\n",
      "Epoch 277/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.0439 - mean_squared_error: 85.0439 - val_loss: 205.0930 - val_mean_squared_error: 205.0930\n",
      "Epoch 278/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.3650 - mean_squared_error: 85.3650 - val_loss: 205.1152 - val_mean_squared_error: 205.1152\n",
      "Epoch 279/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.6385 - mean_squared_error: 85.6385 - val_loss: 205.0980 - val_mean_squared_error: 205.0980\n",
      "Epoch 280/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.8370 - mean_squared_error: 85.8370 - val_loss: 205.3214 - val_mean_squared_error: 205.3214\n",
      "Epoch 281/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.6358 - mean_squared_error: 85.6358 - val_loss: 205.0958 - val_mean_squared_error: 205.0958\n",
      "Epoch 282/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 84.9233 - mean_squared_error: 84.9233 - val_loss: 205.2545 - val_mean_squared_error: 205.2545\n",
      "Epoch 283/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.5782 - mean_squared_error: 85.5782 - val_loss: 205.0642 - val_mean_squared_error: 205.0642\n",
      "Epoch 284/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.5459 - mean_squared_error: 85.5459 - val_loss: 205.1834 - val_mean_squared_error: 205.1834\n",
      "Epoch 285/300\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 85.9675 - mean_squared_error: 85.9675 - val_loss: 205.3834 - val_mean_squared_error: 205.3834\n",
      "Epoch 286/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.3284 - mean_squared_error: 85.3284 - val_loss: 205.1654 - val_mean_squared_error: 205.1654\n",
      "Epoch 287/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.4348 - mean_squared_error: 85.4348 - val_loss: 205.1765 - val_mean_squared_error: 205.1765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.8905 - mean_squared_error: 85.8905 - val_loss: 205.3634 - val_mean_squared_error: 205.3634\n",
      "Epoch 289/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.7432 - mean_squared_error: 85.7432 - val_loss: 205.4556 - val_mean_squared_error: 205.4556\n",
      "Epoch 290/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 84.9090 - mean_squared_error: 84.9090 - val_loss: 205.5850 - val_mean_squared_error: 205.5850\n",
      "Epoch 291/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.7239 - mean_squared_error: 85.7239 - val_loss: 205.5366 - val_mean_squared_error: 205.5366\n",
      "Epoch 292/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.1761 - mean_squared_error: 85.1761 - val_loss: 205.5332 - val_mean_squared_error: 205.5332\n",
      "Epoch 293/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 84.9508 - mean_squared_error: 84.9508 - val_loss: 205.5015 - val_mean_squared_error: 205.5015\n",
      "Epoch 294/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.2929 - mean_squared_error: 85.2929 - val_loss: 205.2654 - val_mean_squared_error: 205.2654\n",
      "Epoch 295/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.1964 - mean_squared_error: 85.1964 - val_loss: 205.3916 - val_mean_squared_error: 205.3916\n",
      "Epoch 296/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.1634 - mean_squared_error: 85.1634 - val_loss: 205.1870 - val_mean_squared_error: 205.1870\n",
      "Epoch 297/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.4712 - mean_squared_error: 85.4712 - val_loss: 205.3811 - val_mean_squared_error: 205.3811\n",
      "Epoch 298/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.3678 - mean_squared_error: 85.3678 - val_loss: 205.1207 - val_mean_squared_error: 205.1207\n",
      "Epoch 299/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 84.8899 - mean_squared_error: 84.8899 - val_loss: 205.3382 - val_mean_squared_error: 205.3382\n",
      "Epoch 300/300\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 85.3359 - mean_squared_error: 85.3359 - val_loss: 205.6866 - val_mean_squared_error: 205.6866\n"
     ]
    }
   ],
   "source": [
    "model = Net() #starting out with basic linear feedforward network (CNN wrote for CIFR-10 does not work with 2D data)\n",
    "\n",
    "runLen = 300    \n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    part1 = runLen//3\n",
    "    part2 = 2*runLen//3\n",
    "    \n",
    "    if epoch < part1:\n",
    "        lr = 0.01\n",
    "        return lr\n",
    "    if epoch >= part1 and epoch < part2:\n",
    "        lr = 0.001\n",
    "        return lr\n",
    "    if epoch >= part2:\n",
    "        lr = 0.0001\n",
    "        return lr\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.MeanSquaredError()],)\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)\n",
    "\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "#Train Model\n",
    "trace = model.fit(x=x_train, y=y_train, batch_size=256, epochs=runLen, verbose=1, \n",
    "                  validation_split=0.1, callbacks = [callback], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "naughty-census",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.0, 1000.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(trace.history['loss'], '-')\n",
    "plt.plot(trace.history['val_loss'], '-')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim(10,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "mental-ultimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error =  [ 4.2387877  4.729311   2.4435675 14.197172  13.927961  13.865121\n",
      " 10.806598 ]\n",
      "error as frac of joint range =  [0.08 0.07 0.03 0.12 0.11 0.03 0.08]\n",
      "total error =  0.5665720485140393\n",
      "[ -0.16843656   0.11421638   0.271204   -21.454273    12.484665\n",
      "  14.405404   -13.966602  ]\n",
      "tf.Tensor([  2.8005   4.6661   4.1648 -20.32     9.7146  24.804  -10.767 ], shape=(7,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#test model\n",
    "prediction = model.predict(x_train[-100:-1])\n",
    "# print(prediction)\n",
    "actual = y_train[-100:-1]\n",
    "# print(actual)\n",
    "\n",
    "error = (actual - prediction)\n",
    "# print(np.floor(error))\n",
    "\n",
    "#average error for estimates for each joint\n",
    "avg = np.average(abs(error),axis=0)\n",
    "print(\"average error = \", avg)\n",
    "\n",
    "#range for each joint:\n",
    "ranges = [50, 60, 67.5, 110, 120, 360, 130] #TODO -> these are not correct\n",
    "rel_error = avg/ranges\n",
    "print(\"error as frac of joint range = \", np.floor(rel_error*100)/100) #1 is full range of joint\n",
    "print(\"total error = \",sum(rel_error))\n",
    "#current best is: 0.566 @ [0.08 0.07 0.03 0.12 0.11 0.03 0.08]\n",
    "\n",
    "print(prediction[10])\n",
    "print(actual[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hourly-laser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Derm\\anaconda3\\envs\\dnn\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Derm\\anaconda3\\envs\\dnn\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: trajectory_cls.kmod\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"trajectory_cls.kmod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "technical-armor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([13.040113 16.174479 43.41501  35.256268 36.824196 72.12078  41.694756], shape=(7,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.26080227 0.26957464 0.6431853  0.32051152 0.30686828 0.2003355\n",
      " 0.3207289 ], shape=(7,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#proof my model is doing better than completely random guessing\n",
    "\n",
    "np.random.seed(None)\n",
    "\n",
    "# print(actual)\n",
    "# print(tf.shape(actual)) #[99 7]\n",
    "B = tf.random.uniform([99,7])\n",
    "\n",
    "# B = tf.ones([99,7])\n",
    "B = B *tf.constant([25., 30., 33.75, 55. , 60., 180., 65.]) + tf.constant([0., 0., 26.25, -35., 30., 0., -65.])\n",
    "\n",
    "# print(tf.shape(B))\n",
    "# print(tf.shape(actual))\n",
    "\n",
    "fake_error = (actual - B)\n",
    "# print(fake_error)\n",
    "\n",
    "fake_avg = tf.math.reduce_mean(tf.math.abs(fake_error), axis=0)\n",
    "print(fake_avg)\n",
    "\n",
    "print(fake_avg/ranges)\n",
    "\n",
    "#NOTE: these are not all the same becuase the starting ranges for joint positions do NOT fall in the middle of all\n",
    "#      possible positions for each joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-agenda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn",
   "language": "python",
   "name": "dnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
