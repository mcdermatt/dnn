{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sorted-channels",
   "metadata": {},
   "source": [
    "# Novel Inertia Based Human Pose Estimation Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "short-progressive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from utils import *\n",
    "\n",
    "#need to have these two lines to work on my ancient 1060 3gb\n",
    "#  https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "synthetic-identification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved augmented data as tbr, jbr\n"
     ]
    }
   ],
   "source": [
    "#Import and augment data by rotating about y axis\n",
    "\n",
    "from utils import *\n",
    "\n",
    "f1 = \"simulation/data/traj_9DOF_rel2start100k.txt\"\n",
    "f2 = \"simulation/data/jointPos_9DOF_rel2start100k.txt\"\n",
    "numTraj = 100000\n",
    "t, jointPos = add_body_rotation(f1, f2, numTraj, mult = 1)\n",
    "\n",
    "# f3 = \"simulation/data/traj_9DOF_250k.txt\"\n",
    "# f4 = \"simulation/data/jointPos_9DOF_250k.txt\"\n",
    "# numTraj = 250000\n",
    "# t2, jointPos2 = add_body_rotation(f3, f4, numTraj, mult = 1)\n",
    "\n",
    "\n",
    "# print(jointPos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine traj and jointpos from the two datasets\n",
    "\n",
    "# print(np.shape(t),np.shape(t2))\n",
    "# print(np.shape(jointPos),np.shape(jointPos2))\n",
    "\n",
    "tCombined = np.concatenate((t,t2), axis = 0)\n",
    "jointPosCombined = np.concatenate((jointPos,jointPos2), axis = 0)\n",
    "\n",
    "print(np.shape(tCombined), np.shape(jointPosCombined))\n",
    "\n",
    "t = tCombined\n",
    "jointPos = jointPosCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "steady-amount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   19    19    19 ... 99953 99953 99953]\n",
      "[]\n",
      "(98965, 10)\n",
      "(98965, 10, 6)\n"
     ]
    }
   ],
   "source": [
    "#find and fix errors in data\n",
    "err = np.argwhere(np.abs(jointPos) == 0)[:,0]\n",
    "over_extended = np.argwhere(np.abs(jointPos) > 360)\n",
    "\n",
    "print(err)\n",
    "print(over_extended)\n",
    "\n",
    "# Remove cells with errors instead of doubling existing cells\n",
    "jointPos = np.delete(jointPos,err,axis = 0)\n",
    "t = np.delete(t,err, axis = 0)\n",
    "\n",
    "#replace empty trials with data from existing trials -> not a good idea...?\n",
    "# for i in err[:,0]:\n",
    "# #     print(jointPos[i])\n",
    "#     randIndex = int(np.floor(np.random.rand()*np.shape(jointPos)[0]))\n",
    "#     jointPos[i] = jointPos[randIndex]\n",
    "#     t[i] = t[randIndex]\n",
    "\n",
    "print(np.shape(jointPos))\n",
    "print(np.shape(t))\n",
    "\n",
    "# np.save(\"simulation/data/traj_combined\", t)\n",
    "# np.save(\"simulation/data/jointPos_combined\", jointPos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-concentrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pre-rotated dataset\n",
    "\n",
    "t = np.load(\"simulation/data/traj_combined.npy\")\n",
    "jointPos = np.load(\"simulation/data/jointPos_combined.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "whole-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import Net4 #for 10DOF model\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "#convert data from numpy to tensors\n",
    "x_train = tf.convert_to_tensor(t,np.float32)\n",
    "y_train = tf.convert_to_tensor(jointPos,np.float32)\n",
    "\n",
    "# print(tf.shape(x_train))\n",
    "# print(x_train[0,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "working-argument",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10, 6)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 10, 6)        24          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 8, 16)        304         batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 8, 16)        784         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8, 16)        64          conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 8, 16)        784         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 8, 16)        64          conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity (TensorFlo [(None, 8, 16)]      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 8, 16)        0           batch_normalization_2[0][0]      \n",
      "                                                                 tf_op_layer_Identity[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 8, 16)        0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 8, 32)        1568        re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 32)        128         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 8, 32)        3104        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 8, 32)        128         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_1 (TensorF [(None, 8, 32)]      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 8, 32)        0           batch_normalization_4[0][0]      \n",
      "                                                                 tf_op_layer_Identity_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 8, 32)        0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 8, 64)        6208        re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 8, 64)        256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 8, 64)        12352       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 64)        256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_2 (TensorF [(None, 8, 64)]      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 8, 64)        0           batch_normalization_6[0][0]      \n",
      "                                                                 tf_op_layer_Identity_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 8, 64)        0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 8, 128)       24704       re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 128)       512         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 8, 128)       49280       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 128)       512         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_3 (TensorF [(None, 8, 128)]     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 128)       0           batch_normalization_8[0][0]      \n",
      "                                                                 tf_op_layer_Identity_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 8, 128)       0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 8, 256)       98560       re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 256)       1024        conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 8, 256)       196864      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 256)       1024        conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_4 (TensorF [(None, 8, 256)]     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 256)       0           batch_normalization_10[0][0]     \n",
      "                                                                 tf_op_layer_Identity_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 8, 256)       0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 8, 512)       393728      re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 512)       2048        conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 8, 512)       786944      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 512)       2048        conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_5 (TensorF [(None, 8, 512)]     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 512)       0           batch_normalization_12[0][0]     \n",
      "                                                                 tf_op_layer_Identity_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 8, 512)       0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 8, 1024)      1573888     re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 1024)      4096        conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 8, 1024)      3146752     batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 1024)      4096        conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_6 (TensorF [(None, 8, 1024)]    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 1024)      0           batch_normalization_14[0][0]     \n",
      "                                                                 tf_op_layer_Identity_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 8, 1024)      0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 8192)         0           re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           524352      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64)           256         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64)           256         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           4160        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64)           256         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           650         batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None, 10)]         0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 10)]         0           tf_op_layer_Mul[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 6,846,194\n",
      "Trainable params: 6,837,670\n",
      "Non-trainable params: 8,524\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766/766 [==============================] - 25s 33ms/step - loss: 1984.9634 - val_loss: 1781.8954\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 24s 31ms/step - loss: 1635.7776 - val_loss: 1702.1827\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 24s 31ms/step - loss: 1535.2855 - val_loss: 1645.3115\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 24s 31ms/step - loss: 1446.1650 - val_loss: 1551.8256\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 1387.4355 - val_loss: 1446.9141\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 1350.2891 - val_loss: 1438.2170\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 1312.1992 - val_loss: 1478.9637\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 1274.8007 - val_loss: 1576.5936\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 1239.1464 - val_loss: 1503.9789\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 1206.0883 - val_loss: 1400.7361\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 1171.8704 - val_loss: 1321.9734\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 1138.3475 - val_loss: 1381.7407\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 1104.4987 - val_loss: 1310.5646\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 1068.0563 - val_loss: 1348.6761\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 1029.2057 - val_loss: 1129.2644\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 993.4177 - val_loss: 1130.6121\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 964.6938 - val_loss: 1027.0109\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 932.7352 - val_loss: 1176.9884\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 892.6182 - val_loss: 1019.0731\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 864.7073 - val_loss: 1228.9568\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 837.6396 - val_loss: 1311.2701\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 807.7189 - val_loss: 1072.0802\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 785.0550 - val_loss: 1047.9938\n",
      "Epoch 24/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 760.1157 - val_loss: 1118.6061\n",
      "Epoch 25/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 736.3492 - val_loss: 895.3027\n",
      "Epoch 26/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 712.3333 - val_loss: 894.7739\n",
      "Epoch 27/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 688.1055 - val_loss: 885.9448\n",
      "Epoch 28/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 671.1318 - val_loss: 928.7648\n",
      "Epoch 29/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 648.3212 - val_loss: 956.2967\n",
      "Epoch 30/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 632.1664 - val_loss: 991.8829\n",
      "Epoch 31/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 618.8845 - val_loss: 912.6752\n",
      "Epoch 32/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 596.2200 - val_loss: 930.2369\n",
      "Epoch 33/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 589.5036 - val_loss: 1003.8104\n",
      "Epoch 34/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 445.6741 - val_loss: 718.9197\n",
      "Epoch 35/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 395.0748 - val_loss: 695.7299\n",
      "Epoch 36/100\n",
      "766/766 [==============================] - 25s 32ms/step - loss: 379.0080 - val_loss: 693.2991\n",
      "Epoch 37/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 361.8290 - val_loss: 712.9589\n",
      "Epoch 38/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 352.6697 - val_loss: 692.2266\n",
      "Epoch 39/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 339.7473 - val_loss: 693.8258\n",
      "Epoch 40/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 332.2665 - val_loss: 721.1689\n",
      "Epoch 41/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 324.0885 - val_loss: 709.2471\n",
      "Epoch 42/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 318.7266 - val_loss: 735.9033\n",
      "Epoch 43/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 309.3434 - val_loss: 706.3844\n",
      "Epoch 44/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 305.0892 - val_loss: 731.8199\n",
      "Epoch 45/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 301.2828 - val_loss: 737.5969\n",
      "Epoch 46/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 291.6836 - val_loss: 716.2034\n",
      "Epoch 47/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 290.4529 - val_loss: 730.6804\n",
      "Epoch 48/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 284.4379 - val_loss: 760.5302\n",
      "Epoch 49/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 280.8599 - val_loss: 703.1556\n",
      "Epoch 50/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 275.1389 - val_loss: 718.2598\n",
      "Epoch 51/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 269.1787 - val_loss: 754.8629\n",
      "Epoch 52/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 266.8933 - val_loss: 772.3052\n",
      "Epoch 53/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 263.9485 - val_loss: 687.2370\n",
      "Epoch 54/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 258.7968 - val_loss: 722.5238\n",
      "Epoch 55/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 258.2174 - val_loss: 727.0583\n",
      "Epoch 56/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 255.3500 - val_loss: 724.7059\n",
      "Epoch 57/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 249.2880 - val_loss: 742.5755\n",
      "Epoch 58/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 246.8901 - val_loss: 768.6255\n",
      "Epoch 59/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 244.9265 - val_loss: 737.7285\n",
      "Epoch 60/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 241.5001 - val_loss: 724.1118\n",
      "Epoch 61/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 238.8805 - val_loss: 739.1538\n",
      "Epoch 62/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 235.3381 - val_loss: 724.9684\n",
      "Epoch 63/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 234.6524 - val_loss: 730.0250\n",
      "Epoch 64/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 229.1081 - val_loss: 693.7849\n",
      "Epoch 65/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 227.6825 - val_loss: 720.2501\n",
      "Epoch 66/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 228.1236 - val_loss: 755.9324\n",
      "Epoch 67/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 217.6036 - val_loss: 724.1013\n",
      "Epoch 68/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 212.4956 - val_loss: 708.1454\n",
      "Epoch 69/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 210.5073 - val_loss: 707.7424\n",
      "Epoch 70/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 210.2505 - val_loss: 692.3026\n",
      "Epoch 71/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 205.3883 - val_loss: 714.2443\n",
      "Epoch 72/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 204.3697 - val_loss: 705.4508\n",
      "Epoch 73/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 203.1927 - val_loss: 707.1955\n",
      "Epoch 74/100\n",
      "766/766 [==============================] - 25s 32ms/step - loss: 203.9025 - val_loss: 709.1111\n",
      "Epoch 75/100\n",
      "766/766 [==============================] - 25s 32ms/step - loss: 199.8325 - val_loss: 722.3333\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766/766 [==============================] - 25s 32ms/step - loss: 198.0954 - val_loss: 713.5696\n",
      "Epoch 77/100\n",
      "766/766 [==============================] - 25s 32ms/step - loss: 200.0367 - val_loss: 706.8163\n",
      "Epoch 78/100\n",
      "766/766 [==============================] - 24s 31ms/step - loss: 197.5192 - val_loss: 725.3683\n",
      "Epoch 79/100\n",
      "766/766 [==============================] - 24s 31ms/step - loss: 195.6889 - val_loss: 699.0942\n",
      "Epoch 80/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 193.1334 - val_loss: 722.2367\n",
      "Epoch 81/100\n",
      "766/766 [==============================] - 24s 31ms/step - loss: 191.9819 - val_loss: 711.8839\n",
      "Epoch 82/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 191.6103 - val_loss: 721.5729\n",
      "Epoch 83/100\n",
      "766/766 [==============================] - 24s 31ms/step - loss: 189.4838 - val_loss: 699.3542\n",
      "Epoch 84/100\n",
      "766/766 [==============================] - 24s 31ms/step - loss: 189.9941 - val_loss: 716.2792\n",
      "Epoch 85/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 186.7732 - val_loss: 716.7316\n",
      "Epoch 86/100\n",
      "766/766 [==============================] - 24s 31ms/step - loss: 185.8351 - val_loss: 740.2310\n",
      "Epoch 87/100\n",
      "766/766 [==============================] - 24s 31ms/step - loss: 186.6746 - val_loss: 719.6050\n",
      "Epoch 88/100\n",
      "766/766 [==============================] - 24s 31ms/step - loss: 183.5693 - val_loss: 724.3341\n",
      "Epoch 89/100\n",
      "766/766 [==============================] - 24s 31ms/step - loss: 184.5682 - val_loss: 705.3797\n",
      "Epoch 90/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 182.3263 - val_loss: 713.0110\n",
      "Epoch 91/100\n",
      "766/766 [==============================] - 24s 31ms/step - loss: 178.0994 - val_loss: 745.3463\n",
      "Epoch 92/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 180.5766 - val_loss: 723.3726\n",
      "Epoch 93/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 179.0157 - val_loss: 707.8103\n",
      "Epoch 94/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 175.9548 - val_loss: 747.0623\n",
      "Epoch 95/100\n",
      "766/766 [==============================] - 24s 31ms/step - loss: 177.7146 - val_loss: 720.2079\n",
      "Epoch 96/100\n",
      "766/766 [==============================] - 24s 31ms/step - loss: 174.3574 - val_loss: 720.9645\n",
      "Epoch 97/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 173.9315 - val_loss: 720.9497\n",
      "Epoch 98/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 171.5940 - val_loss: 728.1454\n",
      "Epoch 99/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 173.0319 - val_loss: 694.5978\n",
      "Epoch 100/100\n",
      "766/766 [==============================] - 24s 32ms/step - loss: 171.5415 - val_loss: 699.1470\n"
     ]
    }
   ],
   "source": [
    "model = Net4()\n",
    "\n",
    "runLen = 100    \n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "#     part1 = 2*runLen//3\n",
    "#     part2 = 5*runLen//6 #net1\n",
    "\n",
    "    part1 = runLen//3\n",
    "    part2 = 2*runLen//3 #net2\n",
    "\n",
    "    if epoch < part1:\n",
    "        lr = 0.01\n",
    "        return lr\n",
    "    if epoch >= part1 and epoch < part2:\n",
    "        lr = 0.001\n",
    "        return lr\n",
    "    if epoch >= part2:\n",
    "        lr = 0.0005\n",
    "        return lr\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "#     loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "#     metrics=[tf.keras.metrics.MeanSquaredError()],\n",
    ")\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)\n",
    "\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "trace = model.fit(x=x_train, y=y_train, batch_size=128, epochs=runLen, verbose=1, \n",
    "                  validation_split=0.01, callbacks = [callback], shuffle=True)\n",
    "\n",
    "#current best on combined dataset:\n",
    "#   val_loss = 505\n",
    "#   sum error on 10k test set: 0.97\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "promotional-howard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(trace.history['loss'], '-')\n",
    "plt.plot(trace.history['val_loss'], '-')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "# plt.ylim(10,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "approved-public",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved augmented data as tbr, jbr\n"
     ]
    }
   ],
   "source": [
    "#load larger test dataset (for calculating accuracy of network)\n",
    "\n",
    "ft1 = \"simulation/data/traj_9DOF_10k.txt\"\n",
    "ft2 = \"simulation/data/jointPos_9DOF_10k.txt\"\n",
    "numTraj = 10000 #number of trajectories given in base file\n",
    "\n",
    "tTest, jointPosTest = add_body_rotation(ft1, ft2, numTraj, mult =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "demonstrated-elimination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved augmented data as tbr, jbr, at\n"
     ]
    }
   ],
   "source": [
    "#load single test case (for use with viz)\n",
    "#DEBUG -> why does this perform better when data is generated with fast restart disabled??\n",
    "\n",
    "ft1 = \"simulation/data/traj_9DOF_1.txt\"\n",
    "ft2 = \"simulation/data/jointPos_9DOF_1.txt\"\n",
    "ft3 = \"simulation/data/jointPath.txt\"\n",
    "numTraj = 1 #number of trajectories given in base file\n",
    "\n",
    "tTest, jointPosTest = add_body_rotation(ft1, ft2, numTraj, mult =1, actual_traj=ft3)\n",
    "\n",
    "# print(tTest)\n",
    "# print(jointPosTest) #issue when only one element in jointPos input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "quiet-reducing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.          0.          0.          0.          0.\n",
      "    0.        ]\n",
      "  [ 0.10951163 -0.077934   -0.20316371  0.26034    -0.13383\n",
      "    0.28885   ]\n",
      "  [ 0.24602187 -0.019759   -0.46568543  0.59084    -0.078596\n",
      "    0.58208   ]\n",
      "  [ 0.3289765   0.13609    -0.6271041   0.77063     0.048619\n",
      "    0.73769   ]\n",
      "  [ 0.37013215  0.28861    -0.6939169   0.86303     0.13096\n",
      "    0.76589   ]\n",
      "  [ 0.36146602  0.5752     -0.7078298   1.0205      0.34926\n",
      "    0.82784   ]\n",
      "  [ 0.17582197  0.95807    -0.3832654   1.1154      0.82767\n",
      "    0.93644   ]\n",
      "  [ 0.03664704  0.94379    -0.0876997  -0.62035     0.61947\n",
      "   -0.0016883 ]\n",
      "  [ 0.19452772  0.92578    -0.3725845   1.1163      0.686\n",
      "    0.90565   ]\n",
      "  [ 0.3665747   0.72409    -0.6412475   1.1037      0.42594\n",
      "    0.70655   ]]], shape=(1, 10, 6), dtype=float32)\n",
      "average error =  [2.9224400e+01 3.0353100e+01 5.9310089e+01 8.0722000e+01 1.1531200e+02\n",
      " 3.6001001e+02 7.1644999e-02 1.3945999e+02 4.6769798e+01 1.2494695e+02]\n",
      "error as frac of joint range =  [0.584 0.505 0.878 0.733 0.96  1.    0.    0.774 0.425 0.347]\n",
      "total error =  6.211422147681423\n",
      "prediction:  [-25.  30.  60.  20. -30. 180.   0. -90. -55. 180.]\n",
      "actual:  tf.Tensor(\n",
      "[ 4.2244000e+00 -3.5310000e-01  6.8990999e-01 -6.0722000e+01\n",
      "  8.5311996e+01 -1.8000999e+02  7.1644999e-02  4.9459999e+01\n",
      " -8.2301998e+00  5.5053047e+01], shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#test model- IMPORTANT TO USE NEVER BEFORE SEEN DATA\n",
    "\n",
    "x_test = tf.convert_to_tensor(tTest,np.float32)\n",
    "print(x_test)\n",
    "y_test = tf.convert_to_tensor(jointPosTest,np.float32)\n",
    "\n",
    "prediction = model.predict(x_test)\n",
    "error = abs(y_test - prediction)\n",
    "\n",
    "#average error for estimates for each joint\n",
    "avg = np.average(error,axis=0)\n",
    "print(\"average error = \", avg)\n",
    "\n",
    "#range for each joint:\n",
    "ranges = [50, 60, 67.5, 110, 120, 360, 130, 180, 110, 360]\n",
    "rel_error = avg/ranges\n",
    "print(\"error as frac of joint range = \", np.floor(rel_error*1000)/1000) #1 is full range of joint\n",
    "print(\"total error = \",sum(rel_error))\n",
    "\n",
    "print(\"prediction: \",prediction[0])\n",
    "print(\"actual: \", y_test[0])\n",
    "\n",
    "np.save(\"simulation/data/prediction.npy\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-rebel",
   "metadata": {},
   "source": [
    "Best total error: \n",
    "\n",
    "1.52 @ 10k  dataset, mult 1, BS 128, MSE\n",
    "\n",
    "1.29 @ 100k dataset, mult 2, BS 128, MSE\n",
    "\n",
    "1.15 @ 100k dataset, mult 1, BS 128, MSE\n",
    "\n",
    "1.10 @ 100k dataset, mult 1, BS 64,  MSE, Val loss = 851, 10 epoch\n",
    "\n",
    "0.97 @ 100k dataset, mult 1, BS 128,  MSE, Val loss = 623, 30 epoch\n",
    "\n",
    "0.86 @ 100k dataset, mult 1, BS 128,  MSE, Val loss = 556, 100 epoch\n",
    "\n",
    "0.90 @ 250k dataset (replace errors with repeats), mult 1, BS 128, val loss = 476, 100 epoch\n",
    "\n",
    "0.82 @ combined 650k dataset, mult 1, BS 128, MSE, val loss = 371, 100 epoch\n",
    "\n",
    "Notes:\n",
    "artifially creating more data by rotating about y axis at different angles is a bad idea. This teaches the network to memorize patterns of movement rather than learn the underlying dynamic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"10DOF.kmod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best scoring model\n",
    "\n",
    "# model = tf.keras.models.load_model(\"10DOF.kmod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proof my model is doing better than completely random guessing\n",
    "\n",
    "np.random.seed(None)\n",
    "\n",
    "# print(actual)\n",
    "# print(tf.shape(actual)) #[99 7]\n",
    "B = tf.random.uniform([1000,7])\n",
    "\n",
    "# B = tf.ones([99,7])\n",
    "B = B *tf.constant([25., 30., 33.75, 55. , 60., 180., 65.]) + tf.constant([0., 0., 26.25, -35., 30., 0., -65.])\n",
    "\n",
    "# print(tf.shape(B))\n",
    "# print(tf.shape(actual))\n",
    "\n",
    "fake_error = (y_test - B)\n",
    "# print(fake_error)\n",
    "\n",
    "fake_avg = tf.math.reduce_mean(tf.math.abs(fake_error), axis=0)\n",
    "print(fake_avg)\n",
    "\n",
    "rel_fake_error = fake_avg/ranges\n",
    "\n",
    "print(\"error as frac of joint range: \",rel_fake_error)\n",
    "print(\"total error: \", sum(rel_fake_error))\n",
    "\n",
    "#NOTE: these are not all the same becuase the starting ranges for joint positions do NOT fall in the middle of all\n",
    "#      possible positions for each joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "r = R.from_euler('zyx', [\n",
    "[90, 0, 0],\n",
    "[0, 45, 0],\n",
    "[45, 60, 30]], degrees=True)\n",
    "\n",
    "print(r)\n",
    "r.as_quat()\n",
    "\n",
    "v = [1, 2, 3]\n",
    "\n",
    "r.apply(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = R.from_euler('z', 90, degrees=True)\n",
    "r2 = R.from_euler('x', 90, degrees=True)\n",
    "r3 = r1*r2\n",
    "\n",
    "v = [1, 2, 3]\n",
    "\n",
    "rot1 = r1.apply(v)\n",
    "rot2 = r3.apply(v)\n",
    "print(rot2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c= r3.apply([1, 2, 3])\n",
    "print(a,b,c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data from MatLab SimScape Multibody Simulator\n",
    "\n",
    "#data comes from two files\n",
    "#1) n trajectories in xyz space, each length m\n",
    "# traj = np.loadtxt(open(\"C:/Users/Derm/Desktop/traj_with_angs_1M.txt\", \"rb\"), delimiter=\",\")\n",
    "traj = np.loadtxt(open(\"simulation/data/traj_9DOF_100k.txt\", \"rb\"), delimiter=\",\")\n",
    "\n",
    "trajPts = np.shape(traj)[0] #points per trajectory\n",
    "# numTraj = np.shape(traj)[1]//3 #number of total trajectories\n",
    "numTraj = np.shape(traj)[1]//6 #number of total trajectories\n",
    "\n",
    "\n",
    "#traj needs to be reshaped to a 3d numpy array\n",
    "#as is traj[n] shows [x,y,z,x,y,z...]\n",
    "\n",
    "\n",
    "#2) 7 joint angles at the end of the sequence\n",
    "# jointPos = np.loadtxt(open(\"C:/Users/Derm/Desktop/jointPos_with_angs_1M.txt\", \"rb\"), delimiter=\",\")\n",
    "jointPos = np.loadtxt(open(\"simulation/data/jointPos_9DOF_100k.txt\", \"rb\"), delimiter=\",\")\n",
    "\n",
    "# print(traj[-1])\n",
    "# print(jointPos[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape traj data into 3d numpy array\n",
    "# t = np.zeros([trajPts,3,numTraj]) #net 1\n",
    "# for j in range(np.shape(traj)[0]):\n",
    "#     for i in range(np.shape(traj)[1]//3):\n",
    "#         t[j,:,i] = traj[j,3*i:3*(i+1)]\n",
    "        \n",
    "t = np.zeros([trajPts,6,numTraj]) #net 3\n",
    "for j in range(np.shape(traj)[0]):\n",
    "    for i in range(np.shape(traj)[1]//6):\n",
    "        t[j,:,i] = traj[j,6*i:6*(i+1)]\n",
    "\n",
    "        \n",
    "# print(t[:,:,0]) #same as in MatLab\n",
    "print(np.shape(t))\n",
    "#swap axis so batch size is first axis (for TF)\n",
    "t = np.swapaxes(t,0,2)\n",
    "print(np.shape(t)) #[numTraj, xyz, trajPts]\n",
    "#swap axis again so that conv1D moves on time and not xyz\n",
    "t = np.swapaxes(t,1,2)\n",
    "print(np.shape(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-signature",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn",
   "language": "python",
   "name": "dnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
