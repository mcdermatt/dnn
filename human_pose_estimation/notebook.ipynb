{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sorted-channels",
   "metadata": {},
   "source": [
    "# Novel Inertia Based Human Pose Estimation Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "short-progressive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from utils import *\n",
    "\n",
    "#need to have these two lines to work on my ancient 1060 3gb\n",
    "#  https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "preceding-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data from MatLab SimScape Multibody Simulator\n",
    "\n",
    "#data comes from two files\n",
    "#1) n trajectories in xyz space, each length m\n",
    "# traj = np.loadtxt(open(\"simulation/data/traj1M.txt\", \"rb\"), delimiter=\",\")\n",
    "# traj = np.loadtxt(open(\"simulation/data/traj_random100k.txt\", \"rb\"), delimiter=\",\")\n",
    "traj = np.loadtxt(open(\"simulation/data/traj_with_angs_1M.txt\", \"rb\"), delimiter=\",\")\n",
    "\n",
    "\n",
    "trajPts = np.shape(traj)[0] #points per trajectory\n",
    "# numTraj = np.shape(traj)[1]//3 #number of total trajectories\n",
    "numTraj = np.shape(traj)[1]//6 #number of total trajectories\n",
    "\n",
    "\n",
    "#traj needs to be reshaped to a 3d numpy array\n",
    "#as is traj[n] shows [x,y,z,x,y,z...]\n",
    "\n",
    "\n",
    "#2) 7 joint angles at the end of the sequence\n",
    "jointPos = np.loadtxt(open(\"simulation/data/jointPos_with_angs_1M.txt\", \"rb\"), delimiter=\",\")\n",
    "# jointPos = np.loadtxt(open(\"simulation/data/jointPos_random100k.txt\", \"rb\"), delimiter=\",\")\n",
    "\n",
    "# print(traj[-1])\n",
    "# print(jointPos[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "strategic-communications",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 17336      0]\n",
      " [ 17336      1]\n",
      " [ 17336      2]\n",
      " [ 17336      3]\n",
      " [ 17336      4]\n",
      " [ 17336      5]\n",
      " [ 17336      6]\n",
      " [202354      3]\n",
      " [202354      4]\n",
      " [202354      5]\n",
      " [202354      6]\n",
      " [738713      0]\n",
      " [738713      1]\n",
      " [738713      2]\n",
      " [738713      3]\n",
      " [738713      4]\n",
      " [738713      5]\n",
      " [738713      6]]\n",
      "[  19873.  -103340.   -31531.  1601800.     5992.9 1787200.  1959500. ]\n",
      "[  2.2016   9.0002   1.8013 -11.052  -21.207  -19.891  -60.938 ]\n",
      "[ -5.4268   3.6844  -4.7108  17.79    27.855   29.911  -94.021 ]\n",
      "[ -9.055    8.6218   3.5242 -23.774   55.622   59.954  -67.667 ]\n",
      "[  4.5408  -2.2205  -2.9486  -5.851   57.234   -8.6855 -41.957 ]\n",
      "[  7.5781   1.8535   3.0295 -16.097  -21.918   19.466  -23.44  ]\n",
      "[  7.8632    0.23486  -2.1774  -86.769   -19.389    -1.9782  -95.285  ]\n",
      "[ -12.321    18.022     2.0468 -235.96    548.07    769.3    1437.2   ]\n",
      "[  4.1578  -3.9599  -3.887  -22.833    7.4811   5.4503 -44.893 ]\n",
      "[ -2.9936   9.058    1.2901 -89.477  -10.475   16.663  -63.564 ]\n",
      "[  1.7739  -4.9588  -1.9878 -11.976   77.977   51.424   -7.3337]\n",
      "[  6010400. -22279000.  -8656500.  46773000. -18625000.  13783000.\n",
      "   4393100.]\n",
      "[  4.8824    2.333    -2.5011   -6.9147   -0.83475   5.515   -53.812  ]\n",
      "[ -8.301   -9.9924   3.7265  -2.3525  24.208   13.962  -47.475 ]\n",
      "[ -1.8362   2.334    4.5704 -36.09    22.847  -28.652  -18.476 ]\n",
      "[-7.5638e+00 -1.0417e+00  1.5603e-02 -5.9521e+01  3.0002e+01  6.8815e+01\n",
      " -6.2011e+01]\n",
      "[ -3.1791   1.0735   4.0139 -15.048  -22.939   -2.2187 -34.973 ]\n",
      "[  6.5148   3.0442   4.6329 -23.048   80.991   34.691  -40.938 ]\n",
      "[   0.82414    7.6136    -1.8528   -56.141      3.9735     6.231\n",
      " -103.06   ]\n"
     ]
    }
   ],
   "source": [
    "#find and fix errors in data (small number of trials had huge joint angles)\n",
    "err = np.argwhere(np.abs(jointPos) > 200)\n",
    "print(err)\n",
    "\n",
    "for i in err[:,0]:\n",
    "    print(jointPos[i])\n",
    "    jointPos[i] = jointPos[int(np.floor(np.random.rand()*np.shape(jointPos)[0]))]\n",
    "\n",
    "print(jointPos[17336])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "immune-recovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 6, 1000000)\n",
      "(1000000, 6, 10)\n",
      "(1000000, 10, 6)\n"
     ]
    }
   ],
   "source": [
    "#reshape traj data into 3d numpy array\n",
    "# t = np.zeros([trajPts,3,numTraj]) #net 1\n",
    "# for j in range(np.shape(traj)[0]):\n",
    "#     for i in range(np.shape(traj)[1]//3):\n",
    "#         t[j,:,i] = traj[j,3*i:3*(i+1)]\n",
    "        \n",
    "t = np.zeros([trajPts,6,numTraj]) #net 3\n",
    "for j in range(np.shape(traj)[0]):\n",
    "    for i in range(np.shape(traj)[1]//6):\n",
    "        t[j,:,i] = traj[j,6*i:6*(i+1)]\n",
    "\n",
    "        \n",
    "# print(t[:,:,0]) #same as in MatLab\n",
    "print(np.shape(t))\n",
    "#swap axis so batch size is first axis (for TF)\n",
    "t = np.swapaxes(t,0,2)\n",
    "print(np.shape(t)) #[numTraj, xyz, trajPts]\n",
    "#swap axis again so that conv1D moves on time and not xyz\n",
    "t = np.swapaxes(t,1,2)\n",
    "print(np.shape(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "whole-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from network import Net1 #optim for 1M linear dataset (not ideal because used inconsistant timesteps in solver)\n",
    "# from network import Net2 #optim for 100k time varying\n",
    "from network import Net3 #optim for data with position and rotation\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "#convert data from numpy to tensors\n",
    "x_train = tf.convert_to_tensor(t,np.float32)\n",
    "y_train = tf.convert_to_tensor(jointPos,np.float32)\n",
    "\n",
    "# print(tf.shape(x_train))\n",
    "# print(x_train[0,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "working-argument",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10, 6)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 10, 6)        24          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 8, 16)        304         batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 8, 16)        784         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8, 16)        64          conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 8, 16)        784         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 8, 16)        64          conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity (TensorFlo [(None, 8, 16)]      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 8, 16)        0           batch_normalization_2[0][0]      \n",
      "                                                                 tf_op_layer_Identity[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 8, 16)        0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 8, 32)        1568        re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 32)        128         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 8, 32)        3104        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 8, 32)        128         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_1 (TensorF [(None, 8, 32)]      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 8, 32)        0           batch_normalization_4[0][0]      \n",
      "                                                                 tf_op_layer_Identity_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 8, 32)        0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 8, 64)        6208        re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 8, 64)        256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 8, 64)        12352       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 64)        256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_2 (TensorF [(None, 8, 64)]      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 8, 64)        0           batch_normalization_6[0][0]      \n",
      "                                                                 tf_op_layer_Identity_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 8, 64)        0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 8, 128)       24704       re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 128)       512         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 8, 128)       49280       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 128)       512         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_3 (TensorF [(None, 8, 128)]     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 128)       0           batch_normalization_8[0][0]      \n",
      "                                                                 tf_op_layer_Identity_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 8, 128)       0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 8, 256)       98560       re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 256)       1024        conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 8, 256)       196864      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 256)       1024        conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_4 (TensorF [(None, 8, 256)]     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 256)       0           batch_normalization_10[0][0]     \n",
      "                                                                 tf_op_layer_Identity_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 8, 256)       0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 8, 512)       393728      re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 512)       2048        conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 8, 512)       786944      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 512)       2048        conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Identity_5 (TensorF [(None, 8, 512)]     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 512)       0           batch_normalization_12[0][0]     \n",
      "                                                                 tf_op_layer_Identity_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 8, 512)       0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 4096)         0           re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           262208      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64)           256         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64)           256         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           4160        batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64)           256         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 7)            455         batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None, 7)]          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 7)]          0           tf_op_layer_Mul[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,855,023\n",
      "Trainable params: 1,850,595\n",
      "Non-trainable params: 4,428\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "7032/7032 [==============================] - 105s 15ms/step - loss: 294.0004 - mean_squared_error: 294.0004 - val_loss: 354.8600 - val_mean_squared_error: 354.8600\n",
      "Epoch 2/30\n",
      "7032/7032 [==============================] - 104s 15ms/step - loss: 215.5478 - mean_squared_error: 215.5478 - val_loss: 227.1226 - val_mean_squared_error: 227.1226\n",
      "Epoch 3/30\n",
      "7032/7032 [==============================] - 104s 15ms/step - loss: 166.3030 - mean_squared_error: 166.3030 - val_loss: 170.8068 - val_mean_squared_error: 170.8068\n",
      "Epoch 4/30\n",
      "7032/7032 [==============================] - 104s 15ms/step - loss: 141.1358 - mean_squared_error: 141.1358 - val_loss: 155.9720 - val_mean_squared_error: 155.9720\n",
      "Epoch 5/30\n",
      "7032/7032 [==============================] - 104s 15ms/step - loss: 122.4008 - mean_squared_error: 122.4008 - val_loss: 136.1148 - val_mean_squared_error: 136.1148\n",
      "Epoch 6/30\n",
      "7032/7032 [==============================] - 103s 15ms/step - loss: 107.3470 - mean_squared_error: 107.3470 - val_loss: 204.2307 - val_mean_squared_error: 204.2307\n",
      "Epoch 7/30\n",
      "7032/7032 [==============================] - 103s 15ms/step - loss: 96.1425 - mean_squared_error: 96.1425 - val_loss: 152.5466 - val_mean_squared_error: 152.5466\n",
      "Epoch 8/30\n",
      "7032/7032 [==============================] - 104s 15ms/step - loss: 88.7993 - mean_squared_error: 88.7993 - val_loss: 291.6244 - val_mean_squared_error: 291.6244\n",
      "Epoch 9/30\n",
      "7032/7032 [==============================] - 104s 15ms/step - loss: 84.0483 - mean_squared_error: 84.0483 - val_loss: 200.6425 - val_mean_squared_error: 200.6425\n",
      "Epoch 10/30\n",
      "7032/7032 [==============================] - 104s 15ms/step - loss: 79.6154 - mean_squared_error: 79.6154 - val_loss: 91.4949 - val_mean_squared_error: 91.4949\n",
      "Epoch 11/30\n",
      "7032/7032 [==============================] - 104s 15ms/step - loss: 60.6630 - mean_squared_error: 60.6630 - val_loss: 55.7355 - val_mean_squared_error: 55.7355\n",
      "Epoch 12/30\n",
      "7032/7032 [==============================] - 105s 15ms/step - loss: 57.7983 - mean_squared_error: 57.7983 - val_loss: 59.9401 - val_mean_squared_error: 59.9401\n",
      "Epoch 13/30\n",
      "7032/7032 [==============================] - 104s 15ms/step - loss: 56.4429 - mean_squared_error: 56.4429 - val_loss: 46.1480 - val_mean_squared_error: 46.1480\n",
      "Epoch 14/30\n",
      "7032/7032 [==============================] - 105s 15ms/step - loss: 55.4081 - mean_squared_error: 55.4081 - val_loss: 45.5189 - val_mean_squared_error: 45.5189\n",
      "Epoch 15/30\n",
      "7032/7032 [==============================] - 104s 15ms/step - loss: 54.5565 - mean_squared_error: 54.5565 - val_loss: 51.0960 - val_mean_squared_error: 51.0960\n",
      "Epoch 16/30\n",
      "7032/7032 [==============================] - 104s 15ms/step - loss: 53.7747 - mean_squared_error: 53.7747 - val_loss: 46.1034 - val_mean_squared_error: 46.1034\n",
      "Epoch 17/30\n",
      "7032/7032 [==============================] - 104s 15ms/step - loss: 53.1062 - mean_squared_error: 53.1062 - val_loss: 54.5871 - val_mean_squared_error: 54.5871\n",
      "Epoch 18/30\n",
      "7032/7032 [==============================] - 104s 15ms/step - loss: 52.5521 - mean_squared_error: 52.5521 - val_loss: 58.7997 - val_mean_squared_error: 58.7997\n",
      "Epoch 19/30\n",
      "7032/7032 [==============================] - 105s 15ms/step - loss: 51.8922 - mean_squared_error: 51.8922 - val_loss: 55.3757 - val_mean_squared_error: 55.3757\n",
      "Epoch 20/30\n",
      "7032/7032 [==============================] - 105s 15ms/step - loss: 51.4753 - mean_squared_error: 51.4753 - val_loss: 45.8044 - val_mean_squared_error: 45.8044\n",
      "Epoch 21/30\n",
      "7032/7032 [==============================] - 104s 15ms/step - loss: 49.3513 - mean_squared_error: 49.3513 - val_loss: 40.1696 - val_mean_squared_error: 40.1696\n",
      "Epoch 22/30\n",
      "7032/7032 [==============================] - 105s 15ms/step - loss: 49.2166 - mean_squared_error: 49.2166 - val_loss: 39.5449 - val_mean_squared_error: 39.5449\n",
      "Epoch 23/30\n",
      "7032/7032 [==============================] - 105s 15ms/step - loss: 48.9931 - mean_squared_error: 48.9931 - val_loss: 39.7948 - val_mean_squared_error: 39.7948\n",
      "Epoch 24/30\n",
      "7032/7032 [==============================] - 105s 15ms/step - loss: 48.8393 - mean_squared_error: 48.8393 - val_loss: 39.5844 - val_mean_squared_error: 39.5844\n",
      "Epoch 25/30\n",
      "7032/7032 [==============================] - 105s 15ms/step - loss: 48.9360 - mean_squared_error: 48.9360 - val_loss: 40.1043 - val_mean_squared_error: 40.1043\n",
      "Epoch 26/30\n",
      "7032/7032 [==============================] - 104s 15ms/step - loss: 48.6915 - mean_squared_error: 48.6915 - val_loss: 39.3510 - val_mean_squared_error: 39.3510\n",
      "Epoch 27/30\n",
      "7032/7032 [==============================] - 104s 15ms/step - loss: 48.6609 - mean_squared_error: 48.6609 - val_loss: 39.2709 - val_mean_squared_error: 39.2709\n",
      "Epoch 28/30\n",
      "7032/7032 [==============================] - 104s 15ms/step - loss: 48.5549 - mean_squared_error: 48.5549 - val_loss: 39.4879 - val_mean_squared_error: 39.4879\n",
      "Epoch 29/30\n",
      "7032/7032 [==============================] - 104s 15ms/step - loss: 48.5141 - mean_squared_error: 48.5141 - val_loss: 40.8305 - val_mean_squared_error: 40.8305\n",
      "Epoch 30/30\n",
      "7032/7032 [==============================] - 103s 15ms/step - loss: 48.4740 - mean_squared_error: 48.4740 - val_loss: 39.0508 - val_mean_squared_error: 39.0508\n"
     ]
    }
   ],
   "source": [
    "# model = Net1()\n",
    "model = Net3()\n",
    "\n",
    "runLen = 30    \n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "#     part1 = 2*runLen//3\n",
    "#     part2 = 5*runLen//6 #net1\n",
    "\n",
    "    part1 = runLen//3\n",
    "    part2 = 2*runLen//3 #net2\n",
    "\n",
    "    if epoch < part1:\n",
    "        lr = 0.01\n",
    "        return lr\n",
    "    if epoch >= part1 and epoch < part2:\n",
    "        lr = 0.001\n",
    "        return lr\n",
    "    if epoch >= part2:\n",
    "        lr = 0.0001\n",
    "        return lr\n",
    "    \n",
    "#     if epoch < part1:\n",
    "#         lr = 0.001\n",
    "#         return lr\n",
    "#     if epoch >= part1 and epoch < part2:\n",
    "#         lr = 0.0001\n",
    "#         return lr\n",
    "#     if epoch >= part2:\n",
    "#         lr = 0.00001\n",
    "#         return lr\n",
    "\n",
    "#model1\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.MeanSquaredError()],)\n",
    "\n",
    "#model 3 - test with absolute loss?\n",
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(lr=0.001, clipvalue = 0.001),\n",
    "# #     optimizer = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9, clipvalue=1.0),\n",
    "#     loss=tf.keras.losses.MeanSquaredError(),\n",
    "#     metrics=[tf.keras.metrics.MeanSquaredError()],)\n",
    "\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)\n",
    "\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "#for 1M linear dataset\n",
    "# trace = model.fit(x=x_train, y=y_train, batch_size=128, epochs=runLen, verbose=1, \n",
    "#                   validation_split=0.1, callbacks = [callback], shuffle=True) \n",
    "#New Changes- added 512 conv layer to network #Increases performance drastically (reaches val error of 89.0 in <30 epoch) \n",
    "#             adding another layer of 1024 (reaches val error of ~81.5 in <30 epoch)\n",
    "\n",
    "# for 1M dataset with endpoint angles\n",
    "trace = model.fit(x=x_train, y=y_train, batch_size=128, epochs=runLen, verbose=1, \n",
    "                  validation_split=0.1, callbacks = [callback], shuffle=True)\n",
    "#new changes: added 512 layers back in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "promotional-howard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.0, 500.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAD3CAYAAACzfEh4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAA2dUlEQVR4nO3deXhV5b33//d37+xMJEwhgTAj8yRQBie0WGfqyLEVa61aj3awrVXbqm3P0/Y8tcdfrbX19LGtPU49jrTWirNoVVRQCYrKEAYZw5BAIIEAmfa+f3+sFdgJCQSSnZXsfF7Xta81r/Xdyy18WPda9zLnHCIiIiISnFDQBYiIiIh0dgpkIiIiIgFTIBMREREJmAKZiIiISMAUyEREREQCpkAmIiIiErCEBjIzW29mn5rZEjMr8Of1NLN5ZrbaH/aIW/92M1tjZivN7JxE1iYiIiLSXrTFFbLTnXMTnXNT/OnbgNedc8OB1/1pzGwMMBsYC5wL3Gdm4TaoT0RERCRQQTRZXgQ84o8/AlwcN/9J51yVc24dsAaY1vbliYiIiLStRAcyB7xqZovN7Hp/Xm/n3FYAf5jnz+8HbIrbtsifJyIiIpLUUhK8/1Occ1vMLA+YZ2aFh1nXGpl3yHud/GB3PUCXLl0mjxo1qnUqFREREUmgxYsX73DO5Ta2LKGBzDm3xR+WmNkzeE2QxWaW75zbamb5QIm/ehEwIG7z/sCWRvZ5P3A/wJQpU1xBQUEiv4KIiIhIqzCzDU0tS1iTpZl1MbPsunHgbGApMBe4yl/tKuBZf3wuMNvM0sxsCDAc+CBR9YmIiIi0F4m8QtYbeMbM6o7zuHPuZTNbBMwxs2uBjcCXAJxzy8xsDrAcqAVucM5FE1ifiIiISLuQsEDmnFsLTGhkfilwRhPb3AHckaiaRERERNqjRN/U3+ZqamooKiqisrIy6FISLj09nf79+xOJRIIuRURERFog6QJZUVER2dnZDB48GL+5NCk55ygtLaWoqIghQ4YEXY6IiIi0QNK9y7KyspKcnJykDmMAZkZOTk6nuBIoIiKS7JIukAFJH8bqdJbvKSIikuySMpAFraysjPvuu++ot5s5cyZlZWWtX5CIiIi0awpkCdBUIItGD9+Lx4svvkj37t0TVJWIiIi0V0l3U397cNttt/HZZ58xceJEIpEIWVlZ5Ofns2TJEpYvX87FF1/Mpk2bqKys5MYbb+T6673XfA4ePJiCggIqKio477zzmD59OgsWLKBfv348++yzZGRkBPzNREREJBF0hSwB7rzzToYOHcqSJUu46667+OCDD7jjjjtYvnw5AA8++CCLFy+moKCAe++9l9LS0kP2sXr1am644QaWLVtG9+7defrpp9v6a4iIiEgbSeorZL94bhnLt+xu1X2O6duVn10w9qi2mTZtWr2uKe69916eeeYZADZt2sTq1avJycmpt82QIUOYOHEiAJMnT2b9+vUtqltERETar6QOZO1Fly5dDoy/+eabvPbaayxcuJDMzExmzJjRaNcVaWlpB8bD4TD79+9vk1pFRESk7SV1IDvaK1mtJTs7mz179jS6rLy8nB49epCZmUlhYSHvvfdeG1cnIiIi7U1SB7Kg5OTkcMoppzBu3DgyMjLo3bv3gWXnnnsuf/rTnzj++OMZOXIkJ554YoCVioiISHtgzrmgazhmU6ZMcQUFBfXmrVixgtGjRwdUUdvrbN9XRESkozKzxc65KY0t01OWIiIiIgFTIBMREREJmAKZiIiISMAUyEREREQCpkAmIiIiEjAFMhEREZGAKZC1A1lZWUGXICIiIgFSIBMREREJmHrqT4Bbb72VQYMG8e1vfxuAn//855gZ8+fPZ9euXdTU1PDLX/6Siy66KOBKRUREpD3QFbIEmD17Nk899dSB6Tlz5nDNNdfwzDPP8OGHH/LGG29wyy230JHfkiAiIiKtJ7mvkL10G2z7tHX32Wc8nHfnYVeZNGkSJSUlbNmyhe3bt9OjRw/y8/O56aabmD9/PqFQiM2bN1NcXEyfPn1atz4RERHpcJI7kAXo0ksv5e9//zvbtm1j9uzZPPbYY2zfvp3FixcTiUQYPHgwlZWVQZcpIiIi7UByB7IjXMlKpNmzZ3PdddexY8cO3nrrLebMmUNeXh6RSIQ33niDDRs2BFabiIiItC/JHcgCNHbsWPbs2UO/fv3Iz8/niiuu4IILLmDKlClMnDiRUaNGBV2iiIiItBMKZAn06acH71/r1asXCxcubHS9ioqKtipJRERE2iE9ZSkiIiISMAUyERERkYApkImIiIgELCkDWWfpcLWzfE8REZFkl/BAZmZhM/vIzJ73p3ua2TwzW+0Pe8Ste7uZrTGzlWZ2zrEcLz09ndLS0qQPK845SktLSU9PD7oUERERaaG2eMryRmAF0NWfvg143Tl3p5nd5k/famZjgNnAWKAv8JqZjXDORY/mYP3796eoqIjt27e33jdop9LT0+nfv3/QZYiIiEgLJTSQmVl/4IvAHcDN/uyLgBn++CPAm8Ct/vwnnXNVwDozWwNMAxrvK6IJkUiEIUOGtLh2ERERkbaS6CbL3wE/AmJx83o757YC+MM8f34/YFPcekX+vHrM7HozKzCzgs5wFUxERESSX8ICmZmdD5Q45xY3d5NG5h1yI5hz7n7n3BTn3JTc3NwW1SgiIiLSHiSyyfIU4EIzmwmkA13N7FGg2MzynXNbzSwfKPHXLwIGxG3fH9iSwPpERERE2oWEXSFzzt3unOvvnBuMd7P+v5xzXwXmAlf5q10FPOuPzwVmm1mamQ0BhgMfJKo+ERERkfYiiHdZ3gnMMbNrgY3AlwCcc8vMbA6wHKgFbjjaJyxFREREOiLryP11TZkyxRUUFARdhoiIiMgRmdli59yUxpYlZU/9IiIiIh2JApmIiIhIwBTIRERERAKmQCYiIiISMAUyERERkYApkImIiIgETIFMREREJGAKZCIiIiIBUyATERERCZgCmYiIiEjAFMhEREREAqZAdiT7dkLl7qCrEBERkSSmQHY4ZZvgN8Phk6eCrkRERESSmALZ4XQfADnDYek/gq5EREREkpgC2ZGMmwUbF8LuLUFXIiIiIklKgexIxs4CHCz7Z9CViIiISJJSIDuSXsOgz3hYpmZLERERSQwFsuYYOwuKFkHZxqArERERkSSkQNYcYy/xhsueCbYOERERSUoKZM3Rcwj0naSnLUVERCQhFMiaa+ws2LoEdq4NuhIRERFJMgpkzaVmSxEREUkQBbLm6j4A+k+DpQpkIiIi0roUyI7GuFlQ/CnsWB10JSIiIpJEFMiOxpiLAdPN/SIiItKqFMiORtd8GHSyOokVERGRVqVAdrTGXgLbC6F4edCViIiISJJQIDtaYy4CC+kqmYiIiLQaBbKjlZUHg6d795E5F3Q1IiIikgQUyI7F2Fmw8zPY9knQlYiIiEgSUCA7FqMvBAurk1gRERFpFQkLZGaWbmYfmNnHZrbMzH7hz+9pZvPMbLU/7BG3ze1mtsbMVprZOYmqrcW65MBxM9RsKSIiIq0ikVfIqoAvOOcmABOBc83sROA24HXn3HDgdX8aMxsDzAbGAucC95lZOIH1tcy4WVC2AbZ8GHQlIiIi0sElLJA5T4U/GfE/DrgIeMSf/whwsT9+EfCkc67KObcOWANMS1R9LTbqixCKqJNYERERabGE3kNmZmEzWwKUAPOcc+8DvZ1zWwH8YZ6/ej9gU9zmRf689imjBww7A5b9E2KxoKsRERGRDiyhgcw5F3XOTQT6A9PMbNxhVrfGdnHISmbXm1mBmRVs3769lSo9RmNnwe4iKFoUbB0iIiLSobXJU5bOuTLgTbx7w4rNLB/AH5b4qxUBA+I26w9saWRf9zvnpjjnpuTm5iaybPZU1vD/vVzImpKKxlcYeR6E09RJrIiIiLRIIp+yzDWz7v54BnAmUAjMBa7yV7sKeNYfnwvMNrM0MxsCDAc+SFR9zVFdG+N/F27gzpcKG18hvSsMP8tvtoy2aW3SyrZ8BEufDroKERHppBJ5hSwfeMPMPgEW4d1D9jxwJ3CWma0GzvKncc4tA+YAy4GXgRucc4GmnJysNL41YyivrSjmvbWlja809hKo2AYbF7ZtcdK6XvkpPH0d7FwXdCUiItIJJfIpy0+cc5Occ8c758Y55/7Tn1/qnDvDOTfcH+6M2+YO59xQ59xI59xLiartaFw7fQj53dL51YsriMUa6XNsxLmQkqGnLTuyvaWwcQG4KCy4N+hqRESkE1JP/UeQHgnzg7NH8klROc99csgtbZCWBSPOgeXPQrS27QuUllv1MrgY9J8GHz0Ke7YFXZGIiHQyCmTNcMmkfozJ78qvX15JZU0jrajjZsG+HbDhnbYvTlqu8AXo2g8u+RPEamHhH4KuSEREOhkFsmYIhYyffHE0m8v288iC9YeuMPxsSM1Ss2VHVL0PPvuX19FvzlAY92+w6EHYt/PI24qIiLQSBbJmOmVYL04fmcsf3ljDrr3V9RdGMrwuMFbMhWhNMAXKsVn7BtTu9wIZwPSboGYvfHB/sHWJiEinokB2FG6fOZq9VbXc+6/Vhy4cOwv274K1b7V9YXLsCl+A9G4w6BRvuvdYGDkT3vsjVO0JtjYREek0FMiOwoje2Vw2dQCPvreB9Tv21l847AxI66pOYjuSaC2sfAmGnwPhyMH502+GyjJY/HBQlYmISCfTrEBmZjeaWVfzPGBmH5rZ2Ykurj266cwRRMIhfv1Kg85iU9K8Zq8Vz0NtVTDFydHZ9B7s33mwubLOgKkw5DRY8AeoqQymNhER6VSae4Xs68653cDZQC5wDX6Hrp1NXtd0rj/tOF78dBuLN+yqv3DsLKgq924Sl/av8AXv1VfDzjh02am3eB3+fvx429clIiKdTnMDWd2Lv2cCDznnPqbxl4F3Ctedehy52Wnc8cJynIvrLPa4GZDeXU9bdgTOeYHsuBmQln3o8iGfh36T4Z3fqX85ERFJuOYGssVm9ipeIHvFzLKBWOLKat+6pKVwy1kj+HBjGS8vjetENCUVRl8AK1+Emv3BFShHVrwMyjYc2lxZx8y7Sla2QfcFiohIwjU3kF0L3AZMdc7tAyJ4zZad1pemDGBE7yzufLmQ6tq4bDpuFlRXwOp5wRUnR1b4AmBedyVNGXEe5I6Gd+6BWKf994eIiLSB5gayk4CVzrkyM/sq8FOgPHFltX/hkHH7zNFsKN3HY+9vOLhg8GmQ2UtXVdq7wudhwDTIymt6nVAITr0ZSpZ7r1cSERFJkOYGsj8C+8xsAvAjYAPw14RV1UHMGJHLKcNy+P3rqynf73cIG06BMRfCqlegeu/hdyDBKNsI2z5purky3thZ0H0QvP0b774zERGRBGhuIKt13t3rFwG/d879HmjkTujOxcz48czRlO+v4b431xxcMHYW1OzzQpm0Pytf8oajzj/yuuEUmP592LwY1s1PaFkiItJ5NTeQ7TGz24ErgRfMLIx3H1mnN7ZvNy6Z1I+H3l1P0a593sxBJ0NWbzVbtleFz0PuKO/dlc0x4SuQ1QfevjuxdYmISKfV3EB2GVCF1x/ZNqAfcFfCqupgfnD2SAz4zSsrvRmhMIy5yLuxX6/faV/27YT173qvR2quSDqc/B1Y9xYUFSSuNhER6bSaFcj8EPYY0M3MzgcqnXOd/h6yOn27Z3Dt9CH8c8kWPikq82aOnQW1lQebx6R9WP0quGjzmivjTb7G62Pu7d8mpCwREencmvvqpC8DHwBfAr4MvG9mlyaysI7mWzOGktMllV+9uMLrLHbACZDdV53EtjeFz0N2PvSddHTbpWXBid+ClS9A8fLE1CYiIp1Wc5ssf4LXB9lVzrmvAdOA/0hcWR1PdnqEG88czntrd/L6ihKvy4Sxl8Ca12B/WdDlCXid9a75l9dcGWruTz/OtOsh0sXrl0xERKQVNfdvpZBzriRuuvQotu00Lp82kON6deG/XlpBbTTmdRIbq/E7IZXArX0LavY2r7uLxmT2hKlfh6V/h53rWrc2ERHp1Jobql42s1fM7Gozuxp4AXgxcWV1TJFwiFvPG8Vn2/fy5KJN3rsQuw/U05btReHzkNYVBp967Ps46TsQSoF3f996dYmISKfX3Jv6fwjcDxwPTADud87dmsjCOqqzx/Rm2uCe/O61VVRUR71my7Vvek/3SXBiUe8Bi+Fnee8cPVbZfWDSV2HJY7B7a+vVJyIinVqzmx2dc0875252zt3knHsmkUV1ZGbGj784mh0V1fz5rc+8py1jtbDiuaBL69w2fQD7dhx7c2W8k7/nBbyFf2j5vkRERDhCIDOzPWa2u5HPHjPb3VZFdjQTB3Tnggl9+cvba9mWORJ6HufddyTBWfkChCIw7KyW76vnEBh/KRQ8pCufIiLSKg4byJxz2c65ro18sp1zXduqyI7oR+eMJBaDu+et8pq41s2HT/4WdFmdk3Ow4nk47vOQ3ko/2+k3eQ8IvP/n1tmfiIh0anpSMkEG9MzkqpMH8fcPi1gx5GoYeBI89z0oWRF0aZ3P9kLYte7oeuc/krzRXuey7/9Jb2MQEZEWUyBLoO+cPpyu6RF+9coauPQhSM2Cp67UX+BtrfB5b9iagQxg+s1QWeY1XYqIiLSAAlkCdcuM8N0vDOPt1TuYvy0FLn0Qdn4Gc7/rNaNJ2yh8AfpNga75rbvf/pPhuBnezf01la27bxER6VQUyBLsypMGMaBnBv/3+eXs7XsSfOE/YNkzuveorZRvhi0ftc7TlY059RaoKPa6wRARETlGCmQJlpYS5o6Lx/PZ9gpuePxDak/6How4D179idcVgyTWSr//4qN9mXhzDT4V+k+Fd38H0drEHENERJKeAlkbOG1ELr+8eDxvrtzOT59djrv4j9CtP/ztati7I+jyklvhC5AzDHJHJGb/Zt5VsrKNsPTpxBxDRESSXsICmZkNMLM3zGyFmS0zsxv9+T3NbJ6ZrfaHPeK2ud3M1pjZSjM7J1G1BeErJwzkO6cP48lFm/jDwh3w5b96Yezpa71ORqX17S+D9W8nrrmyzvBzIG8svPNbiMUSeywREUlKibxCVgvc4pwbDZwI3GBmY4DbgNedc8OB1/1p/GWzgbHAucB9ZhZOYH1t7pazRzDrc/24e94q/r4lB774G++1Sm/eGXRpwajcDTvXJm7/q+d5b0lIVHNlnVAITr3Z615jpV7xKiIiRy9hgcw5t9U596E/vgdYAfQDLgIe8Vd7BLjYH78IeNI5V+WcWwesAaYlqr4gmBl3zjqe6cN6cdvTn/B29nkw8asw/9ew6tWgy2tbsRg8dincdxIULU7MMVa+AF3yvCcsE23MxdBjCLx9t56gFRGRo9Ym95CZ2WBgEvA+0Ns5txW80Abk+av1AzbFbVbkz0sqqSkh7vvq5xiWl8W3Hv2QFZ/7P9B7PPzjOti1Iejy2k7BA7DpfQinwpOXQ3lR6+6/tsq7QjZqpncFK9HCKTD9+7DlQ1j3VuKPJyIiSSXhf1OZWRbwNPB959zh3n9pjcw75FKDmV1vZgVmVrB9+/bWKrNNdU2P8NA1U8lOT+HqRz9l23n3g4vB367ygkSyK98Mr/0Cjjsdrn0VavbDE7OhqqL1jrFuPlRXJL65Mt6EyyEzBxY90HbHFBGRpJDQQGZmEbww9phz7h/+7GIzy/eX5wMl/vwiYEDc5v2BLQ336Zy73zk3xTk3JTc3N3HFJ1h+twweumYq+6qifO2Z7eyd+Qevv6yXbwu6tMRyDl78oXdv1/n3eK8guvQhKF4Gz3yj9W6KL3zeezPCkNNaZ3/NkZLmhbKVL0JFyZHXFxER8SXyKUsDHgBWOOd+G7doLnCVP34V8Gzc/NlmlmZmQ4DhQFJ31DWqT1f+fOVk1u3Yy7Xv51F70neh4EH4+KmgS0ucFXO9e7tOvx16DvHmDT8TzvkvL0S9/ouWHyMWg5UvwbAzvZDUliZf7YVNdRQrIiJHIZFXyE4BrgS+YGZL/M9M4E7gLDNbDZzlT+OcWwbMAZYDLwM3OOeSvj+Ik4f14q5LJ/De2p38oPQi3MCT4bkboXh50KW1vv1l3tWxPsfDiTfUX3bCN2DK170OVj9qYZjZvNjrPb8tmyvr9BoOg6bD4kfUBYaIiDRbIp+yfMc5Z865451zE/3Pi865UufcGc654f5wZ9w2dzjnhjrnRjrnXkpUbe3NxZP68cNzRvLPT0r4Q85PIL0rzLnS6xYimbz2M9i7HS6817sJPp4ZnPdrGPJ5L5BuWHjsxyl8HkIpMPysltV7rCZfDbvWwfr5wRxfREQ6HPXU3058e8ZQrjhhIHcvLOfl0f8FO9fB3O8kTxcK69+FxQ/Did+GvpMaXyccgS8/Aj0GwVNXeOfgWBS+4L3SKKP7sVbbMqMvgIwe3lUyERGRZlAgayfMjF9cOJYzRuXx7XfSWTX+Zlj+LLz3x6BLa7maSu+qV/eBcPqPD79uRg/4yhzv7QVPzIbK8qM71vZVULo68b3zH04k3bu5f8VzejWWiIg0iwJZO5ISDvHfX5nE+H7duPCjz1E28GyY9x+w8b2gS2uZt+/2QtL590BqlyOvnzMULvtfKF0Df//60b20u/B5bzjyvGOrtbV87iqI1cCSx4OtQ0REOgQFsnYmMzWFB66eSl52BhcWXUFNtv8S8oqO2ecaJSvgnXtg/Je9px6ba8hpMPM3sOY1ePUnzd9u5Ytek2i3/kdfa2vKGwUDToQPH0meZmcREUkYBbJ2qFdWGg9fM5U9ZPLNqhtx+3fB01/veC8hj8Vg7vcgLRvO/a+j337KNd49Z+//qXmdre7ZBkWLgm2ujDf5au8q34Z3g65ERETaOQWyduq43Cz+56opvFORz39nfNPref6NO4Iu6+gUPABFH8A5v4IuvY5tH2f/Eoaf7XWXsfbNw69b92LvILq7aMzYiyG9m/cwg4iIyGEokLVjkwf15PezJ3HPjmnei8jfvhuev8l7YrG993EV/3qkCbOPfT+hMPzbA9BrBMz5GuxY3fS6hS94L/jOHXXsx2tNkQw4fjYsnwv7dh55fRER6bQUyNq5c8f14Wfnj+Hft1/GRz3Pwy15Ah6eCfeMhZd/DEUF7e8eJefgxR8cfD2SNfaa0qOQ3hW+8qTXt9jjlzUebip3w9q3vObKlh6vNU2+CqJV8PGTQVciIiLtmAJZB3D1KUP42qkjuWTLlfxgyNPsmvkn78b1RX+B/zkDfn88zPsZbP2kfYSz5c96zYfxr0dqqR6DYfbjUL7Ju1IWram/fM1r3lON7aW5sk7vsdB/qtds2R7+24iISLukQNZB3H7eaG48YzjPrdjNyc/14L/zfkHl91fBxX+EXiNh4R/gz6fCH6bCG7+CksJgCt2/C176UeOvR2qpgSfChf8N69+GF26pH3AKX4DMXjBgWuseszVMvhp2rOz43ZeIiEjCKJB1EKGQcdNZI3j95s8zY2Qud89bxZn3fcRL4dNxV/wNblkF5/8OuubDW7+G+06A+06G+b+BnWvbrtB5h3k9UmuYMBum3+x1J1HXaW5tNax+1et7LBRu/WO21NhLIK2rV7OIiEgjzHXgZpQpU6a4goKCoMsIxII1O/jFc8tZWbyHk47L4f9cMIbR+V29hXu2ec2GS/8Bm/yrMn0nwbh/88JBovroWv8OPPxFOOk7cE4CnwiNxbx3fa58ES5/ygthj86Cy58MvkPYpjx/Myx5DG4p9N5GICIinY6ZLXbOTWl0mQJZx1UbjfHEBxu5e94qdu+v4YoTBnHzWSPo0SX14Eplm2D5P2Hp07DlI2/eoOlw0g0w4lwItdJF0ppK+NMpEK2Gb7/XvB75W6J6Lzx4rve+ywFTvebAH631nmxsj7Z+4jUpn/drOOEbQVcjIiIBUCBLcmX7qrln3ioefX8jWWkp3HzWCK44YSAp4QZha+daL5gt/iuUb/S6kjj5u3D8ZZCS1rIi/vVLmH8XfPUfMOyMlu2ruco3w1++ABXbvBd6X/Zo2xz3WN1/OtRWwbfebV9PgoqISJs4XCDTPWRJoHtmKr+4aBwvfu9Uxvbtys/mLmPmvW/z7poGL7bueRyc9kP43kde314p6TD3u/C78V4fZ/t3HVsBxcu91yMdf1nbhTGAbv3g8schqw9M+lrbHfdYTb4KSpZ5XZWIiIjE0RWyJOOc45Vlxdzx4nI27dzPOWN785OZYxiYk9nYyl7v9wvuhc/+BalZ3kuxT/wWdB/QvAPGovDgOVD6GXxn0bH3yN8SznWMK05Ve+DuUTDmYrj4/wVdjYiItDFdIetEzIxzx/Vh3k2f54fnjGT+qh2cec9b3PVKIXurahuuDENPhyufgW++43Wq+v6f4PcT4OnrYNunRz7goge890ee+1/BhDHoGGEMvHd6jr8Ulv0DKsuDrkZERNoRXSFLctvKK7nzpRX8c8kWendN47bzRnHxxH5YUyGmbJPXncSHj0B1BQz9Apz8PThuxqHBp7wI/t8JXsenVz7TcYJRkDZ/CH85Hb54N0z996CrERGRNqSb+oXFG3byi+eW80lROcf378a104cwc3w+kYY3/tfZvwsKHoT3/wwVxdBnPJx8o9dtRjjFayZ84nKvyfPbC1uvR/5k5xz8+TRv+M23FWJFRDoRBTIBIBZz/P3DIu57Yw3rS/fRu2saV544iMunDSQnq4mnLGur4JOnYMF/w45V0G2A12VGWld49ttw1v+FU77Xtl+ko1v0ALxwM1z3L+g3OehqRESkjSiQST2xmOPNVSU89O563l69g9SUEBdN6Ms1pwxhTN+uTW0Eq172HgDYuNCblz8B/v1fiemRP5lV7oa7R8L4L3lvNBARkU5BgUyatLp4D48sXM/TizezvybKCUN6cs0pgzlzdO9D+zGrs2kRfPw4TPsG5I1q24KTxbM3wNJn4AcrvZv9RUQk6SmQyRGV76vhqYKNPLJgA5vL9tOvewZfO2kQs6cOpFtmJOjykk9RAfzPGd77R6dcE3Q1IiLSBhTIpNmiMce85cU8vGAd763dSUYkzKzP9ePqkwczvLeu5LQa5+BP0yEcgevfDLoaERFpA4cLZLr5R+oJh7x+zM4d14flW3bz8IJ1/G1xEY+9v5FTh/fimlMGM2NEHqGQng5sETOvE96XfghblkDfiUFXJCIiAdIVMjmi0ooqnly0ib8uXE/x7ioG52Ry1cmDuWRSP7pnph55B9K4/WXezf0TvwLn3xN0NSIikmBqspRWURON8fLSbTz07jo+3FhGJGycNjyXCyf25czRvemSpguuR+2Zb8GK57yb+1O7BF2NiIgkkJospVVEwiEumNCXCyb0ZenmcuZ+vIXnPt7C64UlpEdCnDG6NxdO6MuMkbmkpYSDLrdjmHyV98Tq0n/A564MuhoREQmIrpBJi8RijoINu5j78WZe/HQbO/dWk52ewrlj+3DhxL6cdFxO091niHdz/30nei92v+71oKsREZEEUpOltImaaIwFn5Uyd8kWXl22jT1VtfTKSmXm+HwunNCXzw3soYcBGvPeH+Hl2+Cb70KfcUFXIyIiCaJAJm2usibKmytLmPvxFl5fUUJVbYx+3TM4f4IXzsbkd236Beedzb6dcPcor/ly5l1BVyMiIgmiQCaBqqiqZd7ybcxdsoW3V++gNuYYmtuFCyb05Yvj8xmWl6Vw9vR1sOoVuKUQUjODrkZERBIgkEBmZg8C5wMlzrlx/ryewFPAYGA98GXn3C5/2e3AtUAU+J5z7pUjHUOBrOPZubeal5ZuZe6SLXywfifOQV52GicPzeHkob04aWgOA3p2wkCy/l14eCZc/EevGwwREUk6QQWy04AK4K9xgezXwE7n3J1mdhvQwzl3q5mNAZ4ApgF9gdeAEc656OGOoUDWsW0rr+TNlSUs+KyUBZ+VsqOiCoABPTM4xQ9nJw3NIS87PeBK24Bz8IepkJkD1x7x3yIiItIBBdLthXNuvpkNbjD7ImCGP/4I8CZwqz//SedcFbDOzNbghbOFiapPgtenWzqzpw1k9rSBOOdYXVLBgjU7WPBZKS9+upUnF20CYHhelncFbVgvThySk5zv1jTz7iF79adQsgLyRgddkYiItKG27oest3NuK4BzbquZ5fnz+wHvxa1X5M87hJldD1wPMHDgwASWKm3JzBjRO5sRvbO5+pQhRGOO5Vt2s+AzL6DNKSjikYUbMINxfbsdCGhTB/cgMzVJutOb8BV4/T9h8SNw3p1BVyMiIm2ovfxN1tgd3Y22pTrn7gfuB6/JMpFFSXDCIWN8/26M79+Nb3x+KNW1MT4uKmPBmlIWfLaDh95dz5/nryUSNib07864ft38QJfF8N7ZdMvogFfRuuTA6Avg4yfgzJ9DpBM01YqICND2gazYzPL9q2P5QIk/vwgYELdef2BLG9cm7VhqSoipg3sydXBPbjxzOPuroyzesIsFn+3gvbWl/K1gE3urD95y2KdrOsN7ZzHSv+o2ok82w/Oy2v/rnSZfDUufhhVz4fgvB12NiIi0kbb+22kucBVwpz98Nm7+42b2W7yb+ocDH7RxbdKBZKSGmT68F9OH9wK8NwZsKd/PquI9rCqu8Id7ePT9DVTWxA5s1697BiP7ZDO8dxYj8rIZ2SeboblZZKS2k1c9DT4Veh4HC+6F4WdDRvegKxIRkTaQyKcsn8C7gb8XUAz8DPgnMAcYCGwEvuSc2+mv/xPg60At8H3n3EtHOoaespQjicYcm3buY1XxHlaXVLBymxfU1m7fS3XUC2pmMLBnJsf16kJ+9wzyu6bTp1s6+d0y/GF6215ZWz4X/v516DEYLn8Seg1ru2OLiEjCqGNYkQZqozHWl+5jddwVtXU79lK8u5LSvdWHrJ+dnkJ+t3T6dDsY2Pp296e7edPZaSmt18HthgXw1FchVguXPgTDzmid/YqISGAUyESOQmVNlJLdVWwt38+23ZVsLa9kW3mlN13uTW+vqKLh/zpdUsP06ZZO767xn7QDw7zsdPK6ppGW0szm0V0b4InLYfsKOOdXcMI3vct5IiLSIQXSD5lIR5UeCTMwJ5OBOU2/MaAmGqNkTxXbyvfHBTYvtBXvrmLR+p2U7K460Cwar0dm5JDAltc1nd7ZaQfm52anEe4xCK59FZ75hvfy8eJl8MXfQkpqIr++iIgEQIFM5BhEwiH6dc+gX/eMJtdxzlG2r4biPZUU766iuLyS4t2VB6ZLdldSuG032/dUEWtwta1XVipXnDCIK04cSN6X/xfe/BXMvwtK18CX/xeychP8DUVEpC2pyVIkYNGYo7SiygttuyvZtruSNwpLeL2whNRwiAsm9OWaUwYzbtdr8M9vQ5dcuPwJ6DM+6NJFROQo6B4ykQ5o7fYKHlmwnr8tLmJfdZRpQ3ry/TF7OemD72KV5TDrz15HsiIi0iEokIl0YOX7a5izaBMPL1jP5rL9TOyxn/sj95C3eymc/hM47Ye62V9EpAM4XCALtXUxInJ0umVEuO6043jrhzP44xWfI9KtL6eW/IC57lR44w72Pv41qN4XdJkiItICukIm0gF9UlTGQ++sI3/Zn/lB6Ek2pg1nx/kPMnn8uNbrC01ERFqVmixFklTJ7kreffFRzir8KftcGr/K/gknf/48LpzYl/RIO3kdlIiIAApkIkmvastSah69jNR9xdxa/e/MzziDy6cNZFR+Nt0yIvU+2ekRwqFmXkWrqoBQGCJNd+8hIiLNo45hRZJcWt9xpH3nbdycK7ln/R95OauUG968kKhr7DZRR//0Soak7WFg6h76p5TTJ1ROLmX0dLvoFt1Jdk0pmdXbSandRyycRkX/09g/9Dxqh55DJLsXaSlh0iIhUsMhQs0Nd9Iy0VrYWwIVxbCnGCq2HRzGaiEzBzJ7+cO6T09vmJatBz9E2jldIRNJJtEaeOlWKHiA6iFfYHfOJKK7t2EV20jZV0Lq/u1kVO8g7GoP2XQv6ZS47pS47mz3hyWuO71tF2eHC+hnpdS6EO/HRvNybCqvRqdQTE9SwyHSUkKkRUIHglpaStiblxIiLRI+sE4kbETCISIpXpg7MB0OkRq33BuvW8efnxIiEgqREjYiYSPlwHiIlJA/9OdHwkZK3PxmXxEMQs1+2LPND1rboKKkftiqG+7dATTy53VGTwhHYF+pF8waE049NKTVC289vf7t+oz3xkUkIdRkKdLZLPofeOk2iNV4f2Fn94Gs3g2GeZDV5+C8tCzAe5fn7v017K6soXx/DXsqa6muiZK+41Nyi+bRd+s8uu1dB8C2rLEU9pjB0q6nsTWlH1W1Me9TE/XH/WFNjJpo3cdRVRs/7c1LJDOINAhqKXGhLj64HVgeN68uAIbDRiRkhP19hf31wv5+Dk7Hza+bthjd928id88Keu5ZQc/dy+lWvorUmvJD6nUWpjojl5qMXGozcqnN7E20Sx61mXnEsnrjuvTGZfXGdckjHEnz9w8ptRVEKncRrtpJSuVOQvvrPqVeYGv42b/r0JOVMwz6T4MBU6H/VMgb4zVbi0iLKZCJdEbVeyEUScy7L7evhBXPQeHzsOUjb17uaBh9vtdZbZ/jj6qJzDlHTdQdCGjV0RjVtbED86prDwa32miMmpg/jDpqYzFq/fVqG8yviTqiNVVk7ttC1v7NZFdupkvVdipCXdmZkkdpOI8d4V6U0Y1a57z9xBzRum3j9heNOWr8Y0Vj3vFizlEbc0Sj/jDmHTfkahlmWxgXWsdYW8+40DrG2Aa6WBUAlS7CCjeI5bFBbHa9KKH+VcmdZONasVciM+KCYuhAYEy1GN1De8mxPfS2XYyKrWFsbCVjoivp7ryguJ90VkdGsCoymtWpo1iTOpq9Kd0Jmbc/MyNsEDIjFDJSU0J0SQ3TJS2FLqkp3jAt7I978zNTU8hKSyEzNUxWmrdOaop6YZLkp0AmIolTtgkKX/DC2YZ3wcWg20AvmI0+HwackNgrLLEo7N4CZRuhbAPs2lB/uHsLjTb1xUtJh659oVt/6NrfG3brFzfdz7sPqzE1lVCyHLZ+fODjipdhUS98uUgXor3HU5M3nprc8VTljaey2zCihKmNxYjGvNdnHQh3deNRbxiNOaLOC31R54jVTccafFxdgKwLhl6wrI152xwMjAeDY8P1Y87/RB09a7YwpHI5QyqXM7RqOQOq15JCFIBt4XxWRUZTmDKSwpTRrA0PppYQsRhU1UbZVx2loqqWvVW1h7yntSmRsB0IcZmpYUJm9TK9mWEczPlmYJg/PLDSgXWswTbx43X7PrC9vyxUbz2L20/8ut543UEPOU7cNHHbAdT9des4MHJgUPd3cd3pco0siz8PjdUa8o8XCnkHrzfP4r9T4/9YaurfUE390+rgf4u4Pcbt3+qdo7pxqze/sYM2nNNYXQ2/Q8N17HDLmviig3IyOf/4vo0uay0KZCLSNvbugJUveVfP1r4B0Wrv3qQR50CXPAil+J/QwXEL++Nh/5MStyxuvVAYqvYcGrrKi7ym2QPMC1fdB0GPQfWH3QdCdj5UlnnblRfB7s1QvgnKNx+c3rPVC5bx0rvVD2u11V4A277i4L1b6d0gf4L/megNex6XHE1+1ftg6xIoWgSbPvCGFcXeskgm9J3kNXH2GQ89BkOPwbiMnlRFHRVVteyr8kLavupaP6xF2Vvthba6ALevqpaKqij7qmuJ1QUUVxdKoC6uHJzn6gWYhuEl5pw333khKOa8XdSN120f8w/gGmxTvwZ3yDHqSoqvpd66cX+9OufqBYH4YAmNBBUOBgeLn+nX1bBW12BezC/Oxa8fc/VqitdUEmgqI9Q/7/X/u8SvUHcu6mbFn7v2Fj9mjMzl4WumJfQYCmQi0vYqd8OaebDiefjsda8Jtambzo9WZk7jgavHYC8wpaS1bP/RWi+UNRrY/CBn4bjw5X96DO48TzM6552XokWwaZE33Ppx/XAc6VL/v03D/17+fYsiTWksozSc1XCN+G0OXdZw27irj1jCm84VyESk/YjFvGBW93FRr9kxVhs39Mddg+lIhv4ib89qKmHXOti1Pu4qZtx4dUX99TN7NR7Yug/0mpFD8VdP46+m+ldZk41z3pXZuv8P6v7fqJvnYgfPRzjij0eS61w453332kqorWpk2Mi8WI33e4lken9GpHbxhpFM75PqD8ORoL+d+iETkXYkFIJQKpCAhw0kWJF0yBvtfRpyDvbt9AJa2fr6gW3LR7Bi7lFeQbX6TdzWsMk77F2tPNCmF8NrX4w1Me2aWO5ftLCQf/Wz7kaykD/u19Lkcn8eNBGyogeHDZvJj+pcpMSFtJS46bAf2uKmLa4J/cAVXTvCdCPzGp6zRsc5/DrRmoPhKlrtDY/5PBxBKBIX0DK8K7iRjIOBrd9kOO0HiTl2MyiQiYhI4plBlxzv03/yoctjUa95uO6+wGh1E1dKa+tfZa13hbW2/tVWF/ODUsi/s7wuJIUahKaG0w1CFfGhjibCR8MQ12A51A+OB4ahBtN1wbKReWb+d6/xvmO0Ju771s2rPcx01NvmQOBxcd/nMNNNrXPIOTvcOI0H1XDEu8UgJb2RYdx4OLWJddK881pbBTX7Dn6q93l9/NXs9YeNzKuOW39fqdcFUIAUyEREJHihsNdU2X1g0JWIBCKJGp5FREREOiYFMhEREZGAKZCJiIiIBEyBTERERCRgCmQiIiIiAVMgExEREQmYApmIiIhIwBTIRERERAKmQCYiIiISMAUyERERkYCZc+7Ia7VTZrYd2NAGh+oF7GiD43RGOreJpfObODq3iaXzmzg6t4lzpHM7yDmX29iCDh3I2oqZFTjnpgRdRzLSuU0snd/E0blNLJ3fxNG5TZyWnFs1WYqIiIgETIFMREREJGAKZM1zf9AFJDGd28TS+U0cndvE0vlNHJ3bxDnmc6t7yEREREQCpitkIiIiIgFTIDsMMzvXzFaa2Rozuy3oepKNma03s0/NbImZFQRdT0dmZg+aWYmZLY2b19PM5pnZan/YI8gaO7Imzu/PzWyz//tdYmYzg6yxozKzAWb2hpmtMLNlZnajP1+/3xY6zLnVb7cVmFm6mX1gZh/75/cX/vxj+u2qybIJZhYGVgFnAUXAIuBy59zyQAtLIma2HpjinFN/OC1kZqcBFcBfnXPj/Hm/BnY65+70/0HRwzl3a5B1dlRNnN+fAxXOud8EWVtHZ2b5QL5z7kMzywYWAxcDV6Pfb4sc5tx+Gf12W8zMDOjinKswswjwDnAjMItj+O3qClnTpgFrnHNrnXPVwJPARQHXJNIo59x8YGeD2RcBj/jjj+D9QSzHoInzK63AObfVOfehP74HWAH0Q7/fFjvMuZVW4DwV/mTE/ziO8berQNa0fsCmuOki9ENubQ541cwWm9n1QReThHo757aC9wczkBdwPcnoO2b2id+kqSa1FjKzwcAk4H30+21VDc4t6LfbKswsbGZLgBJgnnPumH+7CmRNs0bmqX23dZ3inPsccB5wg98sJNJR/BEYCkwEtgJ3B1pNB2dmWcDTwPedc7uDrieZNHJu9dttJc65qHNuItAfmGZm4451XwpkTSsCBsRN9we2BFRLUnLObfGHJcAzeM3E0nqK/XtI6u4lKQm4nqTinCv2/zCOAX9Bv99j5t9/8zTwmHPuH/5s/X5bQWPnVr/d1uecKwPeBM7lGH+7CmRNWwQMN7MhZpYKzAbmBlxT0jCzLv5NpphZF+BsYOnht5KjNBe4yh+/Cng2wFqSTt0fuL5L0O/3mPg3Rj8ArHDO/TZukX6/LdTUudVvt3WYWa6ZdffHM4AzgUKO8berpywPw38U+HdAGHjQOXdHsBUlDzM7Du+qGEAK8LjO77EzsyeAGUAvoBj4GfBPYA4wENgIfMk5pxvTj0ET53cGXpOPA9YD36i7b0Saz8ymA28DnwIxf/aP8e510u+3BQ5zbi9Hv90WM7Pj8W7aD+Nd4JrjnPtPM8vhGH67CmQiIiIiAVOTpYiIiEjAFMhEREREAqZAJiIiIhIwBTIRERGRgCmQiYiIiARMgUxEOjwzW+APB5vZV1p53z9u7FgiIq1J3V6ISNIwsxnAD5xz5x/FNmHnXPQwyyucc1mtUJ6ISJN0hUxEOjwzq/BH7wRONbMlZnaT/+Lfu8xskf8i5W/4688wszfM7HG8TjMxs3/6L7pfVveyezO7E8jw9/dY/LHMc5eZLTWzT83ssrh9v2lmfzezQjN7zO8xXUSkSSlBFyAi0opuI+4KmR+syp1zU80sDXjXzF71150GjHPOrfOnv+6c2+m/AmWRmT3tnLvNzL7jvzy4oVl4vZ1PwOvBf5GZzfeXTQLG4r3/9l3gFOCd1v6yIpI8dIVMRJLZ2cDXzGwJ3qt4coDh/rIP4sIYwPfM7GPgPWBA3HpNmQ484b+kuRh4C5gat+8i/+XNS4DBrfBdRCSJ6QqZiCQzA77rnHul3kzvXrO9DabPBE5yzu0zszeB9GbsuylVceNR9GetiByBrpCJSDLZA2THTb8CfMvMIgBmNsLMujSyXTdglx/GRgEnxi2rqdu+gfnAZf59arnAacAHrfItRKTT0b/aRCSZfALU+k2PDwO/x2su/NC/sX47cHEj270MfNPMPgFW4jVb1rkf+MTMPnTOXRE3/xngJOBjwAE/cs5t8wOdiMhRUbcXIiIiIgFTk6WIiIhIwBTIRERERAKmQCYiIiISMAUyERERkYApkImIiIgETIFMREREJGAKZCIiIiIBUyATERERCdj/Dw98RdT8PV+bAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(trace.history['loss'], '-')\n",
    "plt.plot(trace.history['val_loss'], '-')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim(10,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model- IMPORTANT TO USE NEVER BEFORE SEEN DATA\n",
    "\n",
    "#from train data (not ideal to use for testing)\n",
    "# prediction = model.predict(x_train[-1000:-1])\n",
    "# actual = y_train[-1000:-1]\n",
    "\n",
    "#x_data------------------\n",
    "# just cart\n",
    "# trajTest = np.loadtxt(open(\"simulation/data/traj_2sec.txt\", \"rb\"), delimiter=\",\")\n",
    "# trajPtsTest = np.shape(trajTest)[0] #points per test trajectory\n",
    "# numTrajTest = np.shape(trajTest)[1]//3 #number of test trajectories\n",
    "# tTest = np.zeros([trajPtsTest,3,numTrajTest])\n",
    "# for j in range(np.shape(trajTest)[0]):\n",
    "#     for i in range(np.shape(trajTest)[1]//3):\n",
    "#         tTest[j,:,i] = trajTest[j,3*i:3*(i+1)]\n",
    "\n",
    "#cat + angs\n",
    "trajTest = np.loadtxt(open(\"simulation/data/traj_with_angs_1k.txt\", \"rb\"), delimiter=\",\")\n",
    "trajPtsTest = np.shape(trajTest)[0] #points per test trajectory\n",
    "numTrajTest = np.shape(trajTest)[1]//6 #number of test trajectories\n",
    "tTest = np.zeros([trajPtsTest,6,numTrajTest])\n",
    "for j in range(np.shape(trajTest)[0]):\n",
    "    for i in range(np.shape(trajTest)[1]//6):\n",
    "        tTest[j,:,i] = trajTest[j,6*i:6*(i+1)]\n",
    "\n",
    "\n",
    "        \n",
    "#swap axis so batch size is first axis (for TF)\n",
    "tTest = np.swapaxes(tTest,0,2)\n",
    "#swap axis again so that conv1D moves on time and not xyz\n",
    "tTest = np.swapaxes(tTest,1,2)\n",
    "x_test = tf.convert_to_tensor(tTest,np.float32)\n",
    "\n",
    "#y_data-------------------\n",
    "# jointPosTest = np.loadtxt(open(\"simulation/data/jointPos_2sec.txt\", \"rb\"), delimiter=\",\")\n",
    "jointPosTest = np.loadtxt(open(\"simulation/data/jointPos_with_angs_1k.txt\", \"rb\"), delimiter=\",\")\n",
    "y_test = tf.convert_to_tensor(jointPosTest,np.float32)\n",
    "\n",
    "prediction = model.predict(x_test)\n",
    "error = (y_test - prediction)\n",
    "# print(np.floor(error))\n",
    "\n",
    "#average error for estimates for each joint\n",
    "avg = np.average(abs(error),axis=0)\n",
    "print(\"average error = \", avg)\n",
    "\n",
    "#range for each joint:\n",
    "ranges = [50, 60, 67.5, 110, 120, 360, 130]\n",
    "rel_error = avg/ranges\n",
    "print(\"error as frac of joint range = \", np.floor(rel_error*1000)/1000) #1 is full range of joint\n",
    "print(\"total error = \",sum(rel_error))\n",
    "\n",
    "#current best for network 1 is: \n",
    "#                 0.438 @ [0.09  0.082 0.034 0.086 0.061 0.024 0.058]\n",
    "#                 val_error: 81.84\n",
    "\n",
    "#current best for network 3 is: \n",
    "#                 0.357 @ [0.087 0.08  0.036 0.053 0.03  0.019 0.047]\n",
    "#                 val_error: 44.97 \n",
    "#                 (using 100k dataset)\n",
    "\n",
    "print(prediction[-10])\n",
    "print(y_test[-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"trajectory_cls.kmod\")\n",
    "\n",
    "# model.save(\"trajectory_random_forces_cls.kmod\")\n",
    "\n",
    "model.save(\"trajectory_with_angs.kmod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best scoring model for 1M dataset\n",
    "# model = tf.keras.models.load_model(\"trajectory_cls.kmod\")\n",
    "\n",
    "model = tf.keras.models.load_model(\"trajectory_with_angs.kmod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proof my model is doing better than completely random guessing\n",
    "\n",
    "np.random.seed(None)\n",
    "\n",
    "# print(actual)\n",
    "# print(tf.shape(actual)) #[99 7]\n",
    "B = tf.random.uniform([1000,7])\n",
    "\n",
    "# B = tf.ones([99,7])\n",
    "B = B *tf.constant([25., 30., 33.75, 55. , 60., 180., 65.]) + tf.constant([0., 0., 26.25, -35., 30., 0., -65.])\n",
    "\n",
    "# print(tf.shape(B))\n",
    "# print(tf.shape(actual))\n",
    "\n",
    "fake_error = (y_test - B)\n",
    "# print(fake_error)\n",
    "\n",
    "fake_avg = tf.math.reduce_mean(tf.math.abs(fake_error), axis=0)\n",
    "print(fake_avg)\n",
    "\n",
    "rel_fake_error = fake_avg/ranges\n",
    "\n",
    "print(\"error as frac of joint range: \",rel_fake_error)\n",
    "print(\"total error: \", sum(rel_fake_error))\n",
    "\n",
    "#NOTE: these are not all the same becuase the starting ranges for joint positions do NOT fall in the middle of all\n",
    "#      possible positions for each joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-punishment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn",
   "language": "python",
   "name": "dnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
