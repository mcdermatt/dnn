{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn Tensorflow via a linear regression model\n",
    "In this excercise, you will learn tensorflow in steps. Please use python 3 and tensorflow >=1.4.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bit of setup\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow graph\n",
    "\n",
    "In the first step, we check the computation graph with a simple example. \n",
    "\n",
    "### <span style=\"color:red\">Question 1 (4 points):</span>\n",
    "Please run the code in the cell below and check the computation graph generated by `tensorboard`. \n",
    "1. What do the three ovals represent? \n",
    "2. Uncomment `x = 3` below and check the graph again. Don't forget to use the dropdown menu to select your latest run. Explain why the computation graph is different with the previous one. \n",
    "\n",
    "Write your answer below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Derm\\anaconda3\\envs\\dnn\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1203: start (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.start` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Derm\\anaconda3\\envs\\dnn\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1259: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Derm\\anaconda3\\envs\\dnn\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1259: save (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "`tf.python.eager.profiler` has deprecated, use `tf.profiler` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Derm\\anaconda3\\envs\\dnn\\lib\\site-packages\\tensorflow\\python\\eager\\profiler.py:151: maybe_create_event_file (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "`tf.python.eager.profiler` has deprecated, use `tf.profiler` instead.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# The function to be traced.\n",
    "@tf.function\n",
    "def my_func(x):\n",
    "  \"A simple function\"\n",
    "\n",
    "  for i in range(3):\n",
    "    x = x + 2\n",
    "\n",
    "  return x\n",
    "\n",
    "# Set up logging.\n",
    "logdir=\"runs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# initialize the argument\n",
    "x = tf.constant(3)\n",
    "#x = 3 # TODO: uncomment this line and check the difference\n",
    "\n",
    "# Bracket the function call with\n",
    "# tf.summary.trace_on() and tf.summary.trace_export().\n",
    "tf.summary.trace_on(graph=True, profiler=True)\n",
    "\n",
    "# Call only one tf.function when tracing.\n",
    "output = my_func(x)\n",
    "\n",
    "with writer.as_default():\n",
    "  tf.summary.trace_export(\n",
    "      name=\"my_func_trace\",\n",
    "      step=0,\n",
    "      profiler_outdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 1536."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn Tensorflow through a linear regression model\n",
    "\n",
    "In this task, you will learn `tensorflow` through a logistic regression model. \n",
    "### <span style=\"color:red\">Question 2 (4 points):</span>\n",
    "You need to run all cells below and make necessary changes to avoid errors. At the end, you will get a regression model trained. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow basics\n",
    "Tensorflow use tensors to store scalars, vectors, matrices, and tensors. Here is the introduction webpage of tensorflow: https://www.tensorflow.org/guide/tensor . The few cells below show you a few simple operations on tensorflow arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a has shape:  (3,)\n",
      "b[:, 1] is: \n",
      "tf.Tensor([2. 5.], shape=(2,), dtype=float32)\n",
      "b[0] is: \n",
      "tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Get the shape of a tensor: \n",
    "\n",
    "a = tf.constant([1, 2, 3], dtype=tf.float32)\n",
    "\n",
    "print('a has shape: ', a.get_shape())\n",
    "\n",
    "\n",
    "# indexing in tensors is similar to numpy arrays\n",
    "\n",
    "b = tf.constant([[1, 2, 3], [4, 5, 6]], dtype=tf.float32)\n",
    "\n",
    "print('b[:, 1] is: ')\n",
    "print(b[:, 1])\n",
    "\n",
    "print('b[0] is: ')\n",
    "print(b[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum up b along rows: tf.Tensor([ 6. 15.], shape=(2,), dtype=float32)\n",
      "Sum up b along rows: tf.Tensor(21.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# take the sum along a dimension \n",
    "\n",
    "print('Sum up b along rows:', tf.reduce_sum(b, axis=1)) # the `axis` specifies the dimension to be ``reduced''\n",
    "\n",
    "# reduce two dimensions in a summation \n",
    "print('Sum up b along rows:', tf.reduce_sum(b, axis=[0, 1])) # the `axis` specifies the dimension to be ``reduced''\n",
    "\n",
    "# similar functions are tf.reduce_max, tf.reduce_logsumexp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c has shape:  (1, 3)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute MatMul as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-89371cc60ca6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'c has shape: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\dnn\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dnn\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   3253\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3254\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[1;32m-> 3255\u001b[1;33m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   3256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dnn\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5622\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5623\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5624\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5625\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5626\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dnn\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6842\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6843\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6844\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dnn\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute MatMul as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "# matrix multiplication \n",
    "\n",
    "c = tf.constant([[2, 2, 2]]) \n",
    "\n",
    "# Use this line, otherwise it doesn't work.\n",
    "# c = tf.constant([[2], [2], [2]], dtype=tf.float32) \n",
    "\n",
    "print('c has shape: ', c.get_shape())\n",
    "\n",
    "print(tf.matmul(b, c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement  functions for a linear regression model \n",
    "\n",
    "### <span style=\"color:red\">Question 3 (4 points):</span>\n",
    "Please implement a linear regression model in `implementation.regression_func`. The empty function has detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementation import regression_func\n",
    "\n",
    "x = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
    "w = tf.constant([1, 1], dtype=tf.float32)\n",
    "b = tf.constant(0.2, dtype=tf.float32)\n",
    "\n",
    "y_hat = regression_func(x, w, b)\n",
    "\n",
    "print(y_hat.numpy())\n",
    "\n",
    "# y_hat should be [3.2, 7.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Question 4 (4 points):</span>\n",
    "\n",
    "Please implement a loss function in  `implementation.loss_func`. The empty function has detailed instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from implementation import loss_func\n",
    "\n",
    "# fix an issue in this line, otherwise it does not work with the loss function\n",
    "y = tf.constant([3, 7])\n",
    "\n",
    "loss = loss_func(y, y_hat)\n",
    "\n",
    "print(loss)\n",
    "\n",
    "# the loss should be 0.08\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate gradient with `tf.GradientTape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as gt:\n",
    "    gt.watch([w, b])\n",
    "    y_hat = regression_func(x, w, b)\n",
    "    \n",
    "dy_dwb = gt.gradient(y_hat, [w, b]) \n",
    "\n",
    "# gradient with respect to w and b\n",
    "print(dy_dwb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update parameters with an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that the learning rate is 1.0\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1.0)\n",
    "\n",
    "# You can update a tf.Variable, but not a tf.Tensor\n",
    "# Can you fix the following to lines?\n",
    "w = tf.constant([1.0, 1.0], dtype=tf.float32)\n",
    "b = tf.constant(1.0, dtype=tf.float32)\n",
    "\n",
    "\n",
    "dw = tf.constant([0.1, 0.2], dtype=tf.float32)\n",
    "db = tf.constant(0.3, dtype=tf.float32)\n",
    "\n",
    "optimizer.apply_gradients(zip([dw, db], [w, b]))\n",
    "\n",
    "# Check the result below. Note that the calculation is: w <- w - dw * learning_rate; \n",
    "# it is subtraction, not addtion.\n",
    "print(w)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the regression model\n",
    "\n",
    "Now we can implement a regression model. We use data with one feature only so we can plot the data easily. Assume the feature matrix is `x_np` and the label is `y_np`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data before fitting the model. \n",
    "# numpy values\n",
    "N = 100\n",
    "x_np = np.random.random_sample([N, 1]).astype(np.float32)\n",
    "y_np = (np.squeeze(x_np.dot([[0.3]])) + 1.0 + 0.1 * np.random.random_sample([N])).astype(np.float32)\n",
    "\n",
    "plt.plot(np.squeeze(x_np), y_np, 'o')\n",
    "plt.ylabel('y')\n",
    "plt.ylabel('x')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Question 5 (4 points):</span>\n",
    "Please implement the `implementation.train_lr` function, which trains a linear regression model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementation import train_lr\n",
    "\n",
    "lamb = tf.constant(1.0, dtype=tf.float32)\n",
    "\n",
    "w, b = train_lr(x=tf.constant(x_np), y=tf.constant(y_np), lamb=lamb)\n",
    "\n",
    "print('(w, b) = ', (w.numpy(), b.numpy()))\n",
    "\n",
    "# the result should be similar to (0.3, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the result\n",
    "\n",
    "w_np = w.numpy()\n",
    "b_np = b.numpy()\n",
    "\n",
    "x_line = np.arange(12) / 10.0\n",
    "y_line = x_line * np.squeeze(w_np) + b_np\n",
    "\n",
    "plt.plot(x_np, y_np, 'o')\n",
    "plt.plot(x_line, y_line)\n",
    "plt.ylabel('y')\n",
    "plt.ylabel('x')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
